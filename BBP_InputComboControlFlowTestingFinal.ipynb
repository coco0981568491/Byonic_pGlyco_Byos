{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aacb31f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original byonic columns:\n",
      "Index(['PID', 'Prot._x000D_\\nRank', 'Pos.', 'Sequence_x000D_\\n(unformatted)',\n",
      "       'Mods_x000D_\\n(variable)', 'Glycans', 'PEP_x000D_\\n2D',\n",
      "       'PEP_x000D_\\n1D', '|Log Prob|', 'Score', 'Delta_x000D_\\nScore',\n",
      "       'Delta Mod._x000D_\\nScore', 'z', 'Obs._x000D_\\nm/z',\n",
      "       'Calc._x000D_\\nm/z', 'ppm_x000D_\\nerr.', 'Off-_x000D_\\nBy-X',\n",
      "       'Obs._x000D_\\nMH', 'Calc._x000D_\\nMH', 'Cleavage',\n",
      "       'Glycans_x000D_\\nPos.', 'Protein_x000D_\\nName', 'Prot._x000D_\\nId',\n",
      "       'Scan_x000D_\\nTime', 'Scan #', 'Mods_x000D_\\n(fixed)', 'Comment',\n",
      "       'Fragment_x000D_\\nType', 'FDR_x000D_\\n2D', 'FDR_x000D_\\n1D',\n",
      "       'FDR uniq._x000D_\\n2D', 'FDR uniq._x000D_\\n1D', 'q-value_x000D_\\n2D',\n",
      "       'q-value_x000D_\\n1D'],\n",
      "      dtype='object')\n",
      "\n",
      "Fixed byonic columns:\n",
      "Index(['PID', 'Prot.\\r\\nRank', 'Pos.', 'Sequence\\r\\n(unformatted)',\n",
      "       'Mods\\r\\n(variable)', 'Glycans', 'PEP\\r\\n2D', 'PEP\\r\\n1D', '|Log Prob|',\n",
      "       'Score', 'Delta\\r\\nScore', 'Delta Mod.\\r\\nScore', 'z', 'Obs.\\r\\nm/z',\n",
      "       'Calc.\\r\\nm/z', 'ppm\\r\\nerr.', 'Off-\\r\\nBy-X', 'Obs.\\r\\nMH',\n",
      "       'Calc.\\r\\nMH', 'Cleavage', 'Glycans\\r\\nPos.', 'Protein\\r\\nName',\n",
      "       'Prot.\\r\\nId', 'Scan\\r\\nTime', 'Scan #', 'Mods\\r\\n(fixed)', 'Comment',\n",
      "       'Fragment\\r\\nType', 'FDR\\r\\n2D', 'FDR\\r\\n1D', 'FDR uniq.\\r\\n2D',\n",
      "       'FDR uniq.\\r\\n1D', 'q-value\\r\\n2D', 'q-value\\r\\n1D'],\n",
      "      dtype='object')\n",
      "\n",
      "Original byonic data size:\n",
      "row: 3327\n",
      "col: 34\n",
      "\n",
      "----- Byonic data preprocessing completed. -----\n",
      "\n",
      "----- Only Byonic file is detected. Start the corresponding processing. -----\n",
      "\n",
      "\n",
      "----- Exporting \"_All\" file... This may take some time, please wait. -----\n",
      "\n",
      "<Color Summary>\n",
      "1958 rows will be colored light green (#ccffcc).\n",
      "0 rows will be colored green (#99ff99).\n",
      "1369 rows will be colorless in byonic data.\n",
      "\n",
      "----- \"_All\" file exported. -----\n",
      "\n",
      "----- Start preparing simplified version. -----\n",
      "\n",
      "Done sorting by z[Byonic] --> Done sorting by Calc.MH --> Done sorting by PepMS --> Done sorting by Glycans --> Done sorting by PureSequence --> Done sorting by N-site(SequonBased)\n",
      "\n",
      "----- Exporting \"_UniquePep\" file... This may take some time, please wait. -----\n",
      "\n",
      "<Color Summary>\n",
      "522 rows will be colored light green (#ccffcc).\n",
      "0 rows will be colored green (#99ff99).\n",
      "0 rows will be colorless in byonic data.\n",
      "\n",
      "----- \"_UniquePep\" file exported. -----\n",
      "\n",
      "\n",
      "All tasks completed.\n",
      "Execution time: 16.62 seconds\n"
     ]
    }
   ],
   "source": [
    "# TO-DO\n",
    "# DEAL W/ O GLYCAN, NEW UNIQUE FILE\n",
    "# %%capture cap --no-stderr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import ticker\n",
    "from IPython.display import display, HTML\n",
    "import re # finding specific patterns in str\n",
    "import textwrap # split text into equal parts\n",
    "import collections # return repeated items in list\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from datetime import datetime # attach current date to export filename\n",
    "import sys\n",
    "import ast # convert str back to tuple/list/int, etc\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import string\n",
    "\n",
    "## INPUT EXCEL FILES\n",
    "byonicfile = 'byonic_Fcwf_T_Chy_Mammalian' # Please paste filename here. if None, please leave it as empty string '' (NOTE: DO NOT INCLUDE .XLSX HERE)\n",
    "byosfile = 'UU4__Fcwf' # Please paste filename here. if None, please leave it as empty string '' (NOTE: DO NOT INCLUDE .XLSX HERE)\n",
    "pglycofile = 'pglyco_Fcwf_T_Chy_Mammalian' # Please paste filename here. if None, please leave it as empty string '' (NOTE: DO NOT INCLUDE .XLSX HERE)\n",
    "\n",
    "## ADJUSTABLE PARAMETERS\n",
    "# HCD: light colors\n",
    "lightgreen_hex = '#ccffcc' \n",
    "lightblue_hex = '#cce6ff'\n",
    "lightorange_hex = '#ffebcc'\n",
    "# ETD: normal colors\n",
    "normalgreen_hex = '#99ff99'\n",
    "normalblue_hex = '#99ccff'\n",
    "normalorange_hex = '#ffd699' \n",
    "# GlycanSource B+P, B/P: deep colors\n",
    "darkgreen_hex = '#66ff66' \n",
    "darkblue_hex = '#66b3ff'\n",
    "# byos colors\n",
    "lightpink_hex = '#ffb6c1'\n",
    "deeppink_hex = '#ff1493'\n",
    "yellow_hex = '#ffff66' \n",
    "# BYONIC RT TOLERANCE <min.> (COUNT PSM)\n",
    "byonic_rt = 3\n",
    "# PGLYCO RT TOLERANCE <sec.> (COUNT PSM)\n",
    "pglyco_rt = 180\n",
    "# SCAN DIFFERENCE <scan num.> (ASSIGN PAIR)\n",
    "byonic_scandif = 5\n",
    "# PLOTTING CHOICES (whether to plot xicauc(byos)/int(byos)/mono(pglyco)/isotope(pglyco))\n",
    "# if you do not want to plot anything, please set all 4 parameters to 'no'.\n",
    "export_xicauc = 'yes' # set this to 'no' if byos file is not present\n",
    "export_int = 'yes' # set this to 'no' if byos file is not present \n",
    "export_mono = 'yes' # set this to 'no' if pglyco file is not present\n",
    "export_isotope = 'yes' # set this to 'no' if pglyco file is not present\n",
    "\n",
    "############################### PLEASE DO NOT ALTER ANYTHING BELOW ###############################\n",
    "# AUXILIARY FUNCTIONS\n",
    "def move_df(df, move_col, insert_left_col):\n",
    "    move_df = df[move_col]\n",
    "    df.drop(labels=[move_col], axis=1, inplace = True)\n",
    "    df.insert(df.columns.get_loc(insert_left_col) + 1, move_col, move_df)\n",
    "def sort_intstr_col(df, col_to_sort):\n",
    "    # accepts int & str mixed type col, no other datatype is allowed\n",
    "    lst = df[col_to_sort].tolist()\n",
    "    lst.sort(key=lambda v: (isinstance(v, str), v))\n",
    "    # reindex the df with .loc by the new sorted lst\n",
    "    df = df.set_index(col_to_sort).loc[lst]\n",
    "    df = df.drop_duplicates().reset_index()\n",
    "    return df\n",
    "# get export filename based on input combo\n",
    "def export_filename(byonicfile = '', byosfile = '', pglycofile = ''):\n",
    "    names = [byonicfile, byosfile, pglycofile]\n",
    "    names = [n for n in names if n != '']\n",
    "    names = '_'.join(names)\n",
    "    return names\n",
    "# define glycansource function\n",
    "def glycansource(df, colname):\n",
    "    # glycan comprison: only present in byonic -> b, only present in pglyco -> p, both the same -> b+p, not the same -> b/p\n",
    "    conditions = [\n",
    "        (df['Glycans[Byonic]'] != -1) & (df['GlycanComposition_ByonicStyle[pGlyco]'] == -1),\n",
    "        (df['Glycans[Byonic]'] == -1) & (df['GlycanComposition_ByonicStyle[pGlyco]'] != -1),\n",
    "        (df['Glycans[Byonic]'] != -1) & (df['GlycanComposition_ByonicStyle[pGlyco]'] != -1) & (df['Glycans[Byonic]'] == df['GlycanComposition_ByonicStyle[pGlyco]']),\n",
    "        (df['Glycans[Byonic]'] != -1) & (df['GlycanComposition_ByonicStyle[pGlyco]'] != -1) & (df['Glycans[Byonic]'] != df['GlycanComposition_ByonicStyle[pGlyco]'])]\n",
    "    choices = ['B', 'P', 'B=P', 'B≠P'] \n",
    "    glycan_source = np.select(conditions, choices, -1) \n",
    "    df.insert(df.columns.get_loc(colname) + 1 , 'GlycanSource', glycan_source , True)\n",
    "# define mask function\n",
    "def threshold_masks_colorind(df):\n",
    "    global b_hcd_mask, p_hcd_mask, both_hcd_mask, b_etd_mask, p_etd_mask, both_etd_mask\n",
    "    global b_glycansource_mask, p_glycansource_mask, byos_exclusiveOr_mask, byos_and_mask, byos_bothsame_mask\n",
    "    global lightgreen_ind, lightblue_ind, lightorange_ind, normalgreen_ind, normalblue_ind, normalorange_ind, deepgreen_ind, deepblue_ind, lightpink_ind, deeppink_ind, yellow_ind  \n",
    "\n",
    "    if byonicfile != '' and byosfile != '' and pglycofile != '': # bbp all present\n",
    "        # HCD \n",
    "        b_hcd_mask = (df['Fragment\\r\\nType[Byonic]'] == 'hcd') & (df['Score[Byonic]'] > 200) & (df['PEP\\r\\n2D[Byonic]'].abs() < 0.001) & ((df['PepScore[pGlyco]'] <= 5) | (df['GlyScore[pGlyco]'] <= 4))\n",
    "        p_hcd_mask = (df['FragmentType[pGlyco]'] == 'hcd') & ((df['Score[Byonic]'] <= 200) | (df['PEP\\r\\n2D[Byonic]'].abs() >= 0.001)) & (df['PepScore[pGlyco]'] > 5) & (df['GlyScore[pGlyco]'] > 4)    \n",
    "        both_hcd_mask = (df['Fragment\\r\\nType[Byonic]'] == 'hcd') & (df['FragmentType[pGlyco]'] == 'hcd') & (df['Score[Byonic]'] > 200) & (df['PEP\\r\\n2D[Byonic]'].abs() < 0.001) & (df['PepScore[pGlyco]'] > 5) & (df['GlyScore[pGlyco]'] > 4)\n",
    "        # ETD: remember byonic etd does not need threshold, so we only need ot make sure that the row only contain byonic data, which means pglyco data will be -1\n",
    "        b_etd_mask = (df['Fragment\\r\\nType[Byonic]'] == 'ethcd') & (df['Score[Byonic]'] != -1) & (df['PEP\\r\\n2D[Byonic]'] != -1) & ((df['PepScore[pGlyco]'] <= 5) | (df['GlyScore[pGlyco]'] <= 4)) \n",
    "        p_etd_mask = (df['FragmentType[pGlyco]'] == 'ethcd') & (df['Score[Byonic]'] == -1) & (df['PEP\\r\\n2D[Byonic]'] == -1) & (df['PepScore[pGlyco]'] > 5) & (df['GlyScore[pGlyco]'] > 4)    \n",
    "        both_etd_mask = (df['Fragment\\r\\nType[Byonic]'] == 'ethcd') & (df['FragmentType[pGlyco]'] == 'ethcd') & (df['Score[Byonic]'] != -1) & (df['PEP\\r\\n2D[Byonic]'] != -1) & (df['PepScore[pGlyco]'] > 5) & (df['GlyScore[pGlyco]'] > 4)\n",
    "        # (HCD OR ETD) & (B+P OR B/P) & passes threshold: parts of lightblue/blue & lightgreen/green will become deep colors\n",
    "        b_glycansource_mask = ((df['GlycanSource'] == 'B=P') ^ (df['GlycanSource'] == 'B≠P')) & ((b_hcd_mask) ^ (b_etd_mask)) & (~((p_hcd_mask) ^ (p_etd_mask))) # hcd exclusive or etd & ~(p)\n",
    "        p_glycansource_mask = ((df['GlycanSource'] == 'B=P') ^ (df['GlycanSource'] == 'B≠P')) & ((p_hcd_mask) ^ (p_etd_mask)) & (~((b_hcd_mask) ^ (b_etd_mask))) # hcd exclusive or etd & ~(b)   \n",
    "        # comparison between byonic & byos\n",
    "        byos_exclusiveOr_mask = (df['Calc.M[Byos]'] != -1) & (df['Calc.M[Byonic]'] != -1) & ((df['Calc.M[Byos]'] != df['Calc.M[Byonic]'])^(df['PureSequence[Byos]'] != df['PureSequence[Byonic]']))\n",
    "        byos_and_mask = (df['Calc.M[Byos]'] != -1) & (df['Calc.M[Byonic]'] != -1) & (df['Calc.M[Byos]'] != df['Calc.M[Byonic]']) & (df['PureSequence[Byos]'] != df['PureSequence[Byonic]'])\n",
    "        byos_bothsame_mask = (df['Calc.M[Byos]'] != -1) & (df['Calc.M[Byonic]'] != -1) & (df['Calc.M[Byos]'] == df['Calc.M[Byonic]']) & (df['PureSequence[Byos]'] == df['PureSequence[Byonic]'])\n",
    "        # record df color indices\n",
    "        lightgreen_ind = df.loc[b_hcd_mask].index.tolist()\n",
    "        df.loc[b_hcd_mask, 'ColorCode'] = 'lightgreen(%s)'%lightgreen_hex\n",
    "        \n",
    "        lightblue_ind = df.loc[p_hcd_mask].index.tolist()\n",
    "        df.loc[p_hcd_mask, 'ColorCode'] = 'lightblue(%s)'%lightblue_hex\n",
    "        \n",
    "        lightorange_ind = df.loc[both_hcd_mask].index.tolist()\n",
    "        df.loc[both_hcd_mask, 'ColorCode'] = 'lightorange(%s)'%lightorange_hex\n",
    "        \n",
    "        normalgreen_ind = df.loc[b_etd_mask].index.tolist()\n",
    "        df.loc[b_etd_mask, 'ColorCode'] = 'normalgreen(%s)'%normalgreen_hex\n",
    "        \n",
    "        normalblue_ind = df.loc[p_etd_mask].index.tolist()\n",
    "        df.loc[p_etd_mask, 'ColorCode'] = 'normalblue(%s)'%normalblue_hex\n",
    "            \n",
    "        normalorange_ind = df.loc[both_etd_mask].index.tolist()\n",
    "        df.loc[both_etd_mask, 'ColorCode'] = 'normalorange(%s)'%normalorange_hex\n",
    "        \n",
    "        deepgreen_ind = df.loc[b_glycansource_mask].index.tolist()\n",
    "        df.loc[b_glycansource_mask, 'ColorCode'] = 'deepgreen(%s)'%darkgreen_hex\n",
    "        \n",
    "        deepblue_ind = df.loc[p_glycansource_mask].index.tolist()\n",
    "        df.loc[p_glycansource_mask, 'ColorCode'] = 'deepblue(%s)'%darkblue_hex\n",
    "        \n",
    "        lightpink_ind = df.loc[byos_exclusiveOr_mask].index.tolist()\n",
    "        \n",
    "        deeppink_ind = df.loc[byos_and_mask].index.tolist()\n",
    "        \n",
    "        yellow_ind = df.loc[byos_bothsame_mask].index.tolist()\n",
    "    elif byonicfile != '' and byosfile == '' and pglycofile != '': # byonic + pglyco\n",
    "        # HCD \n",
    "        b_hcd_mask = (df['Fragment\\r\\nType[Byonic]'] == 'hcd') & (df['Score[Byonic]'] > 200) & (df['PEP\\r\\n2D[Byonic]'].abs() < 0.001) & ((df['PepScore[pGlyco]'] <= 5) | (df['GlyScore[pGlyco]'] <= 4))\n",
    "        p_hcd_mask = (df['FragmentType[pGlyco]'] == 'hcd') & ((df['Score[Byonic]'] <= 200) | (df['PEP\\r\\n2D[Byonic]'].abs() >= 0.001)) & (df['PepScore[pGlyco]'] > 5) & (df['GlyScore[pGlyco]'] > 4)    \n",
    "        both_hcd_mask = (df['Fragment\\r\\nType[Byonic]'] == 'hcd') & (df['FragmentType[pGlyco]'] == 'hcd') & (df['Score[Byonic]'] > 200) & (df['PEP\\r\\n2D[Byonic]'].abs() < 0.001) & (df['PepScore[pGlyco]'] > 5) & (df['GlyScore[pGlyco]'] > 4)\n",
    "        # ETD: remember byonic etd does not need threshold, so we only need ot make sure that the row only contain byonic data, which means pglyco data will be -1\n",
    "        b_etd_mask = (df['Fragment\\r\\nType[Byonic]'] == 'ethcd') & (df['Score[Byonic]'] != -1) & (df['PEP\\r\\n2D[Byonic]'] != -1) & ((df['PepScore[pGlyco]'] <= 5) | (df['GlyScore[pGlyco]'] <= 4)) \n",
    "        p_etd_mask = (df['FragmentType[pGlyco]'] == 'ethcd') & (df['Score[Byonic]'] == -1) & (df['PEP\\r\\n2D[Byonic]'] == -1) & (df['PepScore[pGlyco]'] > 5) & (df['GlyScore[pGlyco]'] > 4)    \n",
    "        both_etd_mask = (df['Fragment\\r\\nType[Byonic]'] == 'ethcd') & (df['FragmentType[pGlyco]'] == 'ethcd') & (df['Score[Byonic]'] != -1) & (df['PEP\\r\\n2D[Byonic]'] != -1) & (df['PepScore[pGlyco]'] > 5) & (df['GlyScore[pGlyco]'] > 4)\n",
    "        # (HCD OR ETD) & (B+P OR B/P) & passes threshold: parts of lightblue/blue & lightgreen/green will become deep colors\n",
    "        b_glycansource_mask = ((df['GlycanSource'] == 'B=P') ^ (df['GlycanSource'] == 'B≠P')) & ((b_hcd_mask) ^ (b_etd_mask)) & (~((p_hcd_mask) ^ (p_etd_mask))) # hcd exclusive or etd & ~(p)\n",
    "        p_glycansource_mask = ((df['GlycanSource'] == 'B=P') ^ (df['GlycanSource'] == 'B≠P')) & ((p_hcd_mask) ^ (p_etd_mask)) & (~((b_hcd_mask) ^ (b_etd_mask))) # hcd exclusive or etd & ~(b)   \n",
    "        # record df color indices\n",
    "        lightgreen_ind = df.loc[b_hcd_mask].index.tolist()\n",
    "        df.loc[b_hcd_mask, 'ColorCode'] = 'lightgreen(%s)'%lightgreen_hex\n",
    "        \n",
    "        lightblue_ind = df.loc[p_hcd_mask].index.tolist()\n",
    "        df.loc[p_hcd_mask, 'ColorCode'] = 'lightblue(%s)'%lightblue_hex\n",
    "        \n",
    "        lightorange_ind = df.loc[both_hcd_mask].index.tolist()\n",
    "        df.loc[both_hcd_mask, 'ColorCode'] = 'lightorange(%s)'%lightorange_hex\n",
    "        \n",
    "        normalgreen_ind = df.loc[b_etd_mask].index.tolist()\n",
    "        df.loc[b_etd_mask, 'ColorCode'] = 'normalgreen(%s)'%normalgreen_hex\n",
    "        \n",
    "        normalblue_ind = df.loc[p_etd_mask].index.tolist()\n",
    "        df.loc[p_etd_mask, 'ColorCode'] = 'normalblue(%s)'%normalblue_hex\n",
    "            \n",
    "        normalorange_ind = df.loc[both_etd_mask].index.tolist()\n",
    "        df.loc[both_etd_mask, 'ColorCode'] = 'normalorange(%s)'%normalorange_hex\n",
    "        \n",
    "        deepgreen_ind = df.loc[b_glycansource_mask].index.tolist()\n",
    "        df.loc[b_glycansource_mask, 'ColorCode'] = 'deepgreen(%s)'%darkgreen_hex\n",
    "        \n",
    "        deepblue_ind = df.loc[p_glycansource_mask].index.tolist()\n",
    "        df.loc[p_glycansource_mask, 'ColorCode'] = 'deepblue(%s)'%darkblue_hex\n",
    "    elif byonicfile != '' and byosfile == '' and pglycofile == '': # only byonic\n",
    "        # HCD \n",
    "        b_hcd_mask = (df['Fragment\\r\\nType'] == 'hcd') & (df['Score'] > 200) & (df['PEP\\r\\n2D'].abs() < 0.001)\n",
    "        # ETD: remember byonic etd does not need threshold, so we only need ot make sure that the row only contain byonic data, which means pglyco data will be -1\n",
    "        b_etd_mask = (df['Fragment\\r\\nType'] == 'ethcd') & (df['Score'] != -1) & (df['PEP\\r\\n2D'] != -1) \n",
    "        # record df color indices\n",
    "        lightgreen_ind = df.loc[b_hcd_mask].index.tolist()\n",
    "        df.loc[b_hcd_mask, 'ColorCode'] = 'lightgreen(%s)'%lightgreen_hex\n",
    "        \n",
    "        normalgreen_ind = df.loc[b_etd_mask].index.tolist()\n",
    "        df.loc[b_etd_mask, 'ColorCode'] = 'normalgreen(%s)'%normalgreen_hex\n",
    "    elif byonicfile == '' and byosfile == '' and pglycofile != '': # only pglyco\n",
    "        # HCD \n",
    "        p_hcd_mask = (df['FragmentType'] == 'hcd') & (df['PepScore'] > 5) & (df['GlyScore'] > 4)    \n",
    "        # ETD: remember byonic etd does not need threshold, so we only need ot make sure that the row only contain byonic data, which means pglyco data will be -1\n",
    "        p_etd_mask = (df['FragmentType'] == 'ethcd') & (df['PepScore'] > 5) & (df['GlyScore'] > 4)    \n",
    "        # record df color indices\n",
    "        lightblue_ind = df.loc[p_hcd_mask].index.tolist()\n",
    "        df.loc[p_hcd_mask, 'ColorCode'] = 'lightblue(%s)'%lightblue_hex\n",
    "        \n",
    "        normalblue_ind = df.loc[p_etd_mask].index.tolist()\n",
    "        df.loc[p_etd_mask, 'ColorCode'] = 'normalblue(%s)'%normalblue_hex\n",
    "    elif byonicfile != '' and byosfile != '' and pglycofile == '': # byonic + byos\n",
    "        # HCD \n",
    "        b_hcd_mask = (df['Fragment\\r\\nType[Byonic]'] == 'hcd') & (df['Score[Byonic]'] > 200) & (df['PEP\\r\\n2D[Byonic]'].abs() < 0.001)\n",
    "        # ETD: remember byonic etd does not need threshold, so we only need ot make sure that the row only contain byonic data, which means pglyco data will be -1\n",
    "        b_etd_mask = (df['Fragment\\r\\nType[Byonic]'] == 'ethcd') & (df['Score[Byonic]'] != -1) & (df['PEP\\r\\n2D[Byonic]'] != -1)\n",
    "        # comparison between byonic & byos\n",
    "        byos_exclusiveOr_mask = (df['Calc.M[Byos]'] != -1) & (df['Calc.M[Byonic]'] != -1) & ((df['Calc.M[Byos]'] != df['Calc.M[Byonic]'])^(df['PureSequence[Byos]'] != df['PureSequence[Byonic]']))\n",
    "        byos_and_mask = (df['Calc.M[Byos]'] != -1) & (df['Calc.M[Byonic]'] != -1) & (df['Calc.M[Byos]'] != df['Calc.M[Byonic]']) & (df['PureSequence[Byos]'] != df['PureSequence[Byonic]'])\n",
    "        byos_bothsame_mask = (df['Calc.M[Byos]'] != -1) & (df['Calc.M[Byonic]'] != -1) & (df['Calc.M[Byos]'] == df['Calc.M[Byonic]']) & (df['PureSequence[Byos]'] == df['PureSequence[Byonic]'])\n",
    "        # record df color indices\n",
    "        lightgreen_ind = df.loc[b_hcd_mask].index.tolist()\n",
    "        df.loc[b_hcd_mask, 'ColorCode'] = 'lightgreen(%s)'%lightgreen_hex\n",
    "        \n",
    "        normalgreen_ind = df.loc[b_etd_mask].index.tolist()\n",
    "        df.loc[b_etd_mask, 'ColorCode'] = 'normalgreen(%s)'%normalgreen_hex\n",
    "        \n",
    "        lightpink_ind = df.loc[byos_exclusiveOr_mask].index.tolist()\n",
    "        \n",
    "        deeppink_ind = df.loc[byos_and_mask].index.tolist()\n",
    "        \n",
    "        yellow_ind = df.loc[byos_bothsame_mask].index.tolist()\n",
    "def bg_color(x):\n",
    "    if byonicfile != '' and byosfile != '' and pglycofile != '': # bbp all present\n",
    "        # byonic & pglyco colors\n",
    "        # HCD: light colors\n",
    "        c1 = 'background-color: %s'%lightgreen_hex \n",
    "        c2 = 'background-color: %s'%lightblue_hex \n",
    "        c3 = 'background-color: %s'%lightorange_hex \n",
    "        # ETD: normal colors\n",
    "        c4 = 'background-color: %s'%normalgreen_hex \n",
    "        c5 = 'background-color: %s'%normalblue_hex \n",
    "        c6 = 'background-color: %s'%normalorange_hex \n",
    "        # GlycanSource B+P, B/P: deep colors\n",
    "        c7 = 'background-color: %s'%darkgreen_hex \n",
    "        c8 = 'background-color: %s'%darkblue_hex \n",
    "        # byos colors\n",
    "        c9 = 'background-color: %s'%lightpink_hex \n",
    "        c10 = 'background-color: %s'%deeppink_hex\n",
    "        c11 = 'background-color: %s'%yellow_hex \n",
    "        c = '' \n",
    "        #DataFrame with same index and columns names as original filled empty strings\n",
    "        df1 =  pd.DataFrame(c, index=x.index, columns=x.columns)    \n",
    "        # byonic & byos coloring range\n",
    "        bb_range = [col for col in df1.columns.tolist() if '[Byos]' in col]\n",
    "        # byonic & pglyco coloring range\n",
    "        bp_range = [col for col in df1.columns.tolist() if '[Byonic]' in col or '[pGlyco]' in col]\n",
    "        # modify values of df1 column by boolean mask\n",
    "        # HCD: light colors (c1-c3)\n",
    "        df1.loc[b_hcd_mask, bp_range] = c1\n",
    "        print('<Color Summary>\\n%s rows will be colored light green (%s).'%(len(df1.loc[b_hcd_mask, bp_range]), lightgreen_hex))\n",
    "        df1.loc[p_hcd_mask, bp_range] = c2 \n",
    "        print('%s rows will be colored light blue (%s).'%(len(df1.loc[p_hcd_mask, bp_range]), lightblue_hex))\n",
    "        df1.loc[both_hcd_mask, bp_range] = c3\n",
    "        print('%s rows will be colored light orange (%s).'%(len(df1.loc[both_hcd_mask, bp_range]), lightorange_hex))\n",
    "        # ETD: normal colors (c4-c6)\n",
    "        df1.loc[b_etd_mask, bp_range] = c4\n",
    "        print('%s rows will be colored green (%s).'%(len(df1.loc[b_etd_mask, bp_range]), normalgreen_hex))\n",
    "        df1.loc[p_etd_mask, bp_range] = c5\n",
    "        print('%s rows will be colored blue (%s).'%(len(df1.loc[p_etd_mask, bp_range]), normalblue_hex))\n",
    "        df1.loc[both_etd_mask, bp_range] = c6\n",
    "        print('%s rows will be colored orange (%s).'%(len(df1.loc[both_etd_mask, bp_range]), normalorange_hex))\n",
    "        # GlycanSource B+P, B/P: deep colors (c7-c8)\n",
    "        df1.loc[b_glycansource_mask, bp_range] = c7\n",
    "        print('%s rows will be colored dark green (%s).'%(len(df1.loc[b_glycansource_mask, bp_range]), darkgreen_hex))\n",
    "        df1.loc[p_glycansource_mask, bp_range] = c8\n",
    "        print('%s rows will be colored dark blue (%s).'%(len(df1.loc[p_glycansource_mask, bp_range]), darkblue_hex))\n",
    "        # byos colors (c9-c11)\n",
    "        df1.loc[byos_exclusiveOr_mask, bb_range] = c9\n",
    "        print('%s rows will be colored light pink (%s).'%(len(df1.loc[byos_exclusiveOr_mask, bb_range]), lightpink_hex))\n",
    "        df1.loc[byos_and_mask, bb_range] = c10\n",
    "        print('%s rows will be colored deep pink (%s).'%(len(df1.loc[byos_and_mask, bb_range]), deeppink_hex))\n",
    "        df1.loc[byos_bothsame_mask, bb_range] = c11\n",
    "        print('%s rows will be colored yellow (%s).'%(len(df1.loc[byos_bothsame_mask, bb_range]), yellow_hex))\n",
    "        \n",
    "        bp_white = len(df1) - (len(df1.loc[b_hcd_mask, bp_range]) + len(df1.loc[p_hcd_mask, bp_range]) \\\n",
    "                          + len(df1.loc[both_hcd_mask, bp_range]) + len(df1.loc[b_etd_mask, bp_range]) + len(df1.loc[p_etd_mask, bp_range]) \\\n",
    "                          + len(df1.loc[both_etd_mask, bp_range]))\n",
    "        bb_white = len(df1) - (len(df1.loc[byos_exclusiveOr_mask, bb_range]) + len(df1.loc[byos_and_mask, bb_range]) + len(df1.loc[byos_bothsame_mask, bb_range]))\n",
    "        print('%s rows will be colorless in byonic & pglyco data.'%bp_white)\n",
    "        print('%s rows will be colorless in byos data (absent data in certain scans).'%bb_white)\n",
    "        return df1\n",
    "    elif byonicfile != '' and byosfile == '' and pglycofile != '': # byonic + pglyco\n",
    "        # byonic & pglyco colors\n",
    "        # HCD: light colors\n",
    "        c1 = 'background-color: %s'%lightgreen_hex \n",
    "        c2 = 'background-color: %s'%lightblue_hex \n",
    "        c3 = 'background-color: %s'%lightorange_hex \n",
    "        # ETD: normal colors\n",
    "        c4 = 'background-color: %s'%normalgreen_hex \n",
    "        c5 = 'background-color: %s'%normalblue_hex \n",
    "        c6 = 'background-color: %s'%normalorange_hex \n",
    "        # GlycanSource B+P, B/P: deep colors\n",
    "        c7 = 'background-color: %s'%darkgreen_hex \n",
    "        c8 = 'background-color: %s'%darkblue_hex\n",
    "        c = '' \n",
    "        #DataFrame with same index and columns names as original filled empty strings\n",
    "        df1 =  pd.DataFrame(c, index=x.index, columns=x.columns) \n",
    "        # byonic & pglyco coloring range\n",
    "        bp_range = [col for col in df1.columns.tolist() if '[Byonic]' in col or '[pGlyco]' in col]\n",
    "        # modify values of df1 column by boolean mask\n",
    "        # HCD: light colors (c1-c3)\n",
    "        df1.loc[b_hcd_mask, bp_range] = c1\n",
    "        print('<Color Summary>\\n%s rows will be colored light green (%s).'%(len(df1.loc[b_hcd_mask, bp_range]), lightgreen_hex))\n",
    "        df1.loc[p_hcd_mask, bp_range] = c2 \n",
    "        print('%s rows will be colored light blue (%s).'%(len(df1.loc[p_hcd_mask, bp_range]), lightblue_hex))\n",
    "        df1.loc[both_hcd_mask, bp_range] = c3\n",
    "        print('%s rows will be colored light orange (%s).'%(len(df1.loc[both_hcd_mask, bp_range]), lightorange_hex))\n",
    "        # ETD: normal colors (c4-c6)\n",
    "        df1.loc[b_etd_mask, bp_range] = c4\n",
    "        print('%s rows will be colored green (%s).'%(len(df1.loc[b_etd_mask, bp_range]), normalgreen_hex))\n",
    "        df1.loc[p_etd_mask, bp_range] = c5\n",
    "        print('%s rows will be colored blue (%s).'%(len(df1.loc[p_etd_mask, bp_range]), normalblue_hex))\n",
    "        df1.loc[both_etd_mask, bp_range] = c6\n",
    "        print('%s rows will be colored orange (%s).'%(len(df1.loc[both_etd_mask, bp_range]), normalorange_hex))\n",
    "        # GlycanSource B+P, B/P: deep colors (c7-c8)\n",
    "        df1.loc[b_glycansource_mask, bp_range] = c7\n",
    "        print('%s rows will be colored dark green (%s).'%(len(df1.loc[b_glycansource_mask, bp_range]), darkgreen_hex))\n",
    "        df1.loc[p_glycansource_mask, bp_range] = c8\n",
    "        print('%s rows will be colored dark blue (%s).'%(len(df1.loc[p_glycansource_mask, bp_range]), darkblue_hex))\n",
    "        \n",
    "        bp_white = len(df1) - (len(df1.loc[b_hcd_mask, bp_range]) + len(df1.loc[p_hcd_mask, bp_range]) \\\n",
    "                          + len(df1.loc[both_hcd_mask, bp_range]) + len(df1.loc[b_etd_mask, bp_range]) + len(df1.loc[p_etd_mask, bp_range]) \\\n",
    "                          + len(df1.loc[both_etd_mask, bp_range]))\n",
    "        print('%s rows will be colorless in byonic & pglyco data.'%bp_white)\n",
    "        return df1\n",
    "    elif byonicfile != '' and byosfile == '' and pglycofile == '': # only byonic\n",
    "        # byonic colors\n",
    "        # HCD: light colors\n",
    "        c1 = 'background-color: %s'%lightgreen_hex\n",
    "        # ETD: normal colors\n",
    "        c4 = 'background-color: %s'%normalgreen_hex\n",
    "        c = '' \n",
    "        #DataFrame with same index and columns names as original filled empty strings\n",
    "        df1 =  pd.DataFrame(c, index=x.index, columns=x.columns) \n",
    "        # modify values of df1 column by boolean mask\n",
    "        # HCD: light colors (c1-c3)\n",
    "        df1.loc[b_hcd_mask, :] = c1\n",
    "        print('<Color Summary>\\n%s rows will be colored light green (%s).'%(len(df1.loc[b_hcd_mask, :]), lightgreen_hex))\n",
    "        # ETD: normal colors (c4-c6)\n",
    "        df1.loc[b_etd_mask, :] = c4\n",
    "        print('%s rows will be colored green (%s).'%(len(df1.loc[b_etd_mask, :]), normalgreen_hex))\n",
    "        \n",
    "        bp_white = len(df1) - (len(df1.loc[b_hcd_mask, :]) + len(df1.loc[b_etd_mask, :]))\n",
    "        print('%s rows will be colorless in byonic data.'%bp_white)\n",
    "        return df1\n",
    "    elif byonicfile == '' and byosfile == '' and pglycofile != '': # only pglyco\n",
    "        # pglyco colors\n",
    "        # HCD: light colors\n",
    "        c2 = 'background-color: %s'%lightblue_hex\n",
    "        # ETD: normal colors\n",
    "        c5 = 'background-color: %s'%normalblue_hex\n",
    "        c = '' \n",
    "        #DataFrame with same index and columns names as original filled empty strings\n",
    "        df1 =  pd.DataFrame(c, index=x.index, columns=x.columns) \n",
    "        # modify values of df1 column by boolean mask\n",
    "        # HCD: light colors (c1-c3)\n",
    "        df1.loc[p_hcd_mask, :] = c2 \n",
    "        print('%s rows will be colored light blue (%s).'%(len(df1.loc[p_hcd_mask, :]), lightblue_hex))\n",
    "        # ETD: normal colors (c4-c6)\n",
    "        df1.loc[p_etd_mask, :] = c5\n",
    "        print('%s rows will be colored blue (%s).'%(len(df1.loc[p_etd_mask, :]), normalblue_hex))\n",
    "        \n",
    "        bp_white = len(df1) - (len(df1.loc[p_hcd_mask, :]) + len(df1.loc[p_etd_mask, :]))\n",
    "        print('%s rows will be colorless in byonic & pglyco data.'%bp_white)\n",
    "        return df1\n",
    "    elif byonicfile != '' and byosfile != '' and pglycofile == '': # byonic + byos\n",
    "        # byonic colors\n",
    "        # HCD: light colors\n",
    "        c1 = 'background-color: %s'%lightgreen_hex\n",
    "        # ETD: normal colors\n",
    "        c4 = 'background-color: %s'%normalgreen_hex\n",
    "        # byos colors\n",
    "        c9 = 'background-color: %s'%lightpink_hex \n",
    "        c10 = 'background-color: %s'%deeppink_hex\n",
    "        c11 = 'background-color: %s'%yellow_hex\n",
    "        c = '' \n",
    "        #DataFrame with same index and columns names as original filled empty strings\n",
    "        df1 =  pd.DataFrame(c, index=x.index, columns=x.columns)    \n",
    "        # byonic & byos coloring range\n",
    "        bb_range = [col for col in df1.columns.tolist() if '[Byos]' in col]\n",
    "        # byonic & pglyco coloring range\n",
    "        bp_range = [col for col in df1.columns.tolist() if '[Byonic]' in col]\n",
    "        # modify values of df1 column by boolean mask\n",
    "        # HCD: light colors (c1-c3)\n",
    "        df1.loc[b_hcd_mask, bp_range] = c1\n",
    "        print('<Color Summary>\\n%s rows will be colored light green (%s).'%(len(df1.loc[b_hcd_mask, bp_range]), lightgreen_hex))\n",
    "        # ETD: normal colors (c4-c6)\n",
    "        df1.loc[b_etd_mask, bp_range] = c4\n",
    "        print('%s rows will be colored green (%s).'%(len(df1.loc[b_etd_mask, bp_range]), normalgreen_hex))\n",
    "        # byos colors (c9-c11)\n",
    "        df1.loc[byos_exclusiveOr_mask, bb_range] = c9\n",
    "        print('%s rows will be colored light pink (%s).'%(len(df1.loc[byos_exclusiveOr_mask, bb_range]), lightpink_hex))\n",
    "        df1.loc[byos_and_mask, bb_range] = c10\n",
    "        print('%s rows will be colored deep pink (%s).'%(len(df1.loc[byos_and_mask, bb_range]), deeppink_hex))\n",
    "        df1.loc[byos_bothsame_mask, bb_range] = c11\n",
    "        print('%s rows will be colored yellow (%s).'%(len(df1.loc[byos_bothsame_mask, bb_range]), yellow_hex))\n",
    "        bp_white = len(df1) - (len(df1.loc[b_hcd_mask, bp_range]) + len(df1.loc[b_etd_mask, bp_range]))\n",
    "        bb_white = len(df1) - (len(df1.loc[byos_exclusiveOr_mask, bb_range]) + len(df1.loc[byos_and_mask, bb_range]) + len(df1.loc[byos_bothsame_mask, bb_range]))\n",
    "        print('%s rows will be colorless in byonic & pglyco data.'%bp_white)\n",
    "        print('%s rows will be colorless in byos data (absent data in certain scans).'%bb_white)\n",
    "        return df1\n",
    "    \n",
    "# PLOTTING FUNC\n",
    "def plot_clustered_stacked(dfall, nsum, labels=None, title='', neugc_exist=None, tickW=2, tickL=15, spineW=2, xlabelsize=15, ticklabelsize=15, xlabel_rotation=90, xlabelpad=5, legend_fontsize=15, legend_handleL=3, hatch_lineW=1, bar_labelpad=0, bar_labelfontsize=7):\n",
    "    # Given a list of dataframes, with identical columns and index, create a clustered stacked bar plot\n",
    "    # labels is a list of the names of the dataframe, used for the legend\n",
    "    # title is a string for the title of the plot\n",
    "    # H is the hatch used for identification of the different dataframe\n",
    "    n_df = len(dfall)\n",
    "    n_col = len(dfall[0].columns) \n",
    "    n_ind = len(dfall[0].index)\n",
    "    k = dfall[0].columns.tolist()\n",
    "    \n",
    "    # sample the colormaps\n",
    "    if neugc_exist is None: # this section caters to v1 plotting\n",
    "        # extract the largest n number in col to determine the color dict range\n",
    "        # so that the color-nnumber relation is locked\n",
    "        # n_max = ast.literal_eval(re.findall(r'N\\((\\d+)\\)', k[-1])[0])\n",
    "        n_max = 12 # default to 12 to make sure the gradients are the same across dif plots\n",
    "        b = plt.cm.Blues(np.linspace(0, 1, (n_max)))[2:] # can be more than N(10)\n",
    "    gw = plt.cm.gray(np.linspace(0, 1, 5))[-2:]\n",
    "    single_p = plt.cm.Purples(np.linspace(0, 1, 10))[5]\n",
    "    single_b = plt.cm.Blues(np.linspace(0, 1, 10))[5]\n",
    "    single_r = plt.cm.Reds(np.linspace(0, 1, 5))[3]\n",
    "    single_g = plt.cm.Greens(np.linspace(0, 1, 4))[2]\n",
    "    \n",
    "    # combine them and build a new colormap\n",
    "    if neugc_exist == True: # v2, complex+sia in red\n",
    "        colors = np.vstack((gw, single_g, single_b, single_r)) \n",
    "        # construct 1 to 1 color dict\n",
    "        n = ['N(0)', 'N(1)', 'OligoMannose', 'Complex', 'Complex+Sia'] # limited categories\n",
    "        c = [colors[i] for i in range(len(n))]\n",
    "        nc_dict = dict(zip(n, c)) # given k lst, can get v = c. v = nc_dict[k[k_cnt]]\n",
    "    elif neugc_exist == False: # v2, complex+sia in purple\n",
    "        colors = np.vstack((gw, single_g, single_b, single_p)) \n",
    "        # construct 1 to 1 color dict\n",
    "        n = ['N(0)', 'N(1)', 'OligoMannose', 'Complex', 'Complex+Sia'] # limited categories\n",
    "        c = [colors[i] for i in range(len(n))]\n",
    "        nc_dict = dict(zip(n, c)) # given k lst, can get v = c. v = nc_dict[k[k_cnt]]\n",
    "    else: # v1\n",
    "        colors = np.vstack((gw, single_g, b)) # b is unlimited cmap determined by n_max\n",
    "        # construct 1 to 1 color dict\n",
    "        n = ['N(%s)'%i for i in range(n_max+1)] # e.g. N(0)-N(10), can be more than 11 cols # unlimited categories\n",
    "        c = [colors[i] for i in range(len(n))]\n",
    "        nc_dict = dict(zip(n, c)) # given k lst, can get v = c. v = nc_dict[k[k_cnt]]\n",
    "        \n",
    "    # make tick & spine thick.\n",
    "    fig, axe = plt.subplots()\n",
    "    axes = plt.gca()\n",
    "    axes.xaxis.set_tick_params(width=tickW, length=tickL)\n",
    "    axes.yaxis.set_tick_params(width=tickW, length=tickL)\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        axes.spines[axis].set_linewidth(spineW)\n",
    "        \n",
    "    # start plotting\n",
    "    bar_label = [string.ascii_uppercase[i] for i in range(n_df)]\n",
    "    bar_label_cnt = 0\n",
    "    for df in dfall : # for each data frame\n",
    "        if 'norm' in labels[0]: # add edge to the bar\n",
    "            axe = df.plot(kind='bar', stacked=True, ax=axe, legend=False, grid=False, figsize =(20, 10), edgecolor = 'k')  # make bar plots\n",
    "        else: # sum: no edge for clarity\n",
    "            axe = df.plot(kind='bar', stacked=True, ax=axe, legend=False, grid=False, figsize =(20, 10))  # make bar plots\n",
    "    # get the y aixs range\n",
    "    ymin, ymax = axes.get_ylim()\n",
    "    # get the handles we want to modify in each site, h: 44 barcontainers, l: 4 full N(x) cols\n",
    "    h,l = axe.get_legend_handles_labels() \n",
    "    # print('h:%s\\n'%h) 44 <BarContainer object of 29 artists> \n",
    "    for i in range(0, n_df * n_col, n_col): # len(h) = n_col * n_df -> 0, 11, 22, 33\n",
    "        k_cnt = 0 # iterate thru k for rect color fix\n",
    "        for j, pa in enumerate(h[i:i+n_col]): # each pa.patches contains 29 <matplotlib.patches.Rectangle object>\n",
    "            # print('pa.patches:%s\\n'%pa.patches)\n",
    "            rect_cnt = 0\n",
    "            for rect in pa.patches: # each rect here is one single N(X) small rect of one single xicauc(int...etc) big rect. Note this loops thru the small rects spanning dif n-sites (iterate thru 29 small rects)\n",
    "                rect.set_x(rect.get_x() + 1 / float(n_df + 1) * i / float(n_col))    \n",
    "                rect.set_width(1 / float(n_df + 1))\n",
    "                axe.text(rect.get_x(), nsum[bar_label_cnt][rect_cnt] + bar_labelpad, bar_label[bar_label_cnt], ha='left', va='bottom')\n",
    "                rect.set_facecolor(nc_dict[k[k_cnt]]) # use this to fix rect color & legend\n",
    "                rect_cnt += 1\n",
    "            k_cnt += 1\n",
    "        bar_label_cnt += 1\n",
    "    \n",
    "    axe.tick_params(axis='both', labelsize=ticklabelsize)\n",
    "    axe.set_xticks((np.arange(0, 2 * n_ind, 2) + 1 / float(n_df + 1)) / 2.)\n",
    "    axe.set_xticklabels(df.index, rotation = xlabel_rotation, fontweight=\"bold\") \n",
    "    axe.set_xlabel(df.index.name, fontweight=\"bold\", fontsize = xlabelsize, labelpad = xlabelpad)\n",
    "    axe.ticklabel_format(axis='y', style='plain')\n",
    "    for label in axe.get_yticklabels():\n",
    "        label.set_fontweight('bold')\n",
    "    axe.set_title(title)\n",
    "    \n",
    "    # legend properties\n",
    "    params = {'legend.fontsize': legend_fontsize, 'legend.handlelength': legend_handleL, 'hatch.linewidth': hatch_lineW}\n",
    "    legend_properties = {'weight':'bold'}\n",
    "    plt.rcParams.update(params)\n",
    "    \n",
    "    # Add invisible data to add another legend \n",
    "    l1 = axe.legend(h[:n_col], l[:n_col], prop=legend_properties, loc=[1.01, 0.5])\n",
    "    \n",
    "    legend_elements = [] # for df legend (xicauc, int.. are from dif. df) \n",
    "    if labels is not None:      \n",
    "        for i in range(n_df):\n",
    "            label = '%s: %s'%(bar_label[i], labels[i])\n",
    "            each_bullet = Patch(label = label)\n",
    "            legend_elements.append(each_bullet)\n",
    "        plt.legend(handles=legend_elements, handlelength = 0, prop=legend_properties, loc=[1.01, 0.1]) # set handleL=0 to hide Patch\n",
    "    axe.add_artist(l1)\n",
    "    \n",
    "    return fig\n",
    "# PREPROCESSING FUNCTIONS\n",
    "def pglyco_preprocessor(pglycofile):\n",
    "    if pglycofile != '':\n",
    "        # read in pglyco as df\n",
    "        pglyco_df = pd.read_excel('%s.xlsx'%pglycofile, header = 0)\n",
    "        pglyco_df = pglyco_df.fillna('N/A')\n",
    "        pglyco_df = pglyco_df.sort_values(by=['Scan'])\n",
    "        pglyco_df = pglyco_df.reset_index(drop = True)\n",
    "\n",
    "        # output column name\n",
    "        print('Original pglyco columns:\\n%s\\n'%pglyco_df.columns)\n",
    "\n",
    "        # replace _x000D_ w/ \\r if exists\n",
    "        fixed_colname = [i.replace('_x000D_', '\\r') if '_x000D_' in i else i for i in pglyco_df.columns]\n",
    "        pglyco_df.columns = fixed_colname\n",
    "        print('Fixed pglyco columns:\\n%s\\n'%pglyco_df.columns)\n",
    "\n",
    "        # record original data size\n",
    "        print('Original pglyco data size:\\nrow: %s\\ncol: %s\\n'%(pglyco_df.shape[0], pglyco_df.shape[1]))\n",
    "\n",
    "        # change J back to N as column named peptide(J-->N)\n",
    "        pglyco_df['Peptide'] = pglyco_df['Peptide'].str.replace('J','N')\n",
    "\n",
    "        # analyze sequon in pglyco file\n",
    "        pglyco_sequon = pglyco_df['Peptide'].str.findall('(N[ARNDBCEQZGHILKMFSTWYV]T)|(N[ARNDBCEQZGHILKMFSTWYV]S)').tolist()\n",
    "        pglyco_sequon_lst = []\n",
    "        for t in pglyco_sequon:\n",
    "            t = str(t)\n",
    "            res = re.findall('[ARNDBCEQZGHILKMFSTWYVP]', t)\n",
    "            res = ''.join(res)\n",
    "            res = textwrap.wrap(res, 3)\n",
    "            if res == []:\n",
    "                pglyco_sequon_lst.append('N/A')\n",
    "            elif len(res) == 1:\n",
    "                pglyco_sequon_lst.append(res[0])\n",
    "            else:\n",
    "                pglyco_sequon_lst.append(res)\n",
    "\n",
    "        pglyco_sequon_lst = [tuple(i) if type(i) == list else i for i in pglyco_sequon_lst]\n",
    "        pglyco_df.insert(pglyco_df.columns.get_loc('Peptide') + 1 , 'Sequon', pglyco_sequon_lst , True)\n",
    "\n",
    "        # replace H, N, A, F, G symbols w/ Hex, HexNAc, NeuAc, Fuc, NeuGc\n",
    "        byonicstyle = []\n",
    "        if 'Glycan(H,N,A,G,F)' in pglyco_df.columns:\n",
    "            glycan_num = pglyco_df['Glycan(H,N,A,G,F)'].tolist()\n",
    "            for i in glycan_num:\n",
    "                i = i.split(' ')\n",
    "                new_order = [1, 0, 4, 2, 3]\n",
    "                i = [i[x] for x in new_order]\n",
    "                if i[0] != '0':\n",
    "                    n = 'HexNAc(%s)'%(i[0])\n",
    "                else :\n",
    "                    n = ''\n",
    "                if i[1] != '0':\n",
    "                    h = 'Hex(%s)'%(i[1])\n",
    "                else:\n",
    "                    h = ''\n",
    "                if i[2] != '0':\n",
    "                    f = 'Fuc(%s)'%(i[2])\n",
    "                else:\n",
    "                    f = ''\n",
    "                if i[3] != '0':\n",
    "                    a = 'NeuAc(%s)'%(i[3])\n",
    "                else:\n",
    "                    a = ''\n",
    "                if i[4] != '0':\n",
    "                    g = 'NeuGc(%s)'%(i[4])\n",
    "                else:\n",
    "                    g = ''\n",
    "                each_byonicstyle = n + h + f + a + g\n",
    "                byonicstyle.append(each_byonicstyle)\n",
    "        elif 'Glycan(H,N,A,F)' in pglyco_df.columns:\n",
    "            glycan_num = pglyco_df['Glycan(H,N,A,F)'].tolist()\n",
    "            for i in glycan_num:\n",
    "                i = i.split(' ')\n",
    "                new_order = [1, 0, 3, 2]\n",
    "                i = [i[x] for x in new_order]\n",
    "                if i[0] != '0':\n",
    "                    n = 'HexNAc(%s)'%(i[0])\n",
    "                else :\n",
    "                    n = ''\n",
    "                if i[1] != '0':\n",
    "                    h = 'Hex(%s)'%(i[1])\n",
    "                else:\n",
    "                    h = ''\n",
    "                if i[2] != '0':\n",
    "                    f = 'Fuc(%s)'%(i[2])\n",
    "                else:\n",
    "                    f = ''\n",
    "                if i[3] != '0':\n",
    "                    a = 'NeuAc(%s)'%(i[3])\n",
    "                else:\n",
    "                    a = ''\n",
    "                each_byonicstyle = n + h + f + a\n",
    "                byonicstyle.append(each_byonicstyle)\n",
    "        elif 'Glycan(H,N,F,A)' in pglyco_df.columns:\n",
    "            glycan_num = pglyco_df['Glycan(H,N,F,A)'].tolist()\n",
    "            for i in glycan_num:\n",
    "                i = i.split(' ')\n",
    "                new_order = [1, 0, 2, 3]\n",
    "                i = [i[x] for x in new_order]\n",
    "                if i[0] != '0':\n",
    "                    n = 'HexNAc(%s)'%(i[0])\n",
    "                else :\n",
    "                    n = ''\n",
    "                if i[1] != '0':\n",
    "                    h = 'Hex(%s)'%(i[1])\n",
    "                else:\n",
    "                    h = ''\n",
    "                if i[2] != '0':\n",
    "                    f = 'Fuc(%s)'%(i[2])\n",
    "                else:\n",
    "                    f = ''\n",
    "                if i[3] != '0':\n",
    "                    a = 'NeuAc(%s)'%(i[3])\n",
    "                else:\n",
    "                    a = ''\n",
    "                each_byonicstyle = n + h + f + a\n",
    "                byonicstyle.append(each_byonicstyle)\n",
    "        else:\n",
    "            sys.exit('Please check if there are glycans other than H, N, A, G, F or if column name has changed. This app will stop.')\n",
    "        pglyco_df.insert(pglyco_df.columns.get_loc('GlycanComposition') + 1 , 'GlycanComposition_ByonicStyle', byonicstyle , True)\n",
    "\n",
    "        # if the etdscan is not -1, duplicate the row and change the duplicated scan to etdscan (micmic byonic format)\n",
    "        pglyco_df.insert(pglyco_df.columns.get_loc('Scan') + 1 , 'FragmentType', 'hcd' , True) # insert 'fragment type' col\n",
    "        row_to_duplicate = pglyco_df[pglyco_df['ETDScan'] != -1].copy() # missing ETDScan in pglyco is represented as -1\n",
    "        row_to_duplicate['FragmentType'] = 'ethcd'\n",
    "        row_to_duplicate['Scan'] = row_to_duplicate['ETDScan']\n",
    "        pglyco_df = pd.concat([pglyco_df, row_to_duplicate]) # duplicate w/ index\n",
    "        pglyco_df = pglyco_df.sort_values(by = ['Scan']) # sort by scan directly, the duplicated ethcd rows can be separated from hcd rows\n",
    "        print('----- pGlyco data preprocessing completed. -----\\n')\n",
    "        return pglyco_df\n",
    "\n",
    "def byonic_preprocessor(byonicfile):\n",
    "    if byonicfile != '':\n",
    "        byonic_df = pd.read_excel('%s.xlsx'%byonicfile, header = 0)\n",
    "        byonic_df = byonic_df.fillna('N/A')\n",
    "        print('Original byonic columns:\\n%s\\n'%byonic_df.columns)\n",
    "        # replace _x000D_ w/ \\r if exists\n",
    "        fixed_colname = [i.replace('_x000D_', '\\r') if '_x000D_' in i else i for i in byonic_df.columns]\n",
    "        byonic_df.columns = fixed_colname\n",
    "        print('Fixed byonic columns:\\n%s\\n'%byonic_df.columns)\n",
    "        # record original data size\n",
    "        print('Original byonic data size:\\nrow: %s\\ncol: %s\\n'%(byonic_df.shape[0], byonic_df.shape[1]))\n",
    "        # extract 'scan' from 'scan #' in byonic file & add a 'Scan' column\n",
    "        byonic_scan = byonic_df['Scan #'].tolist()\n",
    "        byonic_scan_lst = []\n",
    "        for scan in byonic_scan:\n",
    "            scan = scan.split(' ')[-1].split('=')[-1]\n",
    "            scan = int(scan)\n",
    "            byonic_scan_lst.append(scan)\n",
    "        byonic_df.insert(byonic_df.columns.get_loc('Scan\\r\\nTime') + 1 , 'Scan', byonic_scan_lst , True)\n",
    "        byonic_df = byonic_df.sort_values(by = ['Scan'])\n",
    "        byonic_df = byonic_df.reset_index(drop = True)\n",
    "        # add 'PureSequence' column to byonic file\n",
    "        if 'Sequence\\r\\n(unformatted)' in byonic_df.columns: # deal w/ dif byonic version\n",
    "            byonic_seq = byonic_df['Sequence\\r\\n(unformatted)'].str[2:-2].str.findall('[-ARNDBCEQZGHILKMFSTWYVP]').tolist()\n",
    "            byonic_seq = [''.join(each_pure) for each_pure in byonic_seq]\n",
    "            byonic_df.insert(byonic_df.columns.get_loc('Sequence\\r\\n(unformatted)') + 1 , 'PureSequence', byonic_seq , True)\n",
    "            byonic_seq_forSequonNsite = byonic_df['Sequence\\r\\n(unformatted)'].str.findall('[-ARNDBCEQZGHILKMFSTWYVP]').tolist()\n",
    "            byonic_seq_forSequonNsite = [''.join(each_pure) for each_pure in byonic_seq_forSequonNsite]\n",
    "            byonic_seq_forSequonNsite = pd.Series(byonic_seq_forSequonNsite) # preserve aa outside dots\n",
    "        elif 'Sequence' in byonic_df.columns:\n",
    "            byonic_seq = byonic_df['Sequence'].str[2:-2].str.findall('[-ARNDBCEQZGHILKMFSTWYVP]').tolist()  \n",
    "            byonic_seq = [''.join(each_pure) for each_pure in byonic_seq]\n",
    "            byonic_df.insert(byonic_df.columns.get_loc('Sequence') + 1 , 'PureSequence', byonic_seq , True)\n",
    "            byonic_seq_forSequonNsite = byonic_df['Sequence'].str.findall('[-ARNDBCEQZGHILKMFSTWYVP]').tolist()\n",
    "            byonic_seq_forSequonNsite = [''.join(each_pure) for each_pure in byonic_seq_forSequonNsite]\n",
    "            byonic_seq_forSequonNsite = pd.Series(byonic_seq_forSequonNsite)\n",
    "        else:\n",
    "            sys.exit('Please check if sequence column name has changed. This app will stop.')  \n",
    "        # add 'Sequon' & 'N-site' column to byonic file\n",
    "        byonic_sequon_lst = []\n",
    "        n_site_lst = []\n",
    "        pureseq_cnt = 0 # this is byonic_seq_forSequonNsite\n",
    "        pos = byonic_df['Pos.'].tolist()\n",
    "        pos_cnt = 0\n",
    "        byonic_sequon = byonic_seq_forSequonNsite.str.findall('(N[ARNDBCEQZGHILKMFSTWYV]T)|(N[ARNDBCEQZGHILKMFSTWYV]S)').tolist()\n",
    "        for t in byonic_sequon:\n",
    "            t = str(t)\n",
    "            res = re.findall('[ARNDBCEQZGHILKMFSTWYVP]', t)\n",
    "            res = ''.join(res)\n",
    "            res = textwrap.wrap(res, 3)\n",
    "            if res == []:\n",
    "                byonic_sequon_lst.append('N/A')\n",
    "                n_site_lst.append('N/A')\n",
    "                pureseq_cnt += 1\n",
    "                pos_cnt += 1\n",
    "            elif len(res) == 1: # single sequon -> single n-site\n",
    "                byonic_sequon_lst.append(res[0])\n",
    "                regex = re.compile(r'(' + '|'.join(res) + r')')\n",
    "                each_n_site_pos = [m.start() for m in regex.finditer(byonic_seq_forSequonNsite[pureseq_cnt])][0]\n",
    "                each_n_site = pos[pos_cnt] -1 + each_n_site_pos # -1 to fix the 'dots problem'\n",
    "                n_site_lst.append(each_n_site)\n",
    "                pureseq_cnt += 1\n",
    "                pos_cnt += 1\n",
    "            else: # non-single sequon\n",
    "                byonic_sequon_lst.append(res)\n",
    "                regex = re.compile(r'(' + '|'.join(res) + r')')\n",
    "                each_n_site_pos = [m.start() for m in regex.finditer(byonic_seq_forSequonNsite[pureseq_cnt])]\n",
    "                each_n_site = list(pos[pos_cnt] -1 + np.array(each_n_site_pos))\n",
    "                n_site_lst.append(each_n_site)\n",
    "                pureseq_cnt += 1\n",
    "                pos_cnt += 1\n",
    "        # convert lists within list to tuple for later usage ('cos lists are unhashable, which may cause some problems later)\n",
    "        byonic_sequon_lst = [tuple(i) if type(i) == list else i for i in byonic_sequon_lst]\n",
    "        n_site_lst = [tuple(i) if type(i) == list else i for i in n_site_lst]\n",
    "        byonic_df.insert(byonic_df.columns.get_loc('PureSequence') + 1 , 'Sequon', byonic_sequon_lst , True)\n",
    "        byonic_df.insert(0, 'N-site(SequonBased)', n_site_lst , True)\n",
    "        # ONLY FOR HCD//ETD FILES: add N/A col 'Pair' for later modification (pair: cal.m/z same, cal.m same, pureseq same, scan difference <= 5, hcd before ethcd)\n",
    "        if 'ethcd' in byonic_df['Fragment\\r\\nType'].tolist():\n",
    "            byonic_df.insert(byonic_df.columns.get_loc('Scan\\r\\nTime') + 1 , 'Pair', 'N/A' , True)\n",
    "            # potential_pair = byonic_df[['Calc.\\r\\nm/z', 'Calc.\\r\\nMH', 'PureSequence']][byonic_df.duplicated(subset=['Calc.\\r\\nm/z', 'Calc.\\r\\nMH', 'PureSequence'], keep=False)]\n",
    "            potential_pair = byonic_df[byonic_df.duplicated(subset=['Calc.\\r\\nm/z', 'Calc.M', 'PureSequence'], keep=False)].sort_values(['Calc.\\r\\nm/z'])\n",
    "            # print(potential_pair)\n",
    "            mz_gp = sorted(list(set(potential_pair['Calc.\\r\\nm/z'].tolist())))\n",
    "            pair_cnt = 0\n",
    "            all_hcd_ind = []\n",
    "            all_etd_ind = []\n",
    "            for i in mz_gp:\n",
    "                gp = potential_pair[potential_pair['Calc.\\r\\nm/z'] == i][potential_pair.duplicated(subset=['Calc.M', 'PureSequence'], keep=False)]\n",
    "                gp = gp.sort_values(['Scan'])\n",
    "                # skip the gp w/o ethcd & find pairs: last criterion -> scan dif <= 5\n",
    "                if 'hcd' in gp['Fragment\\r\\nType'].tolist() and 'ethcd' in gp['Fragment\\r\\nType'].tolist():\n",
    "                    # from hcd find the nearest ethcd below\n",
    "                    pair_candidate = gp[(gp['Fragment\\r\\nType'] == 'hcd') & (gp['Fragment\\r\\nType'].shift(-1) == 'ethcd') & (gp['Scan'].shift(-1) - gp['Scan'] <= byonic_scandif)]\n",
    "                    hcd_iloc = [gp.index.get_loc(ind) for ind in pair_candidate.index] # get the positions of the hcd in pairs in gp df\n",
    "                    etd_iloc = list(np.array(hcd_iloc) + 1)\n",
    "                    hcd_ind = pair_candidate.index.tolist()\n",
    "                    etd_ind = [gp.index[i] for i in etd_iloc] \n",
    "                    all_hcd_ind.extend(hcd_ind)\n",
    "                    all_etd_ind.extend(etd_ind)\n",
    "                else:\n",
    "                    pass\n",
    "            all_hcd_ind.sort()\n",
    "            all_etd_ind.sort()\n",
    "            byonic_df['Pair'].iloc[all_hcd_ind] = ['pair%s'%(i+1) for i in range(len(all_hcd_ind))]\n",
    "            byonic_df['Pair'].iloc[all_etd_ind] = ['pair%s'%(i+1) for i in range(len(all_etd_ind))]\n",
    "        else:\n",
    "            pass\n",
    "        print('----- Byonic data preprocessing completed. -----\\n')\n",
    "        return byonic_df\n",
    "\n",
    "def byos_preprocessor(byosfile):\n",
    "    if byosfile != '':\n",
    "        byos_df = pd.read_excel('%s.xlsx'%byosfile, header = 0)\n",
    "        # output column name\n",
    "        print('Original byos columns:\\n%s\\n'%byos_df.columns)\n",
    "        # replace _x000D_ w/ \\r if exists\n",
    "        fixed_colname = [i.replace('_x000D_', '\\r') if '_x000D_' in i else i for i in byos_df.columns]\n",
    "        byos_df.columns = fixed_colname\n",
    "        print('Fixed byos columns:\\n%s\\n'%byos_df.columns)\n",
    "        # extract needed columns: Scan Number(s)(Posit), MS Alias name, XIC area summed, XIC AUC, Apex Int.(Posit), Calc.M, Sequence\n",
    "        byos_df = byos_df[['Scan Number(s)\\r\\n(Posit)', 'Glycans', 'MS2 Search\\r\\nAlias name', 'XIC area\\r\\nsummed', 'XIC\\r\\nAUC', 'Apex Int.\\r\\n(Posit)', 'Calc.M', 'Sequence']]\n",
    "        byos_df = byos_df.fillna('N/A')\n",
    "        # output extracted column name\n",
    "        print('Extracted byos columns:\\n%s\\n'%byos_df.columns)\n",
    "        # drop the row w/ multiple scan numbers (data type would be str)\n",
    "        byos_df = byos_df[byos_df['Scan Number(s)\\r\\n(Posit)'].apply(lambda x: isinstance(x, int))]\n",
    "        # sort byos by scan\n",
    "        byos_df = byos_df.sort_values(by=['Scan Number(s)\\r\\n(Posit)'])\n",
    "        byos_df = byos_df.reset_index(drop = True)\n",
    "        # add 'PureSequence' col\n",
    "        byos_df['Sequence'] = byos_df['Sequence'].str.upper()\n",
    "        byos_df['PureSequence'] = byos_df['Sequence'].str[2:-2]\n",
    "        # display(HTML(byos_df.to_html()))\n",
    "        print('----- Byos data preprocessing completed. -----\\n')\n",
    "        return byos_df\n",
    "\n",
    "# MAIN PROCESSING FUNC\n",
    "def main():\n",
    "    # TIMESTAMP\n",
    "    start_time = time.time()\n",
    "    # CURRENT DATE\n",
    "    date = datetime.now().strftime('%Y%m%d')\n",
    "    # PREPARE EXPORT FILENAME\n",
    "    filename = export_filename(byonicfile, byosfile, pglycofile)\n",
    "    # FILE PREPROCESSING\n",
    "    byonic_df = byonic_preprocessor(byonicfile)\n",
    "    byos_df =  byos_preprocessor(byosfile)\n",
    "    pglyco_df = pglyco_preprocessor(pglycofile)\n",
    "    # INPUT COMBO CONTROL FLOW\n",
    "    if byonicfile != '' and byosfile != '' and pglycofile != '': # bbp all present\n",
    "        print('----- Start combining Byonic & Byos & pGlyco. -----\\n')\n",
    "        # combined data based on 'Scan'\n",
    "        byonic_scanasid = byonic_df.copy()\n",
    "        new_byonic_col = [n + '[Byonic]' if n != 'Scan' else n for n in byonic_scanasid.columns]\n",
    "        byonic_scanasid.columns = new_byonic_col\n",
    "        pglyco_scanasid = pglyco_df.copy()\n",
    "        new_pglyco_col = [n + '[pGlyco]' if n != 'Scan' else n for n in pglyco_scanasid.columns]\n",
    "        pglyco_scanasid.columns = new_pglyco_col\n",
    "        byos_scanasid = byos_df.copy()\n",
    "        new_byos_col = [n + '[Byos]' if n != 'Scan Number(s)\\r\\n(Posit)' else n for n in byos_scanasid.columns]\n",
    "        byos_scanasid.columns = new_byos_col\n",
    "        byonic_scanasid = byonic_scanasid.set_index('Scan')\n",
    "        pglyco_scanasid = pglyco_scanasid.set_index('Scan')\n",
    "        byos_scanasid = byos_scanasid.set_index('Scan Number(s)\\r\\n(Posit)')\n",
    "        # align scan & concat (all align on row to make row number all the same)\n",
    "        a1, a2 = byonic_scanasid.align(pglyco_scanasid, join = 'outer', axis = 0) # row: a1 = a2\n",
    "        a1, a3 = a1.align(byos_scanasid, join = 'outer', axis = 0) # row: a1 = a2 = a3\n",
    "        a2, a3 = a2.align(byos_scanasid, join = 'outer', axis = 0) # row: a2 = a1 = a3\n",
    "        all_combined_df = pd.concat([a1,a3,a2], axis = 1)\n",
    "        all_combined_df.index.name = 'Scan'\n",
    "        all_combined_df.reset_index(level=0, inplace=True)\n",
    "        # change all nan to blank -1\n",
    "        all_combined_df = all_combined_df.fillna(-1)\n",
    "        move_df(all_combined_df, 'ProSites[pGlyco]', 'N-site(SequonBased)[Byonic]')\n",
    "        ## result post-processing \n",
    "        glycansource(all_combined_df, 'Scan')\n",
    "        print('\\nCombined data shape:\\nrow --> %s, column --> %s'%(all_combined_df.shape[0], all_combined_df.shape[1]))\n",
    "        ## style apply for excel export\n",
    "        # color the rows below the threshold (threshold [byonic: score > 200 & pep2d < 0.001; pglyco: PepScore>5 & GlyScore>4])\n",
    "        # color code => #ffedcc -> light orange for byonic; #add8e6 -> light blue for pglyco; #FFB6C1 -> light pink for byos w/ dif calm ^ seq from byonic; #FF1493 -> deep pink for byos w/ dif calm & seq from byonic; #FFFF00 -> yellow for byos & byonic all the same\n",
    "        threshold_masks_colorind(all_combined_df)\n",
    "        # analyze PSM (need to pass threshold)\n",
    "        byonic_colored_id = list(set(lightgreen_ind + normalgreen_ind + lightorange_ind + normalorange_ind + deepgreen_ind)) # byonic pass threshold\n",
    "        byonic_belowthreshold_id = [i for i in all_combined_df.index.tolist() if i not in byonic_colored_id]\n",
    "        pglyco_colored_id = list(set(lightblue_ind + normalblue_ind + lightorange_ind + normalorange_ind + deepblue_ind)) # pglyco pass threshold\n",
    "        pglyco_belowthreshold_id = [i for i in all_combined_df.index.tolist() if i not in pglyco_colored_id]\n",
    "        # using groupby size function to count psm & add psm columns (new criterion: RT/scantime dif < 3 min (180s). is regarded as the same, >= 3 min. should be seen as dif)\n",
    "        # byonic & byos\n",
    "        all_combined_df = all_combined_df.astype({'N-site(SequonBased)[Byonic]': 'str'}) # convert list & tuple to str for later groupby function\n",
    "        all_combined_df['to_subtract[Byonic]'] = all_combined_df.loc[all_combined_df.groupby(['N-site(SequonBased)[Byonic]', 'Calc.\\r\\nm/z[Byonic]','Glycans[Byonic]', 'PureSequence[Byonic]'])['Score[Byonic]'].idxmax(), 'Scan\\r\\nTime[Byonic]'] # get the rt of highest score as ref for rt_dif < 3 min.\n",
    "        all_combined_df['to_subtract_fillna[Byonic]'] = all_combined_df.groupby(['N-site(SequonBased)[Byonic]', 'Calc.\\r\\nm/z[Byonic]','Glycans[Byonic]', 'PureSequence[Byonic]'])['to_subtract[Byonic]'].transform(lambda x: x.fillna(x.mean())) # fillna w/ rt of highest score\n",
    "        all_combined_df['rt_dif[Byonic]'] = (all_combined_df['Scan\\r\\nTime[Byonic]'] - all_combined_df['to_subtract_fillna[Byonic]']).abs() # get absolute dif\n",
    "        all_combined_df['rt_dif_reset[Byonic]'] = [0 if dif < byonic_rt else dif for dif in all_combined_df['rt_dif[Byonic]']] # if rt_dif < 3, then reset the dif to 0 -> seen as the same\n",
    "        byonic_psm = all_combined_df.groupby(['N-site(SequonBased)[Byonic]', 'Calc.\\r\\nm/z[Byonic]','Glycans[Byonic]', 'PureSequence[Byonic]', 'rt_dif_reset[Byonic]'])['N-site(SequonBased)[Byonic]'].transform('size')\n",
    "        all_combined_df.insert(all_combined_df.columns.get_loc('N-site(SequonBased)[Byonic]') + 1 , 'PSM[Byonic]', byonic_psm , True)\n",
    "        all_combined_df.loc[(all_combined_df['N-site(SequonBased)[Byonic]'] == 'N/A'), 'PSM[Byonic]'] = 'N/A' # if n-site is 'N/A', do not count psm\n",
    "        all_combined_df.loc[byonic_belowthreshold_id, 'PSM[Byonic]'] = 'N/A' # do not count psm for rows below threshold\n",
    "        all_combined_df.loc[(all_combined_df['N-site(SequonBased)[Byonic]'] == '-1'), 'PSM[Byonic]'] = -1 # if site is '-1', then psm set to -1\n",
    "        # pglyco\n",
    "        all_combined_df = all_combined_df.astype({'ProSites[pGlyco]': 'int'})\n",
    "        all_combined_df = all_combined_df.astype({'ProSites[pGlyco]': 'str'}) # convert list & tuple to str for later groupby function\n",
    "        all_combined_df['to_subtract[pGlyco]'] = all_combined_df.loc[all_combined_df.groupby(['ProSites[pGlyco]', 'PrecursorMZ[pGlyco]','GlycanComposition_ByonicStyle[pGlyco]', 'Peptide[pGlyco]'])['GlyScore[pGlyco]'].idxmax(), 'RT[pGlyco]'] # get the rt of highest score as ref for rt_dif < 3 min.\n",
    "        all_combined_df['to_subtract_fillna[pGlyco]'] = all_combined_df.groupby(['ProSites[pGlyco]', 'PrecursorMZ[pGlyco]','GlycanComposition_ByonicStyle[pGlyco]', 'Peptide[pGlyco]'])['to_subtract[pGlyco]'].transform(lambda x: x.fillna(x.mean())) # fillna w/ rt of highest score\n",
    "        all_combined_df['rt_dif[pGlyco]'] = (all_combined_df['RT[pGlyco]'] - all_combined_df['to_subtract_fillna[pGlyco]']).abs() # get absolute dif\n",
    "        all_combined_df['rt_dif_reset[pGlyco]'] = [0 if dif < pglyco_rt else dif for dif in all_combined_df['rt_dif[pGlyco]']] # if rt_dif < 3, then reset the dif to 0 -> seen as the same\n",
    "        pglyco_psm = all_combined_df.groupby(['ProSites[pGlyco]', 'PrecursorMZ[pGlyco]','GlycanComposition_ByonicStyle[pGlyco]', 'Peptide[pGlyco]', 'rt_dif_reset[pGlyco]'])['ProSites[pGlyco]'].transform('size')\n",
    "        all_combined_df.insert(all_combined_df.columns.get_loc('ProSites[pGlyco]') + 1 , 'PSM[pGlyco]', pglyco_psm , True)\n",
    "        all_combined_df.loc[(all_combined_df['ProSites[pGlyco]'] == 'N/A'), 'PSM[pGlyco]'] = 'N/A' # if n-site is 'N/A', do not count psm\n",
    "        all_combined_df.loc[pglyco_belowthreshold_id, 'PSM[pGlyco]'] = 'N/A' # do not count psm for rows below threshold\n",
    "        all_combined_df.loc[(all_combined_df['ProSites[pGlyco]'] == '-1'), 'PSM[pGlyco]'] = -1 # if site is '-1', then psm set to -1\n",
    "        all_forsimple_df = all_combined_df.copy() # to retain rt_dif_reset for simple df groupy and get unique row\n",
    "        all_combined_df = all_combined_df.drop(['to_subtract[Byonic]', 'to_subtract_fillna[Byonic]', 'rt_dif[Byonic]', 'rt_dif_reset[Byonic]', 'to_subtract[pGlyco]', 'to_subtract_fillna[pGlyco]', 'rt_dif[pGlyco]', 'rt_dif_reset[pGlyco]'], axis = 1) # drop the intermediate cols\n",
    "\n",
    "        print('\\n----- Exporting \"_All\" file... This may take some time, please wait. -----\\n')\n",
    "        all_combined_df.style.apply(bg_color, axis=None).to_excel(f'{date}_{filename}_All.xlsx', index = False)  \n",
    "        print('\\n----- \"_All\" file exported. -----\\n')\n",
    "        \n",
    "        if 'Pair[Byonic]' in all_combined_df.columns.tolist():\n",
    "            # ONLY FOR HCD/ETD FILES: prepare '_Pair' file (as long as byonic passes threshold & have pair)\n",
    "            all_combined_df = all_combined_df.astype({'Pair[Byonic]': 'str'})\n",
    "            pair_df = all_combined_df.loc[byonic_colored_id]\n",
    "            pair_df = pair_df[pair_df['Pair[Byonic]'].str.contains('pair')]\n",
    "            pair_df = pair_df[pair_df.duplicated(subset=['Pair[Byonic]'], keep=False)] # only paired data included in _Pair\n",
    "            threshold_masks_colorind(pair_df)\n",
    "            print('\\n----- Exporting \"_Pair\" file... This may take some time, please wait. -----\\n')\n",
    "            pair_df.style.apply(bg_color, axis=None).to_excel(f'{date}_{filename}_Pair.xlsx', index = False)  \n",
    "            print('\\n----- \"_Pair\" file exported. -----\\n')\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        print('----- Start preparing simplified version. -----\\n')\n",
    "        # extract rows included in colored indices list separately\n",
    "        byonicbyos_col_range = ['Scan'] + [col for col in all_forsimple_df.columns.tolist() if '[Byonic]' in col or '[Byos]' in col]\n",
    "        pglyco_col_range = ['Scan'] + [col for col in all_forsimple_df.columns.tolist() if '[pGlyco]' in col]\n",
    "        simple_byonicbyos = all_forsimple_df.loc[byonic_colored_id, byonicbyos_col_range] # extract colored (pass threshold) rows\n",
    "        simple_pglyco = all_forsimple_df.loc[pglyco_colored_id, pglyco_col_range] # extract colored (pass threshold) rows\n",
    "        # prepare uniquepep first (also contains rows w/o n-sites, i.e. w/o sequon)\n",
    "#         simple_byonicbyos_unique = simple_byonicbyos.copy() # for _UniquePep file, sequon can be igonored. rows w/o n sequon will be included.\n",
    "#         simple_pglyco_unique = simple_pglyco.copy() # for _UniquePep file, sequon can be igonored. rows w/o n sequon will be included.\n",
    "#         simple_pglyco_unique = simple_pglyco_unique.loc[simple_pglyco['FragmentType[pGlyco]'] == 'hcd'] # pglyco etd has the same values as hcd, so only let hcd enter unique file\n",
    "        \n",
    "        \n",
    "        # then prepare nglycopep containing rows all w/ n-site\n",
    "        simple_byonicbyos = simple_byonicbyos[(simple_byonicbyos['N-site(SequonBased)[Byonic]'] != 'N/A')&(simple_byonicbyos['N-site(SequonBased)[Byonic]'] != '-1')] # for simplified, n-site must exist\n",
    "        simple_pglyco = simple_pglyco[(simple_pglyco['ProSites[pGlyco]'] != 'N/A')&(simple_pglyco['ProSites[pGlyco]'] != '-1')] # for simplified, n-site must exist\n",
    "        simple_pglyco = simple_pglyco.loc[simple_pglyco['FragmentType[pGlyco]'] == 'hcd'] # pglyco etd has the same values as hcd, so only let hcd enter unique file\n",
    "        # get unique calc.m/z by groupby & idxmax function to find highest score within each gp and preserve (remember to split the simple_df into byonicbyos & pglyco parts to avoid dropping non-target rows)\n",
    "        simple_byonicbyos = simple_byonicbyos.groupby(['N-site(SequonBased)[Byonic]', 'Calc.\\r\\nm/z[Byonic]','Glycans[Byonic]', 'PureSequence[Byonic]', 'rt_dif_reset[Byonic]'], as_index=False).apply(lambda x: x.loc[x['Score[Byonic]'].idxmax()]).reset_index(drop=True)\n",
    "        simple_pglyco = simple_pglyco.groupby(['ProSites[pGlyco]', 'PrecursorMZ[pGlyco]','GlycanComposition_ByonicStyle[pGlyco]', 'Peptide[pGlyco]', 'rt_dif_reset[pGlyco]'], as_index=False).apply(lambda x: x.loc[x['GlyScore[pGlyco]'].idxmax()]).reset_index(drop=True)\n",
    "\n",
    "        # set scan to index & concat simple_byonicbyos & simple_pglyco by scan\n",
    "        simple_byonicbyos = simple_byonicbyos.set_index('Scan')\n",
    "        simple_pglyco = simple_pglyco.set_index('Scan')\n",
    "        a1, a2 = simple_byonicbyos.align(simple_pglyco, join = 'outer', axis = 0) # row: a1 = a2\n",
    "        id_df = pd.concat([a1,a2], axis = 1)\n",
    "        id_df.index.name = 'Scan'\n",
    "        id_df.reset_index(level=0, inplace=True)\n",
    "        # change all nan to blank -1\n",
    "        id_df = id_df.fillna(-1)\n",
    "        # extract nglycan numbers in Mods & use it to calculate byonic pep mass \n",
    "        mods_nglycan_sum = [sum([ast.literal_eval(v) for v in lst]) if type(lst) == list else -1 for lst in id_df['Mods\\r\\n(variable)[Byonic]'].str.findall(r'Glycan / (\\d+.\\d+)').tolist()]\n",
    "        id_df['glycan_mods_sum[Byonic]'] = mods_nglycan_sum\n",
    "        id_df['PepMS[Byonic]'] = id_df['Calc.\\r\\nMH[Byonic]'] - id_df['glycan_mods_sum[Byonic]']\n",
    "        id_df.loc[(id_df['glycan_mods_sum[Byonic]'] == -1), 'PepMS[Byonic]'] = -1\n",
    "        move_df(id_df, 'ProSites[pGlyco]', 'N-site(SequonBased)[Byonic]')\n",
    "        move_df(id_df, 'PepMS[Byonic]', 'Fragment\\r\\nType[Byonic]')\n",
    "        # ast.literaleval byonicbyos n-site & sorting: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic clam/z -> pglcyo calm/z\n",
    "        id_df['N-site(SequonBased)[Byonic]'] = [ast.literal_eval(i) if type(i) == str and '(' not in i else i for i in id_df['N-site(SequonBased)[Byonic]'].tolist()] # convert str back to int & tuple\n",
    "        id_df['ProSites[pGlyco]'] = [ast.literal_eval(i) if type(i) == str and '(' not in i else i for i in id_df['ProSites[pGlyco]'].tolist()] # convert str back to int & tuple\n",
    "        \n",
    "        id_df.loc[(id_df['N-site(SequonBased)[Byonic]'] == -1), 'mock_site[Byonic]'] = id_df['ProSites[pGlyco]']\n",
    "        id_df.loc[(id_df['N-site(SequonBased)[Byonic]'] != -1), 'mock_site[Byonic]'] = id_df['N-site(SequonBased)[Byonic]']\n",
    "        # drop intermediate cols\n",
    "        id_df = id_df.drop(['to_subtract[Byonic]', 'to_subtract_fillna[Byonic]', 'rt_dif[Byonic]', 'rt_dif_reset[Byonic]', 'to_subtract[pGlyco]', 'to_subtract_fillna[pGlyco]', 'rt_dif[pGlyco]', 'rt_dif_reset[pGlyco]', 'glycan_mods_sum[Byonic]'], axis = 1) # drop the intermediate cols\n",
    "        glycansource(id_df, 'Scan')\n",
    "        move_df(id_df, 'mock_site[Byonic]', 'GlycanSource')\n",
    "        col_order = id_df.columns.tolist()\n",
    "        # sorting order: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic calm/z -> pglcyo calm/z => all of this can be acheive with sort_values to multi cols.\n",
    "\n",
    "        id_df = sort_intstr_col(id_df, 'Charge[pGlyco]')\n",
    "        print('Done sorting by Charge[pGlyco] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'PrecursorMH[pGlyco]')\n",
    "        print('Done sorting by PrecursorMH[pGlyco] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'PeptideMH[pGlyco]')\n",
    "        print('Done sorting by PeptideMH[pGlyco] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'GlycanComposition_ByonicStyle[pGlyco]')\n",
    "        print('Done sorting by GlycanComposition_ByonicStyle[pGlyco] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'Peptide[pGlyco]')\n",
    "        print('Done sorting by Peptide[pGlyco] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'z[Byonic]')\n",
    "        print('Done sorting by z[Byonic] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'Calc.\\r\\nMH[Byonic]')\n",
    "        print('Done sorting by Calc.MH[Byonic] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'PepMS[Byonic]')\n",
    "        print('Done sorting by PepMS[Byonic] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'Glycans[Byonic]')\n",
    "        print('Done sorting by Glycans[Byonic] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'PureSequence[Byonic]')\n",
    "        print('Done sorting by PureSequence[Byonic] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'mock_site[Byonic]')\n",
    "        print('Done sorting by mock_site[Byonic] (added during processing)')\n",
    "\n",
    "        # convert '-1' back to int -1 for correct glycansource analysis\n",
    "        id_df['Glycans[Byonic]'] = [int(i) if i == '-1' else i for i in id_df['Glycans[Byonic]']]\n",
    "        id_df['GlycanComposition_ByonicStyle[pGlyco]'] = [int(i) if i == '-1' else i for i in id_df['GlycanComposition_ByonicStyle[pGlyco]']]\n",
    "        id_df = id_df[col_order]\n",
    "        threshold_masks_colorind(id_df)\n",
    "        print('\\n----- Exporting \"_NGlycoPep\" file... This may take some time, please wait. -----\\n')\n",
    "        id_df.style.apply(bg_color, axis=None).to_excel(f'{date}_{filename}_NGlycoPep.xlsx', index = False)  \n",
    "        print('\\n----- \"_NGlycoPep\" file exported. -----\\n')\n",
    "        print('----- Start preparing quantification file. -----\\n')\n",
    "\n",
    "        # quantification only apply to single sites (quant_df offers important info. for later multiIndex df construction)\n",
    "        quant = id_df[id_df['N-site(SequonBased)[Byonic]'].apply(lambda x: isinstance(x, int))]\n",
    "        drop_ind = quant.loc[(quant['Fragment\\r\\nType[Byonic]'] == 'ethcd') & ((quant['Score[Byonic]'] <= 200)|(quant['PEP\\r\\n2D[Byonic]'].abs() >= 0.001)) & ((quant['Pair[Byonic]'] == -1)|(quant['Pair[Byonic]'] == 'N/A'))].index.tolist()\n",
    "        ind = [i for i in quant.index.tolist() if i not in drop_ind]\n",
    "        quant = quant.loc[ind] # hcd all in, if byonic etd pass score & pep2d all in, otherwise in with pair\n",
    "        # avoid adding values from below-threshold rows: if deepgreen -> change value to -1, if deepblue -> change value to -1.(-1 to make lambda function easier to write)\n",
    "        threshold_masks_colorind(quant)\n",
    "        quant.loc[deepgreen_ind, ['MonoArea[pGlyco]', 'IsotopeArea[pGlyco]']] = -1\n",
    "        quant.loc[deepblue_ind, ['XIC\\r\\nAUC[Byos]', 'Apex Int.\\r\\n(Posit)[Byos]']] = -1\n",
    "        # calculate the sum within each n-site, then normalize xicauc/ int/ mono/ iso by these sum\n",
    "        quant['sumpersite_xicauc'] = quant.groupby(['N-site(SequonBased)[Byonic]'])['XIC\\r\\nAUC[Byos]'].transform(lambda x: x[x!=-1].sum())\n",
    "        quant['sumpersite_int'] = quant.groupby(['N-site(SequonBased)[Byonic]'])['Apex Int.\\r\\n(Posit)[Byos]'].transform(lambda x: x[x!=-1].sum())\n",
    "        quant['sumpersite_mono'] = quant.groupby(['ProSites[pGlyco]'])['MonoArea[pGlyco]'].transform(lambda x: x[x!=-1].sum())\n",
    "        quant['sumpersite_iso'] = quant.groupby(['ProSites[pGlyco]'])['IsotopeArea[pGlyco]'].transform(lambda x: x[x!=-1].sum())\n",
    "        # convert all the 'N/A' in byonic glycans to 'Unoccupied'\n",
    "        quant.loc[(quant['Glycans[Byonic]'] == 'N/A'), ['Glycans[Byonic]']] = 'Unoccupied'\n",
    "        # using groupby transform sum function to add 8 cols (byos xicauc/byos area int/pglycomono/pglycoisotope) recording summed values & normalized values (same site & same glycan & seq can be dif)\n",
    "        quant['e_sum_XIC\\r\\nAUC[Byos]'] = quant.groupby(['N-site(SequonBased)[Byonic]', 'Glycans[Byonic]'])['XIC\\r\\nAUC[Byos]'].transform(lambda x: x[x != -1].sum())\n",
    "        quant['f_sum_Apex Int.\\r\\n(Posit)[Byos]'] = quant.groupby(['N-site(SequonBased)[Byonic]', 'Glycans[Byonic]'])['Apex Int.\\r\\n(Posit)[Byos]'].transform(lambda x: x[x != -1].sum())\n",
    "        quant['g_sum_MonoArea[pGlyco]'] = quant.groupby(['ProSites[pGlyco]', 'GlycanComposition_ByonicStyle[pGlyco]'])['MonoArea[pGlyco]'].transform(lambda x: x[x != -1].sum())\n",
    "        quant['h_sum_IsotopeArea[pGlyco]'] = quant.groupby(['ProSites[pGlyco]', 'GlycanComposition_ByonicStyle[pGlyco]'])['IsotopeArea[pGlyco]'].transform(lambda x: x[x != -1].sum())\n",
    "        quant['a_norm_XIC\\r\\nAUC[Byos]'] = quant['e_sum_XIC\\r\\nAUC[Byos]']/quant['sumpersite_xicauc']\n",
    "        quant['b_norm_Apex Int.\\r\\n(Posit)[Byos]'] = quant['f_sum_Apex Int.\\r\\n(Posit)[Byos]']/quant['sumpersite_int']\n",
    "        quant['c_norm_MonoArea[pGlyco]'] = quant['g_sum_MonoArea[pGlyco]']/quant['sumpersite_mono']\n",
    "        quant['d_norm_IsotopeArea[pGlyco]'] = quant['h_sum_IsotopeArea[pGlyco]']/quant['sumpersite_iso']\n",
    "        # since it's possible to have real 0 from calculation, change the real absent data back to -1 in sum_ & norm_\n",
    "        quant.loc[quant['MonoArea[pGlyco]'] == -1, ['g_sum_MonoArea[pGlyco]', 'h_sum_IsotopeArea[pGlyco]', 'c_norm_MonoArea[pGlyco]', 'd_norm_IsotopeArea[pGlyco]']] = -1\n",
    "        quant.loc[quant['XIC\\r\\nAUC[Byos]'] == -1, ['e_sum_XIC\\r\\nAUC[Byos]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]', 'a_norm_XIC\\r\\nAUC[Byos]', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']] = -1 \n",
    "        # extract the needed cols only & split byonicbyos/pglyco, drop all -1 rows, glycans as index to outer union concat data again\n",
    "        quant_bb = quant[['N-site(SequonBased)[Byonic]', 'Glycans[Byonic]', 'MS2 Search\\r\\nAlias name[Byos]', 'e_sum_XIC\\r\\nAUC[Byos]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]', 'a_norm_XIC\\r\\nAUC[Byos]', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "        quant_p = quant[['ProSites[pGlyco]', 'GlycanComposition_ByonicStyle[pGlyco]', 'g_sum_MonoArea[pGlyco]', 'h_sum_IsotopeArea[pGlyco]', 'c_norm_MonoArea[pGlyco]', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "        quant_bb = quant_bb.loc[quant_bb['N-site(SequonBased)[Byonic]'] != -1]\n",
    "        quant_p = quant_p.loc[quant_p['ProSites[pGlyco]'] != -1]\n",
    "        quant_bb = quant_bb.set_index('Glycans[Byonic]')\n",
    "        quant_p = quant_p.set_index('GlycanComposition_ByonicStyle[pGlyco]')\n",
    "        a1, a2 = quant_bb.align(quant_p, join = 'outer', axis = 0) \n",
    "        quant_glycanid = pd.concat([a1,a2], axis = 1)\n",
    "        quant_glycanid.index.name = 'Glycans ↓'\n",
    "        quant_glycanid.reset_index(level=0, inplace=True)\n",
    "        # add N(x) col\n",
    "        nx = ['N(0)' if lst == [] else 'N(%s)'%(lst[0]) for lst in quant_glycanid['Glycans ↓'].str.findall(r'HexNAc\\((\\d+)\\)').tolist()]\n",
    "        quant_glycanid.insert(0 , 'N(x) ↓', nx , True)\n",
    "        move_df(quant_glycanid, 'ProSites[pGlyco]', 'N-site(SequonBased)[Byonic]')\n",
    "        quant_glycanid = quant_glycanid.drop('MS2 Search\\r\\nAlias name[Byos]', axis = 1)\n",
    "        # change all nan to blank -1\n",
    "        quant_glycanid = quant_glycanid.fillna(-1)\n",
    "        quant_glycanid = quant_glycanid.drop_duplicates() # remember to drop duplicates after splitting & reconcat df\n",
    "        # generate 4 versions: bp_intersection (both sites are present at the same time <intersection>), bp_union (n site union), only b (xicauc/int), only p (mono/isotope)\n",
    "        ## onlyb\n",
    "        onlyb = quant_glycanid.loc[(quant_glycanid['N-site(SequonBased)[Byonic]'] != -1), [col for col in quant_glycanid.columns.tolist() if 'pGlyco' not in col]]\n",
    "        onlyb = onlyb.drop_duplicates()\n",
    "        # clean off all no data rows\n",
    "        onlyb = onlyb.loc[~((onlyb['e_sum_XIC\\r\\nAUC[Byos]']==-1)&(onlyb['f_sum_Apex Int.\\r\\n(Posit)[Byos]']==-1)&(onlyb['a_norm_XIC\\r\\nAUC[Byos]']==-1)&(onlyb['b_norm_Apex Int.\\r\\n(Posit)[Byos]']==-1))]\n",
    "        nx = list(set(onlyb['N(x) ↓'].tolist()))\n",
    "        nx = [int(re.findall(r'[0-9]+', i)[0]) if type(i) == str else i for i in nx]\n",
    "        nx.sort(key=lambda v: (isinstance(v, str), v))\n",
    "        b_new_nx = ['N(%s)'%(str(i)) if type(i) == int and i != -1 else i for i in nx]\n",
    "\n",
    "        ## onlyp\n",
    "        onlyp = quant_glycanid.loc[(quant_glycanid['ProSites[pGlyco]'] != -1), [col for col in quant_glycanid.columns.tolist() if 'Byonic' not in col and 'Byos' not in col]]\n",
    "        onlyp = onlyp.drop_duplicates()\n",
    "        # clean off all no data rows\n",
    "        onlyp = onlyp.loc[~((onlyp['g_sum_MonoArea[pGlyco]']==-1)&(onlyp['h_sum_IsotopeArea[pGlyco]']==-1)&(onlyp['c_norm_MonoArea[pGlyco]']==-1)&(onlyp['d_norm_IsotopeArea[pGlyco]']==-1))]\n",
    "        nx = list(set(onlyp['N(x) ↓'].tolist()))\n",
    "        nx = [int(re.findall(r'[0-9]+', i)[0]) if type(i) == str else i for i in nx]\n",
    "        nx.sort(key=lambda v: (isinstance(v, str), v))\n",
    "        p_new_nx = ['N(%s)'%(str(i)) if type(i) == int and i != -1 else i for i in nx]\n",
    "\n",
    "        ## bp_union\n",
    "        onlyb_union = onlyb.rename(columns={'N-site(SequonBased)[Byonic]':'N-site(Byonic ∪ pGlyco) →'}) \n",
    "        onlyp_union = onlyp.rename(columns={'ProSites[pGlyco]':'N-site(Byonic ∪ pGlyco) →'}) \n",
    "        a1, a2 = onlyb_union.drop('N(x) ↓', axis = 1).align(onlyp_union.drop('N(x) ↓', axis = 1), join='outer', axis = 1) # align col only\n",
    "        bp_union = pd.concat([a1,a2])\n",
    "        bp_union = bp_union.sort_values('Glycans ↓').reset_index(drop = True).fillna(-1)\n",
    "        # add N(x) col\n",
    "        nx = ['N(0)' if lst == [] else 'N(%s)'%(lst[0]) for lst in bp_union['Glycans ↓'].str.findall(r'HexNAc\\((\\d+)\\)').tolist()]\n",
    "        bp_union.insert(0 , 'N(x) ↓', nx , True)\n",
    "        nx = list(set(bp_union['N(x) ↓'].tolist()))\n",
    "        nx = [int(re.findall(r'[0-9]+', i)[0]) if type(i) == str else i for i in nx]\n",
    "        nx.sort(key=lambda v: (isinstance(v, str), v))\n",
    "        bp_union_new_nx = ['N(%s)'%(str(i)) if type(i) == int and i != -1 else i for i in nx]\n",
    "\n",
    "        ## bp_intersection\n",
    "        bpsite_union_lst = list(set(onlyb['N-site(SequonBased)[Byonic]'].tolist()).intersection(set(onlyp['ProSites[pGlyco]'].tolist())))\n",
    "        bp_inter = bp_union.loc[bp_union['N-site(Byonic ∪ pGlyco) →'].isin(bpsite_union_lst)]\n",
    "        # add N(x) col\n",
    "        nx = ['N(0)' if lst == [] else 'N(%s)'%(lst[0]) for lst in bp_inter['Glycans ↓'].str.findall(r'HexNAc\\((\\d+)\\)').tolist()]\n",
    "        nx = list(set(bp_inter['N(x) ↓'].tolist()))\n",
    "        nx = [int(re.findall(r'[0-9]+', i)[0]) if type(i) == str else i for i in nx]\n",
    "        nx.sort(key=lambda v: (isinstance(v, str), v))\n",
    "        bp_intersection_new_nx = ['N(%s)'%(str(i)) if type(i) == int and i != -1 else i for i in nx]\n",
    "\n",
    "        ## onlyb_top10\n",
    "        onlyb_top10 = onlyb.copy()\n",
    "        xicauc_top10 = onlyb_top10.groupby('N-site(SequonBased)[Byonic]')['a_norm_XIC\\r\\nAUC[Byos]'].nlargest(10).droplevel(level = 0).index.tolist()\n",
    "        int_top10 = onlyb_top10.groupby('N-site(SequonBased)[Byonic]')['b_norm_Apex Int.\\r\\n(Posit)[Byos]'].nlargest(10).droplevel(level = 0).index.tolist()\n",
    "        onlyb_top10.loc[[i for i in onlyb_top10.index.tolist() if i not in xicauc_top10], 'a_norm_XIC\\r\\nAUC[Byos]'] = -1\n",
    "        onlyb_top10.loc[[i for i in onlyb_top10.index.tolist() if i not in int_top10], 'b_norm_Apex Int.\\r\\n(Posit)[Byos]'] = -1\n",
    "        onlyb_top10 = onlyb_top10.loc[(onlyb_top10['a_norm_XIC\\r\\nAUC[Byos]'] != -1)|(onlyb_top10['b_norm_Apex Int.\\r\\n(Posit)[Byos]'] != -1)].reset_index(drop=True).drop(['N(x) ↓', 'e_sum_XIC\\r\\nAUC[Byos]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]', 'N(x) ↓'], axis = 1)\n",
    "\n",
    "        ## onlyp_top10\n",
    "        onlyp_top10 = onlyp.copy()\n",
    "        mono_top10 = onlyp_top10.groupby('ProSites[pGlyco]')['c_norm_MonoArea[pGlyco]'].nlargest(10).droplevel(level = 0).index.tolist()\n",
    "        iso_top10 = onlyp_top10.groupby('ProSites[pGlyco]')['d_norm_IsotopeArea[pGlyco]'].nlargest(10).droplevel(level = 0).index.tolist()\n",
    "        onlyp_top10.loc[[i for i in onlyp_top10.index.tolist() if i not in mono_top10], 'c_norm_MonoArea[pGlyco]'] = -1\n",
    "        onlyp_top10.loc[[i for i in onlyp_top10.index.tolist() if i not in iso_top10], 'd_norm_IsotopeArea[pGlyco]'] = -1\n",
    "        onlyp_top10 = onlyp_top10.loc[(onlyp_top10['c_norm_MonoArea[pGlyco]'] != -1)|(onlyp_top10['d_norm_IsotopeArea[pGlyco]'] != -1)].reset_index(drop=True).drop(['N(x) ↓', 'g_sum_MonoArea[pGlyco]', 'h_sum_IsotopeArea[pGlyco]', 'N(x) ↓'], axis = 1)\n",
    "\n",
    "        ## bp_top10\n",
    "        onlyb_top10 = onlyb_top10.rename(columns={'N-site(SequonBased)[Byonic]':'N-site(Byonic ∪ pGlyco) →'}) \n",
    "        onlyp_top10 = onlyp_top10.rename(columns={'ProSites[pGlyco]':'N-site(Byonic ∪ pGlyco) →'})\n",
    "        a1, a2 = onlyb_top10.align(onlyp_top10, join='outer', axis = 1) # align cols only\n",
    "        bptop10 = pd.concat([a1,a2]) # concat vertically \n",
    "        bptop10 = bptop10.fillna(-1).sort_values('Glycans ↓').reset_index(drop = True)\n",
    "        # add N(x) col\n",
    "        nx = ['N(0)' if lst == [] else 'N(%s)'%(lst[0]) for lst in bptop10['Glycans ↓'].str.findall(r'HexNAc\\((\\d+)\\)').tolist()]\n",
    "        bptop10.insert(0 , 'N(x) ↓', nx , True)\n",
    "        nx = list(set(bptop10['N(x) ↓'].tolist()))\n",
    "        nx = [int(re.findall(r'[0-9]+', i)[0]) if type(i) == str else i for i in nx]\n",
    "        nx.sort(key=lambda v: (isinstance(v, str), v))\n",
    "        bptop10_new_nx = ['N(%s)'%(str(i)) if type(i) == int and i != -1 else i for i in nx]\n",
    "\n",
    "        print('----- Start summary table construction. -----\\n')\n",
    "        # start grouping: N(X) -> byonic glycans -> byonic sites -> .agg({all 8 cols, apply .mean() & .mean()/total XXX})\n",
    "        # bp_intersection\n",
    "        bp_intersection_gp = bp_inter.groupby(['N(x) ↓', 'Glycans ↓', 'N-site(Byonic ∪ pGlyco) →']).agg({'a_norm_XIC\\r\\nAUC[Byos]': lambda x: x[x!= -1].mean(), 'b_norm_Apex Int.\\r\\n(Posit)[Byos]': lambda x: x[x!= -1].mean() \\\n",
    "                                                                                              , 'c_norm_MonoArea[pGlyco]': lambda x: x[x!= -1].mean(), 'd_norm_IsotopeArea[pGlyco]': lambda x: x[x!= -1].mean()})\n",
    "        # fix the str '10' sorted before '2' problem\n",
    "        bp_intersection_gp = bp_intersection_gp.reindex(bp_intersection_new_nx, level = 0)\n",
    "        # unstack byonic n-sites, pglyco n-sites\n",
    "        bp_intersection_gp = bp_intersection_gp.unstack(level=-1)\n",
    "        # multiIndex col swaplevel\n",
    "        bp_intersection_gp.columns = bp_intersection_gp.columns.swaplevel(0, 1)\n",
    "        # sort is necessary for the right table structure (but since it will sort every level, so we need to manually adjust level3 back to the original order)\n",
    "        bp_intersection_gp.sort_index(axis=1, level=[0, 1], inplace=True)\n",
    "        bp_intersection_gp.columns = bp_intersection_gp.columns.set_names(['N-site(Byonic ∩ pGlyco) →', 'Quant. →'])\n",
    "        # delete a-h in Quant. (the alphabet is just for sorting)\n",
    "        bp_intersection_gp.columns.set_levels(['norm_XIC\\r\\nAUC[Byos]', 'norm_Apex Int.\\r\\n(Posit)[Byos]', 'norm_MonoArea[pGlyco]', 'norm_IsotopeArea[pGlyco]'], level = 1, inplace=True)\n",
    "\n",
    "        # bp_union\n",
    "        bp_union_gp = bp_union.groupby(['N(x) ↓', 'Glycans ↓', 'N-site(Byonic ∪ pGlyco) →']).agg({'a_norm_XIC\\r\\nAUC[Byos]': lambda x: x[x!= -1].mean(), 'b_norm_Apex Int.\\r\\n(Posit)[Byos]': lambda x: x[x!= -1].mean() \\\n",
    "                                                                                              , 'c_norm_MonoArea[pGlyco]': lambda x: x[x!= -1].mean(), 'd_norm_IsotopeArea[pGlyco]': lambda x: x[x!= -1].mean()})\n",
    "\n",
    "        # fix the str '10' sorted before '2' problem\n",
    "        bp_union_gp = bp_union_gp.reindex(bp_union_new_nx, level = 0)\n",
    "        # unstack byonic n-sites, pglyco n-sites\n",
    "        bp_union_gp = bp_union_gp.unstack(level=-1)\n",
    "        # multiIndex col swaplevel\n",
    "        bp_union_gp.columns = bp_union_gp.columns.swaplevel(0, 1)\n",
    "        # sort is necessary for the right table structure (but since it will sort every level, so we need to manually adjust level3 back to the original order)\n",
    "        bp_union_gp.sort_index(axis=1, level=[0, 1], inplace=True)\n",
    "        bp_union_gp.columns = bp_union_gp.columns.set_names(['N-site(Byonic ∪ pGlyco) →', 'Quant. →'])\n",
    "        # delete a-h in Quant. (the alphabet is just for sorting)\n",
    "        bp_union_gp.columns.set_levels(['norm_XIC\\r\\nAUC[Byos]', 'norm_Apex Int.\\r\\n(Posit)[Byos]', 'norm_MonoArea[pGlyco]', 'norm_IsotopeArea[pGlyco]'], level = 1, inplace=True)\n",
    "\n",
    "\n",
    "        # onlyb\n",
    "        onlyb_gp = onlyb.groupby(['N(x) ↓', 'Glycans ↓', 'N-site(SequonBased)[Byonic]']).agg({'e_sum_XIC\\r\\nAUC[Byos]': lambda x: x.mean(), 'f_sum_Apex Int.\\r\\n(Posit)[Byos]': lambda x: x.mean() \\\n",
    "                                                                                              , 'a_norm_XIC\\r\\nAUC[Byos]': lambda x: x.mean(), 'b_norm_Apex Int.\\r\\n(Posit)[Byos]': lambda x: x.mean()})\n",
    "\n",
    "        # fix the str '10' sorted before '2' problem\n",
    "        onlyb_gp = onlyb_gp.reindex(b_new_nx, level = 0)\n",
    "        # unstack byonic n-sites\n",
    "        onlyb_gp = onlyb_gp.unstack(level=-1)\n",
    "        # multiIndex col swaplevel\n",
    "        onlyb_gp.columns = onlyb_gp.columns.swaplevel(0, 1)\n",
    "        # sort is necessary for the right table structure (but since it will sort every level, so we need to manually adjust level3 back to the original order)\n",
    "        onlyb_gp.sort_index(axis=1, level=[0, 1], inplace=True)\n",
    "        onlyb_gp.columns = onlyb_gp.columns.set_names(['N-site(SequonBased)[Byonic] →', 'Quant. →'])\n",
    "        # delete a-h in Quant. (the alphabet is just for sorting)\n",
    "        onlyb_gp.columns.set_levels(['norm_XIC\\r\\nAUC[Byos]', 'norm_Apex Int.\\r\\n(Posit)[Byos]', 'sum_XIC\\r\\nAUC[Byos]', 'sum_Apex Int.\\r\\n(Posit)[Byos]'], level = 1, inplace=True)\n",
    "\n",
    "        # onlyp\n",
    "        onlyp_gp = onlyp.groupby(['N(x) ↓', 'Glycans ↓', 'ProSites[pGlyco]']).agg({'g_sum_MonoArea[pGlyco]': lambda x: x.mean(), 'h_sum_IsotopeArea[pGlyco]': lambda x: x.mean() \\\n",
    "                                                                                              , 'c_norm_MonoArea[pGlyco]': lambda x: x.mean(), 'd_norm_IsotopeArea[pGlyco]': lambda x: x.mean()})\n",
    "\n",
    "        # fix the str '10' sorted before '2' problem\n",
    "        onlyp_gp = onlyp_gp.reindex(p_new_nx, level = 0)\n",
    "        # unstack byonic n-sites, pglyco n-sites\n",
    "        onlyp_gp = onlyp_gp.unstack(level=-1)\n",
    "        # multiIndex col swaplevel\n",
    "        onlyp_gp.columns = onlyp_gp.columns.swaplevel(0, 1)\n",
    "        # sort is necessary for the right table structure (but since it will sort every level, so we need to manually adjust level3 back to the original order)\n",
    "        onlyp_gp.sort_index(axis=1, level=[0, 1], inplace=True)\n",
    "        onlyp_gp.columns = onlyp_gp.columns.set_names(['ProSites[pGlyco] →', 'Quant. →'])\n",
    "        # delete a-h in Quant. (the alphabet is just for sorting)\n",
    "        onlyp_gp.columns.set_levels(['norm_MonoArea[pGlyco]', 'norm_IsotopeArea[pGlyco]', 'sum_MonoArea[pGlyco]', 'sum_IsotopeArea[pGlyco]'], level = 1, inplace=True)\n",
    "\n",
    "        # bp_top10\n",
    "        bptop10_gp = bptop10.groupby(['N(x) ↓', 'Glycans ↓', 'N-site(Byonic ∪ pGlyco) →']).agg({'a_norm_XIC\\r\\nAUC[Byos]': lambda x: x[x!= -1].mean(), 'b_norm_Apex Int.\\r\\n(Posit)[Byos]': lambda x: x[x!= -1].mean() \\\n",
    "                                                                                              , 'c_norm_MonoArea[pGlyco]': lambda x: x[x!= -1].mean(), 'd_norm_IsotopeArea[pGlyco]': lambda x: x[x!= -1].mean()})\n",
    "\n",
    "        # fix the str '10' sorted before '2' problem\n",
    "        bptop10_gp = bptop10_gp.reindex(bptop10_new_nx, level = 0)\n",
    "        # unstack byonic n-sites, pglyco n-sites\n",
    "        bptop10_gp = bptop10_gp.unstack(level=-1)\n",
    "        # multiIndex col swaplevel\n",
    "        bptop10_gp.columns = bptop10_gp.columns.swaplevel(0, 1)\n",
    "        # sort is necessary for the right table structure (but since it will sort every level, so we need to manually adjust level3 back to the original order)\n",
    "        bptop10_gp.sort_index(axis=1, level=[0, 1], inplace=True)\n",
    "        bptop10_gp.columns = bptop10_gp.columns.set_names(['N-site(Byonic ∪ pGlyco) →', 'Quant. →'])\n",
    "        # delete a-h in Quant. (the alphabet is just for sorting)\n",
    "        bptop10_gp.columns.set_levels(['norm_XIC\\r\\nAUC[Byos]', 'norm_Apex Int.\\r\\n(Posit)[Byos]', 'norm_MonoArea[pGlyco]', 'norm_IsotopeArea[pGlyco]'], level = 1, inplace=True)\n",
    "\n",
    "        print('\\n----- Exporting 3 \"_Quant\" files... This may take some time, please wait. -----\\n')\n",
    "\n",
    "        # bp_intersection\n",
    "        bp_intersection_gp.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "        bp_intersection_gp.style.background_gradient(cmap ='Reds').highlight_null(null_color='white').to_excel(f'{date}_{filename}_Sheet3(QuantBPinter).xlsx') \n",
    "        print('\\n----- \"_QuantBPintersection\" file exported (Intersection of Byonic & pGlyco N-glycosylation sites). -----\\n')\n",
    "        # bp_union\n",
    "        bp_union_gp.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "        bp_union_gp.style.background_gradient(cmap ='Reds').highlight_null(null_color='white').to_excel(f'{date}_{filename}_Sheet4(QuantBPunion).xlsx') \n",
    "        print('\\n----- \"_QuantBPunion\" file exported (Union of Byonic & pGlyco N-glycosylation sites). -----\\n')\n",
    "        # onlyb\n",
    "        onlyb_gp.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "        onlyb_gp.style.background_gradient(cmap ='Greens').highlight_null(null_color='white').to_excel(f'{date}_{filename}_Sheet1(QuantB).xlsx')\n",
    "        print('\\n----- \"_QuantB\" file exported. -----\\n')\n",
    "        # onlyp\n",
    "        onlyb_gp.replace(to_replace = -1, value = np.nan , inplace = True) \n",
    "        onlyp_gp.style.background_gradient(cmap ='Blues').highlight_null(null_color='white').to_excel(f'{date}_{filename}_Sheet2(QuantP).xlsx')\n",
    "        print('\\n----- \"_QuantP\" file exported. -----\\n')\n",
    "        # bp_top10\n",
    "        bptop10_gp.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "        bptop10_gp.style.background_gradient(cmap ='Reds').highlight_null(null_color='white').to_excel(f'{date}_{filename}_Sheet5(Top10).xlsx') \n",
    "        print('\\n----- \"_Top10\" file exported. -----\\n')\n",
    "        \n",
    "        print('----- Start plotting. -----\\n')\n",
    "        bpunionNORM_dfall_lstv1, bpunionNORM_label_lstv1, bpunionNORM_dfall_lstv2, bpunionNORM_label_lstv2 \\\n",
    "        , bpinterNORM_dfall_lstv1, bpinterNORM_label_lstv1, bpinterNORM_dfall_lstv2, bpinterNORM_label_lstv2 \\\n",
    "        , bNORM_dfall_lstv1, bNORM_label_lstv1, bNORM_dfall_lstv2, bNORM_label_lstv2 \\\n",
    "        , bSUM_dfall_lstv1, bSUM_label_lstv1, bSUM_nsum_lstv1, bSUM_dfall_lstv2, bSUM_label_lstv2, bSUM_nsum_lstv2 \\\n",
    "        , pNORM_dfall_lstv1, pNORM_label_lstv1, pNORM_dfall_lstv2, pNORM_label_lstv2 \\\n",
    "        , pSUM_dfall_lstv1, pSUM_label_lstv1, pSUM_nsum_lstv1, pSUM_dfall_lstv2, pSUM_label_lstv2, pSUM_nsum_lstv2 \\\n",
    "        = [],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]\n",
    "        \n",
    "        col_order = ['N(0)', 'N(1)', 'OligoMannose', 'Complex', 'Complex+Sia'] # col order for v2 plotting\n",
    "        \n",
    "        # necessary preprocessings for v2 plotting\n",
    "        # bp union v2\n",
    "        bp_union.loc[(bp_union['N(x) ↓'] == 'N(0)')|(bp_union['N(x) ↓'] == 'N(1)'), 'nx_version2'] = bp_union['N(x) ↓']\n",
    "        bp_union.loc[(bp_union['N(x) ↓'] == 'N(2)'), 'nx_version2'] = 'OligoMannose'\n",
    "        bp_union.loc[(bp_union['N(x) ↓'] != 'N(0)')&(bp_union['N(x) ↓'] != 'N(1)')&(bp_union['N(x) ↓'] != 'N(2)'), 'nx_version2'] = 'Complex'\n",
    "        bp_union.loc[(bp_union['N(x) ↓'] != 'N(0)')&(bp_union['N(x) ↓'] != 'N(1)')&(bp_union['N(x) ↓'] != 'N(2)')&(bp_union['Glycans ↓'].str.contains('NeuAc|NeuGc')), 'nx_version2'] = 'Complex+Sia'\n",
    "        bpunion_neugc_exist = sum(bp_union['Glycans ↓'].str.contains('NeuGc')) > 0 # Bool, if T, red. else purple\n",
    "        # bp inter v2\n",
    "        bp_inter.loc[(bp_inter['N(x) ↓'] == 'N(0)')|(bp_inter['N(x) ↓'] == 'N(1)'), 'nx_version2'] = bp_inter['N(x) ↓']\n",
    "        bp_inter.loc[(bp_inter['N(x) ↓'] == 'N(2)'), 'nx_version2'] = 'OligoMannose'\n",
    "        bp_inter.loc[(bp_inter['N(x) ↓'] != 'N(0)')&(bp_inter['N(x) ↓'] != 'N(1)')&(bp_inter['N(x) ↓'] != 'N(2)'), 'nx_version2'] = 'Complex'\n",
    "        bp_inter.loc[(bp_inter['N(x) ↓'] != 'N(0)')&(bp_inter['N(x) ↓'] != 'N(1)')&(bp_inter['N(x) ↓'] != 'N(2)')&(bp_inter['Glycans ↓'].str.contains('NeuAc|NeuGc')), 'nx_version2'] = 'Complex+Sia'\n",
    "        bpinter_neugc_exist = sum(bp_inter['Glycans ↓'].str.contains('NeuGc')) > 0 # Bool, if T, red. else purple\n",
    "        # onlyb v2\n",
    "        onlyb.loc[(onlyb['N(x) ↓'] == 'N(0)')|(onlyb['N(x) ↓'] == 'N(1)'), 'nx_version2'] = onlyb['N(x) ↓']\n",
    "        onlyb.loc[(onlyb['N(x) ↓'] == 'N(2)'), 'nx_version2'] = 'OligoMannose'\n",
    "        onlyb.loc[(onlyb['N(x) ↓'] != 'N(0)')&(onlyb['N(x) ↓'] != 'N(1)')&(onlyb['N(x) ↓'] != 'N(2)'), 'nx_version2'] = 'Complex'\n",
    "        onlyb.loc[(onlyb['N(x) ↓'] != 'N(0)')&(onlyb['N(x) ↓'] != 'N(1)')&(onlyb['N(x) ↓'] != 'N(2)')&(onlyb['Glycans ↓'].str.contains('NeuAc|NeuGc')), 'nx_version2'] = 'Complex+Sia'\n",
    "        b_neugc_exist = sum(onlyb['Glycans ↓'].str.contains('NeuGc')) > 0 # Bool, if T, red. else purple\n",
    "        # onlyp v2\n",
    "        onlyp.loc[(onlyp['N(x) ↓'] == 'N(0)')|(onlyp['N(x) ↓'] == 'N(1)'), 'nx_version2'] = onlyp['N(x) ↓']\n",
    "        onlyp.loc[(onlyp['N(x) ↓'] == 'N(2)'), 'nx_version2'] = 'OligoMannose'\n",
    "        onlyp.loc[(onlyp['N(x) ↓'] != 'N(0)')&(onlyp['N(x) ↓'] != 'N(1)')&(onlyp['N(x) ↓'] != 'N(2)'), 'nx_version2'] = 'Complex'\n",
    "        onlyp.loc[(onlyp['N(x) ↓'] != 'N(0)')&(onlyp['N(x) ↓'] != 'N(1)')&(onlyp['N(x) ↓'] != 'N(2)')&(onlyp['Glycans ↓'].str.contains('NeuAc|NeuGc')), 'nx_version2'] = 'Complex+Sia'\n",
    "        p_neugc_exist = sum(onlyp['Glycans ↓'].str.contains('NeuGc')) > 0 # Bool, if T, red. else purple\n",
    "        # rename bp inter colname\n",
    "        bp_inter = bp_inter.rename(columns={'N-site(Byonic ∪ pGlyco) →':'N-site(Byonic ∩ pGlyco) →'})\n",
    "        # make sure that sites are presented as int not float\n",
    "        bp_union = bp_union.astype({'N-site(Byonic ∪ pGlyco) →':'Int64'})\n",
    "        bp_inter = bp_inter.astype({'N-site(Byonic ∩ pGlyco) →':'Int64'})\n",
    "        onlyb = onlyb.astype({'N-site(SequonBased)[Byonic]':'Int64'})\n",
    "        onlyp = onlyp.astype({'ProSites[pGlyco]':'Int64'})\n",
    "        \n",
    "        # split bp_union into: xicauc_df / int_df / mono_df / iso_df for later clustered stacked plot (norm only)\n",
    "        if export_xicauc == 'yes':\n",
    "            # bpunion norm v1\n",
    "            bpunion_xicaucNORM_df = bp_union.loc[:, ['N(x) ↓', 'N-site(Byonic ∪ pGlyco) →', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "            bpunion_xicaucNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            bpunion_xicaucNORM_df = bpunion_xicaucNORM_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='a_norm_XIC\\r\\nAUC[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=bp_union_new_nx)\n",
    "            bpunionNORM_dfall_lstv1.append(bpunion_xicaucNORM_df)\n",
    "            bpunionNORM_label_lstv1.append('norm_XIC AUC[Byos]')\n",
    "            # bpuion norm v2\n",
    "            bpunion_xicaucNORMv2_df = bp_union.loc[:, ['nx_version2', 'N-site(Byonic ∪ pGlyco) →', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "            bpunion_xicaucNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            bpunion_xicaucNORMv2_df = bpunion_xicaucNORMv2_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='a_norm_XIC\\r\\nAUC[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "            bpunionNORM_dfall_lstv2.append(bpunion_xicaucNORMv2_df)\n",
    "            bpunionNORM_label_lstv2.append('norm_XIC AUC[Byos]')\n",
    "            # bpinter norm v1\n",
    "            bpinter_xicaucNORM_df = bp_inter.loc[:, ['N(x) ↓', 'N-site(Byonic ∩ pGlyco) →', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "            bpinter_xicaucNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            bpinter_xicaucNORM_df = bpinter_xicaucNORM_df.pivot_table(index='N-site(Byonic ∩ pGlyco) →', values='a_norm_XIC\\r\\nAUC[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=bp_intersection_new_nx)\n",
    "            bpinterNORM_dfall_lstv1.append(bpinter_xicaucNORM_df)\n",
    "            bpinterNORM_label_lstv1.append('norm_XIC AUC[Byos]')\n",
    "            # bpinter norm v2\n",
    "            bpinter_xicaucNORMv2_df = bp_inter.loc[:, ['nx_version2', 'N-site(Byonic ∩ pGlyco) →', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "            bpinter_xicaucNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            bpinter_xicaucNORMv2_df = bpinter_xicaucNORMv2_df.pivot_table(index='N-site(Byonic ∩ pGlyco) →', values='a_norm_XIC\\r\\nAUC[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "            bpinterNORM_dfall_lstv2.append(bpinter_xicaucNORMv2_df)\n",
    "            bpinterNORM_label_lstv2.append('norm_XIC AUC[Byos]')\n",
    "            # onlyb norm v1\n",
    "            b_xicaucNORM_df = onlyb.loc[:, ['N(x) ↓', 'N-site(SequonBased)[Byonic]', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "            b_xicaucNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            b_xicaucNORM_df = b_xicaucNORM_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='a_norm_XIC\\r\\nAUC[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=b_new_nx)\n",
    "            bNORM_dfall_lstv1.append(b_xicaucNORM_df)\n",
    "            bNORM_label_lstv1.append('norm_XIC AUC[Byos]')\n",
    "            # onlyb norm v2\n",
    "            b_xicaucNORMv2_df = onlyb.loc[:, ['nx_version2', 'N-site(SequonBased)[Byonic]', 'a_norm_XIC\\r\\nAUC[Byos]']]\n",
    "            b_xicaucNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            b_xicaucNORMv2_df = b_xicaucNORMv2_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='a_norm_XIC\\r\\nAUC[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "            bNORM_dfall_lstv2.append(b_xicaucNORMv2_df)\n",
    "            bNORM_label_lstv2.append('norm_XIC AUC[Byos]')\n",
    "            # onlyb sum v1\n",
    "            b_xicaucSUM_df = onlyb.loc[:, ['N(x) ↓', 'N-site(SequonBased)[Byonic]', 'e_sum_XIC\\r\\nAUC[Byos]']]\n",
    "            b_xicaucSUM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            b_xicaucSUM_df = b_xicaucSUM_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='e_sum_XIC\\r\\nAUC[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=b_new_nx)\n",
    "            b_xicaucSUM_df_nsum = [b_xicaucSUM_df.loc[i].sum() for i in b_xicaucSUM_df.index.tolist()] # for A bar label\n",
    "            bSUM_dfall_lstv1.append(b_xicaucSUM_df)\n",
    "            bSUM_label_lstv1.append('sum_XIC AUC[Byos]')\n",
    "            bSUM_nsum_lstv1.append(b_xicaucSUM_df_nsum)\n",
    "            # onlyb sum v2\n",
    "            b_xicaucSUMv2_df = onlyb.loc[:, ['nx_version2', 'N-site(SequonBased)[Byonic]', 'e_sum_XIC\\r\\nAUC[Byos]']]\n",
    "            b_xicaucSUMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            b_xicaucSUMv2_df = b_xicaucSUMv2_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='e_sum_XIC\\r\\nAUC[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "            b_xicaucSUMv2_df_nsum = [b_xicaucSUMv2_df.loc[i].sum() for i in b_xicaucSUMv2_df.index.tolist()] # for A bar label\n",
    "            bSUM_dfall_lstv2.append(b_xicaucSUMv2_df)\n",
    "            bSUM_label_lstv2.append('sum_XIC AUC[Byos]')\n",
    "            bSUM_nsum_lstv2.append(b_xicaucSUMv2_df_nsum)\n",
    "        else:\n",
    "            pass\n",
    "        if export_int == 'yes': \n",
    "            # bp union norm v1\n",
    "            bpunion_intNORM_df = bp_union.loc[:, ['N(x) ↓', 'N-site(Byonic ∪ pGlyco) →', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']] \n",
    "            bpunion_intNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            bpunion_intNORM_df = bpunion_intNORM_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=bp_union_new_nx)\n",
    "            bpunionNORM_dfall_lstv1.append(bpunion_intNORM_df)\n",
    "            bpunionNORM_label_lstv1.append('norm_Apex Int.(Posit)[Byos]')\n",
    "            # bp union norm v2\n",
    "            bpunion_intNORMv2_df = bp_union.loc[:, ['nx_version2', 'N-site(Byonic ∪ pGlyco) →', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "            bpunion_intNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            bpunion_intNORMv2_df = bpunion_intNORMv2_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "            bpunionNORM_dfall_lstv2.append(bpunion_intNORMv2_df)\n",
    "            bpunionNORM_label_lstv2.append('norm_Apex Int.(Posit)[Byos]')\n",
    "            # bp inter norm v1\n",
    "            bpinter_intNORM_df = bp_inter.loc[:, ['N(x) ↓', 'N-site(Byonic ∩ pGlyco) →', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "            bpinter_intNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            bpinter_intNORM_df = bpinter_intNORM_df.pivot_table(index='N-site(Byonic ∩ pGlyco) →', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=bp_intersection_new_nx)\n",
    "            bpinterNORM_dfall_lstv1.append(bpinter_intNORM_df)\n",
    "            bpinterNORM_label_lstv1.append('norm_Apex Int.(Posit)[Byos]')\n",
    "            # bp inter norm v2\n",
    "            bpinter_intNORMv2_df = bp_inter.loc[:, ['nx_version2', 'N-site(Byonic ∩ pGlyco) →', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "            bpinter_intNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            bpinter_intNORMv2_df = bpinter_intNORMv2_df.pivot_table(index='N-site(Byonic ∩ pGlyco) →', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "            bpinterNORM_dfall_lstv2.append(bpinter_intNORMv2_df)\n",
    "            bpinterNORM_label_lstv2.append('norm_Apex Int.(Posit)[Byos]')\n",
    "            # onlyb norm v1 \n",
    "            b_intNORM_df = onlyb.loc[:, ['N(x) ↓', 'N-site(SequonBased)[Byonic]', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']] \n",
    "            b_intNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            b_intNORM_df = b_intNORM_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=b_new_nx)\n",
    "            bNORM_dfall_lstv1.append(b_intNORM_df)\n",
    "            bNORM_label_lstv1.append('norm_Apex Int.(Posit)[Byos]')\n",
    "            # onlyb norm v2\n",
    "            b_intNORMv2_df = onlyb.loc[:, ['nx_version2', 'N-site(SequonBased)[Byonic]', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']] \n",
    "            b_intNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            b_intNORMv2_df = b_intNORMv2_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='b_norm_Apex Int.\\r\\n(Posit)[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "            bNORM_dfall_lstv2.append(b_intNORMv2_df)\n",
    "            bNORM_label_lstv2.append('norm_Apex Int.(Posit)[Byos]')\n",
    "            # onlyb sum v1\n",
    "            b_intSUM_df = onlyb.loc[:, ['N(x) ↓', 'N-site(SequonBased)[Byonic]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]']] \n",
    "            b_intSUM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            b_intSUM_df = b_intSUM_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='f_sum_Apex Int.\\r\\n(Posit)[Byos]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=b_new_nx)\n",
    "            b_intSUM_df_nsum = [b_intSUM_df.loc[i].sum() for i in b_intSUM_df.index.tolist()] # for B bar label\n",
    "            bSUM_dfall_lstv1.append(b_intSUM_df)\n",
    "            bSUM_label_lstv1.append('sum_Apex Int.(Posit)[Byos]')\n",
    "            bSUM_nsum_lstv1.append(b_intSUM_df_nsum)\n",
    "            # onlyb sum v2\n",
    "            b_intSUMv2_df = onlyb.loc[:, ['nx_version2', 'N-site(SequonBased)[Byonic]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]']] \n",
    "            b_intSUMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            b_intSUMv2_df = b_intSUMv2_df.pivot_table(index='N-site(SequonBased)[Byonic]', values='f_sum_Apex Int.\\r\\n(Posit)[Byos]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "            b_intSUMv2_df_nsum = [b_intSUMv2_df.loc[i].sum() for i in b_intSUMv2_df.index.tolist()] # for B bar label\n",
    "            bSUM_dfall_lstv2.append(b_intSUMv2_df)\n",
    "            bSUM_label_lstv2.append('sum_Apex Int.(Posit)[Byos]')\n",
    "            bSUM_nsum_lstv2.append(b_intSUMv2_df_nsum)\n",
    "        else:\n",
    "            pass\n",
    "        if export_mono == 'yes':\n",
    "            # bp union norm v1\n",
    "            bpunion_monoNORM_df = bp_union.loc[:, ['N(x) ↓', 'N-site(Byonic ∪ pGlyco) →', 'c_norm_MonoArea[pGlyco]']]\n",
    "            bpunion_monoNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            bpunion_monoNORM_df = bpunion_monoNORM_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='c_norm_MonoArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=bp_union_new_nx)\n",
    "            bpunionNORM_dfall_lstv1.append(bpunion_monoNORM_df)\n",
    "            bpunionNORM_label_lstv1.append('norm_MonoArea[pGlyco]')\n",
    "            # bp union norm v2\n",
    "            bpunion_monoNORMv2_df = bp_union.loc[:, ['nx_version2', 'N-site(Byonic ∪ pGlyco) →', 'c_norm_MonoArea[pGlyco]']]\n",
    "            bpunion_monoNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            bpunion_monoNORMv2_df = bpunion_monoNORMv2_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='c_norm_MonoArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "            bpunionNORM_dfall_lstv2.append(bpunion_monoNORMv2_df)\n",
    "            bpunionNORM_label_lstv2.append('norm_MonoArea[pGlyco]')\n",
    "            # bp inter norm v1\n",
    "            bpinter_monoNORM_df = bp_inter.loc[:, ['N(x) ↓', 'N-site(Byonic ∩ pGlyco) →', 'c_norm_MonoArea[pGlyco]']]\n",
    "            bpinter_monoNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            bpinter_monoNORM_df = bpinter_monoNORM_df.pivot_table(index='N-site(Byonic ∩ pGlyco) →', values='c_norm_MonoArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=bp_intersection_new_nx)\n",
    "            bpinterNORM_dfall_lstv1.append(bpinter_monoNORM_df)\n",
    "            bpinterNORM_label_lstv1.append('norm_MonoArea[pGlyco]')\n",
    "            # bp inter norm v2\n",
    "            bpinter_monoNORMv2_df = bp_inter.loc[:, ['nx_version2', 'N-site(Byonic ∩ pGlyco) →', 'c_norm_MonoArea[pGlyco]']]\n",
    "            bpinter_monoNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            bpinter_monoNORMv2_df = bpinter_monoNORMv2_df.pivot_table(index='N-site(Byonic ∩ pGlyco) →', values='c_norm_MonoArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "            bpinterNORM_dfall_lstv2.append(bpinter_monoNORMv2_df)\n",
    "            bpinterNORM_label_lstv2.append('norm_MonoArea[pGlyco]')\n",
    "            # onlyp norm v1\n",
    "            p_monoNORM_df = onlyp.loc[:, ['N(x) ↓', 'ProSites[pGlyco]', 'c_norm_MonoArea[pGlyco]']]\n",
    "            p_monoNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            p_monoNORM_df = p_monoNORM_df.pivot_table(index='ProSites[pGlyco]', values='c_norm_MonoArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=p_new_nx)\n",
    "            pNORM_dfall_lstv1.append(p_monoNORM_df)\n",
    "            pNORM_label_lstv1.append('norm_MonoArea[pGlyco]')\n",
    "            # onlyp norm v2\n",
    "            p_monoNORMv2_df = onlyp.loc[:, ['nx_version2', 'ProSites[pGlyco]', 'c_norm_MonoArea[pGlyco]']]\n",
    "            p_monoNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            p_monoNORMv2_df = p_monoNORMv2_df.pivot_table(index='ProSites[pGlyco]', values='c_norm_MonoArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "            pNORM_dfall_lstv2.append(p_monoNORMv2_df)\n",
    "            pNORM_label_lstv2.append('norm_MonoArea[pGlyco]')\n",
    "            # onlyp sum v1\n",
    "            p_monoSUM_df = onlyp.loc[:, ['N(x) ↓', 'ProSites[pGlyco]', 'g_sum_MonoArea[pGlyco]']]\n",
    "            p_monoSUM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            p_monoSUM_df = p_monoSUM_df.pivot_table(index='ProSites[pGlyco]', values='g_sum_MonoArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=p_new_nx)\n",
    "            p_monoSUM_df_nsum = [p_monoSUM_df.loc[i].sum() for i in p_monoSUM_df.index.tolist()] # for A bar label\n",
    "            pSUM_dfall_lstv1.append(p_monoSUM_df)\n",
    "            pSUM_label_lstv1.append('sum_MonoArea[pGlyco]')\n",
    "            pSUM_nsum_lstv1.append(p_monoSUM_df_nsum)\n",
    "            # onlyp sum v2\n",
    "            p_monoSUMv2_df = onlyp.loc[:, ['nx_version2', 'ProSites[pGlyco]', 'g_sum_MonoArea[pGlyco]']]\n",
    "            p_monoSUMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            p_monoSUMv2_df = p_monoSUMv2_df.pivot_table(index='ProSites[pGlyco]', values='g_sum_MonoArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "            p_monoSUMv2_df_nsum = [p_monoSUMv2_df.loc[i].sum() for i in p_monoSUMv2_df.index.tolist()] # for A bar label\n",
    "            pSUM_dfall_lstv2.append(p_monoSUMv2_df)\n",
    "            pSUM_label_lstv2.append('sum_MonoArea[pGlyco]')\n",
    "            pSUM_nsum_lstv2.append(p_monoSUMv2_df_nsum)\n",
    "        else:\n",
    "            pass\n",
    "        if export_isotope == 'yes':\n",
    "            # bp union norm v1\n",
    "            bpunion_isoNORM_df = bp_union.loc[:, ['N(x) ↓', 'N-site(Byonic ∪ pGlyco) →', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "            bpunion_isoNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            bpunion_isoNORM_df = bpunion_isoNORM_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='d_norm_IsotopeArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=bp_union_new_nx)\n",
    "            bpunionNORM_dfall_lstv1.append(bpunion_isoNORM_df)\n",
    "            bpunionNORM_label_lstv1.append('norm_IsotopeArea[pGlyco]')\n",
    "            # bp union norm v2\n",
    "            bpunion_isoNORMv2_df = bp_union.loc[:, ['nx_version2', 'N-site(Byonic ∪ pGlyco) →', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "            bpunion_isoNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            bpunion_isoNORMv2_df = bpunion_isoNORMv2_df.pivot_table(index='N-site(Byonic ∪ pGlyco) →', values='d_norm_IsotopeArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "            bpunionNORM_dfall_lstv2.append(bpunion_isoNORMv2_df)\n",
    "            bpunionNORM_label_lstv2.append('norm_IsotopeArea[pGlyco]')\n",
    "            # bp inter norm v1\n",
    "            bpinter_isoNORM_df = bp_inter.loc[:, ['N(x) ↓', 'N-site(Byonic ∩ pGlyco) →', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "            bpinter_isoNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            bpinter_isoNORM_df = bpinter_isoNORM_df.pivot_table(index='N-site(Byonic ∩ pGlyco) →', values='d_norm_IsotopeArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=bp_intersection_new_nx)\n",
    "            bpinterNORM_dfall_lstv1.append(bpinter_isoNORM_df)\n",
    "            bpinterNORM_label_lstv1.append('norm_IsotopeArea[pGlyco]')\n",
    "            # bp inter norm v2\n",
    "            bpinter_isoNORMv2_df = bp_inter.loc[:, ['nx_version2', 'N-site(Byonic ∩ pGlyco) →', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "            bpinter_isoNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            bpinter_isoNORMv2_df = bpinter_isoNORMv2_df.pivot_table(index='N-site(Byonic ∩ pGlyco) →', values='d_norm_IsotopeArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "            bpinterNORM_dfall_lstv2.append(bpinter_isoNORMv2_df)\n",
    "            bpinterNORM_label_lstv2.append('norm_IsotopeArea[pGlyco]')\n",
    "            # onlyp norm v1\n",
    "            p_isoNORM_df = onlyp.loc[:, ['N(x) ↓', 'ProSites[pGlyco]', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "            p_isoNORM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            p_isoNORM_df = p_isoNORM_df.pivot_table(index='ProSites[pGlyco]', values='d_norm_IsotopeArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=p_new_nx)\n",
    "            pNORM_dfall_lstv1.append(p_isoNORM_df)\n",
    "            pNORM_label_lstv1.append('norm_IsotopeArea[pGlyco]')\n",
    "            # onlyp norm v2\n",
    "            p_isoNORMv2_df = onlyp.loc[:, ['nx_version2', 'ProSites[pGlyco]', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "            p_isoNORMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            p_isoNORMv2_df = p_isoNORMv2_df.pivot_table(index='ProSites[pGlyco]', values='d_norm_IsotopeArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "            pNORM_dfall_lstv2.append(p_isoNORMv2_df)\n",
    "            pNORM_label_lstv2.append('norm_IsotopeArea[pGlyco]')\n",
    "            # onlyp sum v1\n",
    "            p_isoSUM_df = onlyp.loc[:, ['N(x) ↓', 'ProSites[pGlyco]', 'h_sum_IsotopeArea[pGlyco]']] \n",
    "            p_isoSUM_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            p_isoSUM_df = p_isoSUM_df.pivot_table(index='ProSites[pGlyco]', values='h_sum_IsotopeArea[pGlyco]', columns='N(x) ↓', aggfunc=np.sum).reindex(columns=p_new_nx)\n",
    "            p_isoSUM_df_nsum = [p_isoSUM_df.loc[i].sum() for i in p_isoSUM_df.index.tolist()] # for B bar label\n",
    "            pSUM_dfall_lstv1.append(p_isoSUM_df)\n",
    "            pSUM_label_lstv1.append('sum_IsotopeArea[pGlyco]')\n",
    "            pSUM_nsum_lstv1.append(p_isoSUM_df_nsum)\n",
    "            # onlyp sum v2\n",
    "            p_isoSUMv2_df = onlyp.loc[:, ['nx_version2', 'ProSites[pGlyco]', 'h_sum_IsotopeArea[pGlyco]']] \n",
    "            p_isoSUMv2_df.replace(to_replace = -1, value = np.nan , inplace = True)\n",
    "            p_isoSUMv2_df = p_isoSUMv2_df.pivot_table(index='ProSites[pGlyco]', values='h_sum_IsotopeArea[pGlyco]', columns='nx_version2', aggfunc=np.sum).reindex(columns=col_order)\n",
    "            p_isoSUMv2_df_nsum = [p_isoSUMv2_df.loc[i].sum() for i in p_isoSUMv2_df.index.tolist()] # for B bar label\n",
    "            pSUM_dfall_lstv2.append(p_isoSUMv2_df)\n",
    "            pSUM_label_lstv2.append('sum_IsotopeArea[pGlyco]')\n",
    "            pSUM_nsum_lstv2.append(p_isoSUMv2_df_nsum)\n",
    "        else:\n",
    "            pass\n",
    "        # bp_union NORMv1\n",
    "        fig1 = plot_clustered_stacked(bpunionNORM_dfall_lstv1, [[1]*len(bpunionNORM_dfall_lstv1[0].index) for i in range(len(bpunionNORM_dfall_lstv1))], bpunionNORM_label_lstv1)\n",
    "        fig1.tight_layout()\n",
    "        fig1.savefig(f'{date}_{filename}_bpUnionNORMv1_Figures.png')\n",
    "\n",
    "        # bp_union NORMv2\n",
    "        fig2 = plot_clustered_stacked(bpunionNORM_dfall_lstv2, [[1]*len(bpunionNORM_dfall_lstv2[0].index) for i in range(len(bpunionNORM_dfall_lstv2))], bpunionNORM_label_lstv2, neugc_exist=bpunion_neugc_exist)\n",
    "        fig2.tight_layout()\n",
    "        fig2.savefig(f'{date}_{filename}_bpUnionNORMv2_Figures.png')\n",
    "\n",
    "        # bp_intersection NORMv1\n",
    "        fig3 = plot_clustered_stacked(bpinterNORM_dfall_lstv1, [[1]*len(bpinterNORM_dfall_lstv1[0].index) for i in range(len(bpinterNORM_dfall_lstv1))], bpinterNORM_label_lstv1)\n",
    "        fig3.tight_layout()\n",
    "        fig3.savefig(f'{date}_{filename}_bpInterNORMv1_Figures.png')\n",
    "\n",
    "        # bp_intersection NORMv2\n",
    "        fig4 = plot_clustered_stacked(bpinterNORM_dfall_lstv2, [[1]*len(bpinterNORM_dfall_lstv2[0].index) for i in range(len(bpinterNORM_dfall_lstv2))], bpinterNORM_label_lstv2, neugc_exist=bpinter_neugc_exist)\n",
    "        fig4.tight_layout()\n",
    "        fig4.savefig(f'{date}_{filename}_bpInterNORMv2_Figures.png')\n",
    "\n",
    "        # onlyb NORMv1\n",
    "        fig5 = plot_clustered_stacked(bNORM_dfall_lstv1, [[1]*len(bNORM_dfall_lstv1[0].index) for i in range(len(bNORM_dfall_lstv1))],bNORM_label_lstv1)\n",
    "        fig5.tight_layout()\n",
    "        fig5.savefig(f'{date}_{filename}_onlybNORMv1_Figures.png')\n",
    "\n",
    "        # onlyb NORMv2\n",
    "        fig6 = plot_clustered_stacked(bNORM_dfall_lstv2, [[1]*len(bNORM_dfall_lstv2[0].index) for i in range(len(bNORM_dfall_lstv2))],bNORM_label_lstv2, neugc_exist=b_neugc_exist)\n",
    "        fig6.tight_layout()\n",
    "        fig6.savefig(f'{date}_{filename}_onlybNORMv2_Figures.png')\n",
    "\n",
    "        # onlyb SUMv1\n",
    "        fig7 = plot_clustered_stacked(bSUM_dfall_lstv1, bSUM_nsum_lstv1,bSUM_label_lstv1)\n",
    "        fig7.tight_layout()\n",
    "        fig7.savefig(f'{date}_{filename}_onlybSUMv1_Figures.png')\n",
    "\n",
    "        # onlyb SUMv2\n",
    "        fig8 = plot_clustered_stacked(bSUM_dfall_lstv2,bSUM_nsum_lstv2 ,bSUM_label_lstv2, neugc_exist=b_neugc_exist)\n",
    "        fig8.tight_layout()\n",
    "        fig8.savefig(f'{date}_{filename}_onlybSUMv2_Figures.png')\n",
    "\n",
    "        # onlyp NORMv1\n",
    "        fig9 = plot_clustered_stacked(pNORM_dfall_lstv1,[[1]*len(pNORM_dfall_lstv1[0].index) for i in range(len(pNORM_dfall_lstv1))],pNORM_label_lstv1)\n",
    "        fig9.tight_layout()\n",
    "        fig9.savefig(f'{date}_{filename}_onlypNORMv1_Figures.png')\n",
    "\n",
    "        # onlyp NORMv2\n",
    "        fig10 = plot_clustered_stacked(pNORM_dfall_lstv2,[[1]*len(pNORM_dfall_lstv2[0].index) for i in range(len(pNORM_dfall_lstv2))],pNORM_label_lstv2, neugc_exist=p_neugc_exist)\n",
    "        fig10.tight_layout()\n",
    "        fig10.savefig(f'{date}_{filename}_onlypNORMv2_Figures.png')\n",
    "\n",
    "        # onlyp SUMv1\n",
    "        fig11 = plot_clustered_stacked(pSUM_dfall_lstv1,pSUM_nsum_lstv1,pSUM_label_lstv1)\n",
    "        fig11.tight_layout()\n",
    "        fig11.savefig(f'{date}_{filename}_onlypSUMv1_Figures.png')\n",
    "\n",
    "        # onlyp SUMv2\n",
    "        fig12 = plot_clustered_stacked(pSUM_dfall_lstv2,pSUM_nsum_lstv2 ,pSUM_label_lstv2, neugc_exist=p_neugc_exist)\n",
    "        fig12.tight_layout()\n",
    "        fig12.savefig(f'{date}_{filename}_onlypSUMv2_Figures.png')\n",
    "    elif byonicfile != '' and byosfile == '' and pglycofile != '': # byonic + pglyco \n",
    "        print('----- Start combining Byonic & pGlyco. -----\\n')\n",
    "        # combined data based on 'Scan'\n",
    "        byonic_scanasid = byonic_df.copy()\n",
    "        new_byonic_col = [n + '[Byonic]' if n != 'Scan' else n for n in byonic_scanasid.columns]\n",
    "        byonic_scanasid.columns = new_byonic_col\n",
    "        pglyco_scanasid = pglyco_df.copy()\n",
    "        new_pglyco_col = [n + '[pGlyco]' if n != 'Scan' else n for n in pglyco_scanasid.columns]\n",
    "        pglyco_scanasid.columns = new_pglyco_col\n",
    "        byonic_scanasid = byonic_scanasid.set_index('Scan')\n",
    "        pglyco_scanasid = pglyco_scanasid.set_index('Scan')\n",
    "        # align scan & concat (all align on row to make row number all the same)\n",
    "        a1, a2 = byonic_scanasid.align(pglyco_scanasid, join = 'outer', axis = 0) # row: a1 = a2\n",
    "        all_combined_df = pd.concat([a1,a2], axis = 1)\n",
    "        all_combined_df.index.name = 'Scan'\n",
    "        all_combined_df.reset_index(level=0, inplace=True)\n",
    "        # change all nan to blank -1\n",
    "        all_combined_df = all_combined_df.fillna(-1)\n",
    "        move_df(all_combined_df, 'ProSites[pGlyco]', 'N-site(SequonBased)[Byonic]')\n",
    "        ## result post-processing \n",
    "        glycansource(all_combined_df, 'Scan')\n",
    "        print('\\nCombined data shape:\\nrow --> %s, column --> %s'%(all_combined_df.shape[0], all_combined_df.shape[1]))\n",
    "        ## style apply for excel export\n",
    "        # color the rows below the threshold (threshold [byonic: score > 200 & pep2d < 0.001; pglyco: PepScore>5 & GlyScore>4])\n",
    "        # color code => #ffedcc -> light orange for byonic; #add8e6 -> light blue for pglyco; #FFB6C1 -> light pink for byos w/ dif calm ^ seq from byonic; #FF1493 -> deep pink for byos w/ dif calm & seq from byonic; #FFFF00 -> yellow for byos & byonic all the same\n",
    "        threshold_masks_colorind(all_combined_df)\n",
    "        # analyze PSM (need to pass threshold)\n",
    "        byonic_colored_id = list(set(lightgreen_ind + normalgreen_ind + lightorange_ind + normalorange_ind + deepgreen_ind)) # byonic pass threshold\n",
    "        byonic_belowthreshold_id = [i for i in all_combined_df.index.tolist() if i not in byonic_colored_id]\n",
    "        pglyco_colored_id = list(set(lightblue_ind + normalblue_ind + lightorange_ind + normalorange_ind + deepblue_ind)) # pglyco pass threshold\n",
    "        pglyco_belowthreshold_id = [i for i in all_combined_df.index.tolist() if i not in pglyco_colored_id]\n",
    "        # using groupby size function to count psm & add psm columns (new criterion: RT/scantime dif < 3 min (180s). is regarded as the same, >= 3 min. should be seen as dif)\n",
    "        # byonic\n",
    "        all_combined_df = all_combined_df.astype({'N-site(SequonBased)[Byonic]': 'str'}) # convert list & tuple to str for later groupby function\n",
    "        all_combined_df['to_subtract[Byonic]'] = all_combined_df.loc[all_combined_df.groupby(['N-site(SequonBased)[Byonic]', 'Calc.\\r\\nm/z[Byonic]','Glycans[Byonic]', 'PureSequence[Byonic]'])['Score[Byonic]'].idxmax(), 'Scan\\r\\nTime[Byonic]'] # get the rt of highest score as ref for rt_dif < 3 min.\n",
    "        all_combined_df['to_subtract_fillna[Byonic]'] = all_combined_df.groupby(['N-site(SequonBased)[Byonic]', 'Calc.\\r\\nm/z[Byonic]','Glycans[Byonic]', 'PureSequence[Byonic]'])['to_subtract[Byonic]'].transform(lambda x: x.fillna(x.mean())) # fillna w/ rt of highest score\n",
    "        all_combined_df['rt_dif[Byonic]'] = (all_combined_df['Scan\\r\\nTime[Byonic]'] - all_combined_df['to_subtract_fillna[Byonic]']).abs() # get absolute dif\n",
    "        all_combined_df['rt_dif_reset[Byonic]'] = [0 if dif < byonic_rt else dif for dif in all_combined_df['rt_dif[Byonic]']] # if rt_dif < 3, then reset the dif to 0 -> seen as the same\n",
    "        byonic_psm = all_combined_df.groupby(['N-site(SequonBased)[Byonic]', 'Calc.\\r\\nm/z[Byonic]','Glycans[Byonic]', 'PureSequence[Byonic]', 'rt_dif_reset[Byonic]'])['N-site(SequonBased)[Byonic]'].transform('size')\n",
    "        all_combined_df.insert(all_combined_df.columns.get_loc('N-site(SequonBased)[Byonic]') + 1 , 'PSM[Byonic]', byonic_psm , True)\n",
    "        all_combined_df.loc[(all_combined_df['N-site(SequonBased)[Byonic]'] == 'N/A'), 'PSM[Byonic]'] = 'N/A' # if n-site is 'N/A', do not count psm\n",
    "        all_combined_df.loc[byonic_belowthreshold_id, 'PSM[Byonic]'] = 'N/A' # do not count psm for rows below threshold\n",
    "        all_combined_df.loc[(all_combined_df['N-site(SequonBased)[Byonic]'] == '-1'), 'PSM[Byonic]'] = -1 # if site is '-1', then psm set to -1\n",
    "        # pglyco\n",
    "        all_combined_df = all_combined_df.astype({'ProSites[pGlyco]': 'int'})\n",
    "        all_combined_df = all_combined_df.astype({'ProSites[pGlyco]': 'str'}) # convert list & tuple to str for later groupby function\n",
    "        all_combined_df['to_subtract[pGlyco]'] = all_combined_df.loc[all_combined_df.groupby(['ProSites[pGlyco]', 'PrecursorMZ[pGlyco]','GlycanComposition_ByonicStyle[pGlyco]', 'Peptide[pGlyco]'])['GlyScore[pGlyco]'].idxmax(), 'RT[pGlyco]'] # get the rt of highest score as ref for rt_dif < 3 min.\n",
    "        all_combined_df['to_subtract_fillna[pGlyco]'] = all_combined_df.groupby(['ProSites[pGlyco]', 'PrecursorMZ[pGlyco]','GlycanComposition_ByonicStyle[pGlyco]', 'Peptide[pGlyco]'])['to_subtract[pGlyco]'].transform(lambda x: x.fillna(x.mean())) # fillna w/ rt of highest score\n",
    "        all_combined_df['rt_dif[pGlyco]'] = (all_combined_df['RT[pGlyco]'] - all_combined_df['to_subtract_fillna[pGlyco]']).abs() # get absolute dif\n",
    "        all_combined_df['rt_dif_reset[pGlyco]'] = [0 if dif < pglyco_rt else dif for dif in all_combined_df['rt_dif[pGlyco]']] # if rt_dif < 3, then reset the dif to 0 -> seen as the same\n",
    "        pglyco_psm = all_combined_df.groupby(['ProSites[pGlyco]', 'PrecursorMZ[pGlyco]','GlycanComposition_ByonicStyle[pGlyco]', 'Peptide[pGlyco]', 'rt_dif_reset[pGlyco]'])['ProSites[pGlyco]'].transform('size')\n",
    "        all_combined_df.insert(all_combined_df.columns.get_loc('ProSites[pGlyco]') + 1 , 'PSM[pGlyco]', pglyco_psm , True)\n",
    "        all_combined_df.loc[(all_combined_df['ProSites[pGlyco]'] == 'N/A'), 'PSM[pGlyco]'] = 'N/A' # if n-site is 'N/A', do not count psm\n",
    "        all_combined_df.loc[pglyco_belowthreshold_id, 'PSM[pGlyco]'] = 'N/A' # do not count psm for rows below threshold\n",
    "        all_combined_df.loc[(all_combined_df['ProSites[pGlyco]'] == '-1'), 'PSM[pGlyco]'] = -1 # if site is '-1', then psm set to -1\n",
    "        all_forsimple_df = all_combined_df.copy() # to retain rt_dif_reset for simple df groupy and get unique row\n",
    "        all_combined_df = all_combined_df.drop(['to_subtract[Byonic]', 'to_subtract_fillna[Byonic]', 'rt_dif[Byonic]', 'rt_dif_reset[Byonic]', 'to_subtract[pGlyco]', 'to_subtract_fillna[pGlyco]', 'rt_dif[pGlyco]', 'rt_dif_reset[pGlyco]'], axis = 1) # drop the intermediate cols\n",
    "\n",
    "        print('\\n----- Exporting \"_All\" file... This may take some time, please wait. -----\\n')\n",
    "        all_combined_df.style.apply(bg_color, axis=None).to_excel(f'{date}_{filename}_All.xlsx', index = False)  \n",
    "        print('\\n----- \"_All\" file exported. -----\\n')\n",
    "        \n",
    "        if 'Pair[Byonic]' in all_combined_df.columns.tolist():\n",
    "            # ONLY FOR HCD/ETD FILES: prepare '_Pair' file (as long as byonic passes threshold & have pair)\n",
    "            all_combined_df = all_combined_df.astype({'Pair[Byonic]': 'str'})\n",
    "            pair_df = all_combined_df.loc[byonic_colored_id]\n",
    "            pair_df = pair_df[pair_df['Pair[Byonic]'].str.contains('pair')]\n",
    "            pair_df = pair_df[pair_df.duplicated(subset=['Pair[Byonic]'], keep=False)] # only paired data included in _Pair\n",
    "            threshold_masks_colorind(pair_df)\n",
    "            print('\\n----- Exporting \"_Pair\" file... This may take some time, please wait. -----\\n')\n",
    "#             pair_df.style.apply(bg_color, axis=None).to_excel(f'{date}_{filename}_Pair.xlsx', index = False)  \n",
    "            print('\\n----- \"_Pair\" file exported. -----\\n')\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        print('----- Start preparing simplified version. -----\\n')\n",
    "        # extract rows included in colored indices list separately\n",
    "        byonicbyos_col_range = ['Scan'] + [col for col in all_forsimple_df.columns.tolist() if '[Byonic]' in col or '[Byos]' in col]\n",
    "        pglyco_col_range = ['Scan'] + [col for col in all_forsimple_df.columns.tolist() if '[pGlyco]' in col]\n",
    "        simple_byonicbyos = all_forsimple_df.loc[byonic_colored_id, byonicbyos_col_range] # extract colored (pass threshold) rows\n",
    "        simple_byonicbyos = simple_byonicbyos[(simple_byonicbyos['N-site(SequonBased)[Byonic]'] != 'N/A')&(simple_byonicbyos['N-site(SequonBased)[Byonic]'] != '-1')] # for simplified, n-site must exist\n",
    "        simple_pglyco = all_forsimple_df.loc[pglyco_colored_id, pglyco_col_range] # extract colored (pass threshold) rows\n",
    "        simple_pglyco = simple_pglyco[(simple_pglyco['ProSites[pGlyco]'] != 'N/A')&(simple_pglyco['ProSites[pGlyco]'] != '-1')] # for simplified, n-site must exist\n",
    "        simple_pglyco = simple_pglyco.loc[simple_pglyco['FragmentType[pGlyco]'] == 'hcd'] # pglyco etd has the same values as hcd, so only let hcd enter unique file\n",
    "        # get unique calc.m/z by groupby & idxmax function to find highest score within each gp and preserve (remember to split the simple_df into byonicbyos & pglyco parts to avoid dropping non-target rows)\n",
    "        simple_byonicbyos = simple_byonicbyos.groupby(['N-site(SequonBased)[Byonic]', 'Calc.\\r\\nm/z[Byonic]','Glycans[Byonic]', 'PureSequence[Byonic]', 'rt_dif_reset[Byonic]'], as_index=False).apply(lambda x: x.loc[x['Score[Byonic]'].idxmax()]).reset_index(drop=True)\n",
    "        simple_pglyco = simple_pglyco.groupby(['ProSites[pGlyco]', 'PrecursorMZ[pGlyco]','GlycanComposition_ByonicStyle[pGlyco]', 'Peptide[pGlyco]', 'rt_dif_reset[pGlyco]'], as_index=False).apply(lambda x: x.loc[x['GlyScore[pGlyco]'].idxmax()]).reset_index(drop=True)\n",
    "\n",
    "        # set scan to index & concat simple_byonicbyos & simple_pglyco by scan\n",
    "        simple_byonicbyos = simple_byonicbyos.set_index('Scan')\n",
    "        simple_pglyco = simple_pglyco.set_index('Scan')\n",
    "        a1, a2 = simple_byonicbyos.align(simple_pglyco, join = 'outer', axis = 0) # row: a1 = a2\n",
    "        id_df = pd.concat([a1,a2], axis = 1)\n",
    "        id_df.index.name = 'Scan'\n",
    "        id_df.reset_index(level=0, inplace=True)\n",
    "        # change all nan to blank -1\n",
    "        id_df = id_df.fillna(-1)\n",
    "        # extract nglycan numbers in Mods & use it to calculate byonic pep mass \n",
    "        mods_nglycan_sum = [sum([ast.literal_eval(v) for v in lst]) if type(lst) == list else -1 for lst in id_df['Mods\\r\\n(variable)[Byonic]'].str.findall(r'Glycan / (\\d+.\\d+)').tolist()]\n",
    "        id_df['glycan_mods_sum[Byonic]'] = mods_nglycan_sum\n",
    "        id_df['PepMS[Byonic]'] = id_df['Calc.\\r\\nMH[Byonic]'] - id_df['glycan_mods_sum[Byonic]']\n",
    "        id_df.loc[(id_df['glycan_mods_sum[Byonic]'] == -1), 'PepMS[Byonic]'] = -1\n",
    "        move_df(id_df, 'ProSites[pGlyco]', 'N-site(SequonBased)[Byonic]')\n",
    "        move_df(id_df, 'PepMS[Byonic]', 'Fragment\\r\\nType[Byonic]')\n",
    "        # ast.literaleval byonicbyos n-site & sorting: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic clam/z -> pglcyo calm/z\n",
    "        id_df['N-site(SequonBased)[Byonic]'] = [ast.literal_eval(i) if type(i) == str and '(' not in i else i for i in id_df['N-site(SequonBased)[Byonic]'].tolist()] # convert str back to int & tuple\n",
    "        id_df['ProSites[pGlyco]'] = [ast.literal_eval(i) if type(i) == str and '(' not in i else i for i in id_df['ProSites[pGlyco]'].tolist()] # convert str back to int & tuple\n",
    "        \n",
    "        id_df.loc[(id_df['N-site(SequonBased)[Byonic]'] == -1), 'mock_site[Byonic]'] = id_df['ProSites[pGlyco]']\n",
    "        id_df.loc[(id_df['N-site(SequonBased)[Byonic]'] != -1), 'mock_site[Byonic]'] = id_df['N-site(SequonBased)[Byonic]']\n",
    "        # drop intermediate cols\n",
    "        id_df = id_df.drop(['to_subtract[Byonic]', 'to_subtract_fillna[Byonic]', 'rt_dif[Byonic]', 'rt_dif_reset[Byonic]', 'to_subtract[pGlyco]', 'to_subtract_fillna[pGlyco]', 'rt_dif[pGlyco]', 'rt_dif_reset[pGlyco]', 'glycan_mods_sum[Byonic]'], axis = 1) # drop the intermediate cols\n",
    "        glycansource(id_df, 'Scan')\n",
    "        move_df(id_df, 'mock_site[Byonic]', 'GlycanSource')\n",
    "        col_order = id_df.columns.tolist()\n",
    "        # sorting order: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic calm/z -> pglcyo calm/z => all of this can be acheive with sort_values to multi cols.\n",
    "\n",
    "        id_df = sort_intstr_col(id_df, 'Charge[pGlyco]')\n",
    "        print('Done sorting by Charge[pGlyco] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'PrecursorMH[pGlyco]')\n",
    "        print('Done sorting by PrecursorMH[pGlyco] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'PeptideMH[pGlyco]')\n",
    "        print('Done sorting by PeptideMH[pGlyco] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'GlycanComposition_ByonicStyle[pGlyco]')\n",
    "        print('Done sorting by GlycanComposition_ByonicStyle[pGlyco] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'Peptide[pGlyco]')\n",
    "        print('Done sorting by Peptide[pGlyco] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'z[Byonic]')\n",
    "        print('Done sorting by z[Byonic] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'Calc.\\r\\nMH[Byonic]')\n",
    "        print('Done sorting by Calc.MH[Byonic] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'PepMS[Byonic]')\n",
    "        print('Done sorting by PepMS[Byonic] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'Glycans[Byonic]')\n",
    "        print('Done sorting by Glycans[Byonic] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'PureSequence[Byonic]')\n",
    "        print('Done sorting by PureSequence[Byonic] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'mock_site[Byonic]')\n",
    "        print('Done sorting by mock_site[Byonic] (added during processing)')\n",
    "\n",
    "        # convert '-1' back to int -1 for correct glycansource analysis\n",
    "        id_df['Glycans[Byonic]'] = [int(i) if i == '-1' else i for i in id_df['Glycans[Byonic]']]\n",
    "        id_df['GlycanComposition_ByonicStyle[pGlyco]'] = [int(i) if i == '-1' else i for i in id_df['GlycanComposition_ByonicStyle[pGlyco]']]\n",
    "        id_df = id_df[col_order]\n",
    "        threshold_masks_colorind(id_df)\n",
    "        print('\\n----- Exporting \"_UniquePep\" file... This may take some time, please wait. -----\\n')\n",
    "#         id_df.style.apply(bg_color, axis=None).to_excel(f'{date}_{filename}_UniquePep.xlsx', index = False)  \n",
    "        print('\\n----- \"_UniquePep\" file exported. -----\\n')\n",
    "    \n",
    "    elif byonicfile != '' and byosfile == '' and pglycofile == '': # only byonic\n",
    "        print('----- Only Byonic file is detected. Start the corresponding processing. -----\\n')\n",
    "        # change the variable name\n",
    "        all_combined_df = byonic_df\n",
    "        # make sure scan is at the start\n",
    "        all_combined_df = all_combined_df.set_index('Scan')\n",
    "        all_combined_df.reset_index(level=0, inplace=True)\n",
    "        ## style apply for excel export\n",
    "        # color the rows below the threshold (threshold [byonic: score > 200 & pep2d < 0.001; pglyco: PepScore>5 & GlyScore>4])\n",
    "        # color code => #ffedcc -> light orange for byonic; #add8e6 -> light blue for pglyco; #FFB6C1 -> light pink for byos w/ dif calm ^ seq from byonic; #FF1493 -> deep pink for byos w/ dif calm & seq from byonic; #FFFF00 -> yellow for byos & byonic all the same\n",
    "        threshold_masks_colorind(all_combined_df)\n",
    "        # analyze PSM (need to pass threshold)\n",
    "        byonic_colored_id = list(set(lightgreen_ind + normalgreen_ind)) # byonic pass threshold\n",
    "        byonic_belowthreshold_id = [i for i in all_combined_df.index.tolist() if i not in byonic_colored_id]\n",
    "        \n",
    "        # using groupby size function to count psm & add psm columns (new criterion: RT/scantime dif < 3 min (180s). is regarded as the same, >= 3 min. should be seen as dif)\n",
    "        # byonic\n",
    "        all_combined_df = all_combined_df.astype({'N-site(SequonBased)': 'str'}) # convert list & tuple to str for later groupby function\n",
    "        all_combined_df['to_subtract'] = all_combined_df.loc[all_combined_df.groupby(['N-site(SequonBased)', 'Calc.\\r\\nm/z','Glycans', 'PureSequence'])['Score'].idxmax(), 'Scan\\r\\nTime'] # get the rt of highest score as ref for rt_dif < 3 min.\n",
    "        all_combined_df['to_subtract_fillna'] = all_combined_df.groupby(['N-site(SequonBased)', 'Calc.\\r\\nm/z','Glycans', 'PureSequence'])['to_subtract'].transform(lambda x: x.fillna(x.mean())) # fillna w/ rt of highest score\n",
    "        all_combined_df['rt_dif'] = (all_combined_df['Scan\\r\\nTime'] - all_combined_df['to_subtract_fillna']).abs() # get absolute dif\n",
    "        all_combined_df['rt_dif_reset'] = [0 if dif < byonic_rt else dif for dif in all_combined_df['rt_dif']] # if rt_dif < 3, then reset the dif to 0 -> seen as the same\n",
    "        byonic_psm = all_combined_df.groupby(['N-site(SequonBased)', 'Calc.\\r\\nm/z','Glycans', 'PureSequence', 'rt_dif_reset'])['N-site(SequonBased)'].transform('size')\n",
    "        all_combined_df.insert(all_combined_df.columns.get_loc('N-site(SequonBased)') + 1 , 'PSM', byonic_psm , True)\n",
    "        all_combined_df.loc[(all_combined_df['N-site(SequonBased)'] == 'N/A'), 'PSM'] = 'N/A' # if n-site is 'N/A', do not count psm\n",
    "        all_combined_df.loc[byonic_belowthreshold_id, 'PSM'] = 'N/A' # do not count psm for rows below threshold\n",
    "        all_combined_df.loc[(all_combined_df['N-site(SequonBased)'] == '-1'), 'PSM'] = -1 # if site is '-1', then psm set to -1\n",
    "        all_forsimple_df = all_combined_df.copy() # to retain rt_dif_reset for simple df groupy and get unique row\n",
    "        all_combined_df = all_combined_df.drop(['to_subtract', 'to_subtract_fillna', 'rt_dif', 'rt_dif_reset'], axis = 1) # drop the intermediate cols\n",
    "        print('\\n----- Exporting \"_All\" file... This may take some time, please wait. -----\\n')\n",
    "        all_combined_df.style.apply(bg_color, axis=None).to_excel(f'{date}_{filename}_All.xlsx', index = False)  \n",
    "        print('\\n----- \"_All\" file exported. -----\\n')\n",
    "        \n",
    "        if 'Pair' in all_combined_df.columns.tolist():\n",
    "            # ONLY FOR HCD/ETD FILES: prepare '_Pair' file (as long as byonic passes threshold & have pair)\n",
    "            all_combined_df = all_combined_df.astype({'Pair': 'str'})\n",
    "            pair_df = all_combined_df.loc[byonic_colored_id]\n",
    "            pair_df = pair_df[pair_df['Pair'].str.contains('pair')]\n",
    "            pair_df = pair_df[pair_df.duplicated(subset=['Pair'], keep=False)] # only paired data included in _Pair\n",
    "            threshold_masks_colorind(pair_df)\n",
    "            print('\\n----- Exporting \"_Pair\" file... This may take some time, please wait. -----\\n')\n",
    "            pair_df.style.apply(bg_color, axis=None).to_excel(f'{date}_{filename}_Pair.xlsx', index = False)  \n",
    "            print('\\n----- \"_Pair\" file exported. -----\\n')\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        print('----- Start preparing simplified version. -----\\n')\n",
    "        # extract rows included in colored indices list\n",
    "        simple_byonicbyos = all_forsimple_df.loc[byonic_colored_id, :] # extract colored (pass threshold) rows\n",
    "        simple_byonicbyos = simple_byonicbyos[(simple_byonicbyos['N-site(SequonBased)'] != 'N/A')&(simple_byonicbyos['N-site(SequonBased)'] != '-1')] # for simplified, n-site must exist\n",
    "        \n",
    "        # get unique calc.m/z by groupby & idxmax function to find highest score within each gp and preserve (remember to split the simple_df into byonicbyos & pglyco parts to avoid dropping non-target rows)\n",
    "        simple_byonicbyos = simple_byonicbyos.groupby(['N-site(SequonBased)', 'Calc.\\r\\nm/z','Glycans', 'PureSequence', 'rt_dif_reset'], as_index=False).apply(lambda x: x.loc[x['Score'].idxmax()]).reset_index(drop=True)\n",
    "        \n",
    "        # change variable name\n",
    "        id_df = simple_byonicbyos\n",
    "        \n",
    "        # make sure 'Scan' is the 1st col\n",
    "        id_df = id_df.set_index('Scan')\n",
    "        id_df.reset_index(level=0, inplace=True)\n",
    "        \n",
    "        # extract nglycan numbers in Mods & use it to calculate byonic pep mass \n",
    "        mods_nglycan_sum = [sum([ast.literal_eval(v) for v in lst]) if type(lst) == list else -1 for lst in id_df['Mods\\r\\n(variable)'].str.findall(r'Glycan / (\\d+.\\d+)').tolist()]\n",
    "        id_df['glycan_mods_sum'] = mods_nglycan_sum\n",
    "        id_df['PepMS'] = id_df['Calc.\\r\\nMH'] - id_df['glycan_mods_sum']\n",
    "        id_df.loc[(id_df['glycan_mods_sum'] == -1), 'PepMS'] = -1\n",
    "        move_df(id_df, 'PepMS', 'Fragment\\r\\nType')\n",
    "        # ast.literaleval byonicbyos n-site & sorting: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic clam/z -> pglcyo calm/z\n",
    "        id_df['N-site(SequonBased)'] = [ast.literal_eval(i) if type(i) == str and '(' not in i else i for i in id_df['N-site(SequonBased)'].tolist()] # convert str back to int & tuple\n",
    "        # drop intermediate cols\n",
    "        id_df = id_df.drop(['to_subtract', 'to_subtract_fillna', 'rt_dif', 'rt_dif_reset', 'glycan_mods_sum'], axis = 1) # drop the intermediate cols\n",
    "        col_order = id_df.columns.tolist()\n",
    "        # sorting order: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic calm/z -> pglcyo calm/z => all of this can be acheive with sort_values to multi cols.\n",
    "\n",
    "        id_df = sort_intstr_col(id_df, 'z')\n",
    "        print('Done sorting by z[Byonic] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'Calc.\\r\\nMH')\n",
    "        print('Done sorting by Calc.MH --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'PepMS')\n",
    "        print('Done sorting by PepMS --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'Glycans')\n",
    "        print('Done sorting by Glycans --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'PureSequence')\n",
    "        print('Done sorting by PureSequence --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'N-site(SequonBased)')\n",
    "        print('Done sorting by N-site(SequonBased)')\n",
    "\n",
    "        # convert '-1' back to int -1 for correct glycansource analysis\n",
    "        id_df['Glycans'] = [int(i) if i == '-1' else i for i in id_df['Glycans']]\n",
    "        id_df = id_df[col_order]\n",
    "        threshold_masks_colorind(id_df)\n",
    "        print('\\n----- Exporting \"_UniquePep\" file... This may take some time, please wait. -----\\n')\n",
    "        id_df.style.apply(bg_color, axis=None).to_excel(f'{date}_{filename}_UniquePep.xlsx', index = False)  \n",
    "        print('\\n----- \"_UniquePep\" file exported. -----\\n')\n",
    "    elif byonicfile == '' and byosfile == '' and pglycofile != '': # only pglyco\n",
    "        print('----- Only pGlyco file is detected. Start the corresponding processing. -----\\n')\n",
    "        # change the variable name\n",
    "        all_combined_df = pglyco_df\n",
    "        # make sure scan is at the start\n",
    "        all_combined_df = all_combined_df.set_index('Scan')\n",
    "        all_combined_df.reset_index(level=0, inplace=True)\n",
    "        print('\\nCombined data shape:\\nrow --> %s, column --> %s'%(all_combined_df.shape[0], all_combined_df.shape[1]))\n",
    "        ## style apply for excel export\n",
    "        # color the rows below the threshold (threshold [byonic: score > 200 & pep2d < 0.001; pglyco: PepScore>5 & GlyScore>4])\n",
    "        # color code => #ffedcc -> light orange for byonic; #add8e6 -> light blue for pglyco; #FFB6C1 -> light pink for byos w/ dif calm ^ seq from byonic; #FF1493 -> deep pink for byos w/ dif calm & seq from byonic; #FFFF00 -> yellow for byos & byonic all the same\n",
    "        threshold_masks_colorind(all_combined_df)\n",
    "        # analyze PSM (need to pass threshold)\n",
    "        pglyco_colored_id = list(set(lightblue_ind + normalblue_ind)) # pglyco pass threshold\n",
    "        pglyco_belowthreshold_id = [i for i in all_combined_df.index.tolist() if i not in pglyco_colored_id]\n",
    "        # using groupby size function to count psm & add psm columns (new criterion: RT/scantime dif < 3 min (180s). is regarded as the same, >= 3 min. should be seen as dif)\n",
    "        # pglyco\n",
    "        all_combined_df = all_combined_df.astype({'ProSites': 'int'})\n",
    "        all_combined_df = all_combined_df.astype({'ProSites': 'str'}) # convert list & tuple to str for later groupby function\n",
    "        all_combined_df['to_subtract'] = all_combined_df.loc[all_combined_df.groupby(['ProSites', 'PrecursorMZ','GlycanComposition_ByonicStyle', 'Peptide'])['GlyScore'].idxmax(), 'RT'] # get the rt of highest score as ref for rt_dif < 3 min.\n",
    "        all_combined_df['to_subtract_fillna'] = all_combined_df.groupby(['ProSites', 'PrecursorMZ','GlycanComposition_ByonicStyle', 'Peptide'])['to_subtract'].transform(lambda x: x.fillna(x.mean())) # fillna w/ rt of highest score\n",
    "        all_combined_df['rt_dif'] = (all_combined_df['RT'] - all_combined_df['to_subtract_fillna']).abs() # get absolute dif\n",
    "        all_combined_df['rt_dif_reset'] = [0 if dif < pglyco_rt else dif for dif in all_combined_df['rt_dif']] # if rt_dif < 3, then reset the dif to 0 -> seen as the same\n",
    "        pglyco_psm = all_combined_df.groupby(['ProSites', 'PrecursorMZ','GlycanComposition_ByonicStyle', 'Peptide', 'rt_dif_reset'])['ProSites'].transform('size')\n",
    "        all_combined_df.insert(all_combined_df.columns.get_loc('ProSites') + 1 , 'PSM', pglyco_psm , True)\n",
    "        all_combined_df.loc[(all_combined_df['ProSites'] == 'N/A'), 'PSM'] = 'N/A' # if n-site is 'N/A', do not count psm\n",
    "        all_combined_df.loc[pglyco_belowthreshold_id, 'PSM'] = 'N/A' # do not count psm for rows below threshold\n",
    "        all_combined_df.loc[(all_combined_df['ProSites'] == '-1'), 'PSM'] = -1 # if site is '-1', then psm set to -1\n",
    "        all_forsimple_df = all_combined_df.copy() # to retain rt_dif_reset for simple df groupy and get unique row\n",
    "        all_combined_df = all_combined_df.drop(['to_subtract', 'to_subtract_fillna', 'rt_dif', 'rt_dif_reset', 'to_subtract', 'to_subtract_fillna', 'rt_dif', 'rt_dif_reset'], axis = 1) # drop the intermediate cols\n",
    "\n",
    "        print('\\n----- Exporting \"_All\" file... This may take some time, please wait. -----\\n')\n",
    "        all_combined_df.style.apply(bg_color, axis=None).to_excel(f'{date}_{filename}_All.xlsx', index = False)  \n",
    "        print('\\n----- \"_All\" file exported. -----\\n')\n",
    "\n",
    "        print('----- Start preparing simplified version. -----\\n')\n",
    "        # extract rows included in colored indices list separately\n",
    "        simple_pglyco = all_forsimple_df.loc[pglyco_colored_id, :] # extract colored (pass threshold) rows\n",
    "        simple_pglyco = simple_pglyco[(simple_pglyco['ProSites'] != 'N/A')&(simple_pglyco['ProSites'] != '-1')] # for simplified, n-site must exist\n",
    "        simple_pglyco = simple_pglyco.loc[simple_pglyco['FragmentType[pGlyco]'] == 'hcd'] # pglyco etd has the same values as hcd, so only let hcd enter unique file\n",
    "        # get unique calc.m/z by groupby & idxmax function to find highest score within each gp and preserve (remember to split the simple_df into byonicbyos & pglyco parts to avoid dropping non-target rows)\n",
    "        simple_pglyco = simple_pglyco.groupby(['ProSites', 'PrecursorMZ','GlycanComposition_ByonicStyle', 'Peptide', 'rt_dif_reset'], as_index=False).apply(lambda x: x.loc[x['GlyScore'].idxmax()]).reset_index(drop=True)\n",
    "\n",
    "        # set scan to index & concat simple_byonicbyos & simple_pglyco by scan\n",
    "        simple_pglyco = simple_pglyco.set_index('Scan')\n",
    "        simple_pglyco.reset_index(level=0, inplace=True)\n",
    "        # change variable name\n",
    "        id_df = simple_pglyco\n",
    "        # ast.literaleval byonicbyos n-site & sorting: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic clam/z -> pglcyo calm/z\n",
    "        id_df['ProSites'] = [ast.literal_eval(i) if type(i) == str and '(' not in i else i for i in id_df['ProSites'].tolist()] # convert str back to int & tuple\n",
    "        # drop intermediate cols\n",
    "        id_df = id_df.drop(['to_subtract', 'to_subtract_fillna', 'rt_dif', 'rt_dif_reset'], axis = 1) # drop the intermediate cols\n",
    "        col_order = id_df.columns.tolist()\n",
    "        # sorting order: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic calm/z -> pglcyo calm/z => all of this can be acheive with sort_values to multi cols.\n",
    "\n",
    "        id_df = sort_intstr_col(id_df, 'Charge')\n",
    "        print('Done sorting by Charge --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'PrecursorMH')\n",
    "        print('Done sorting by PrecursorMH --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'PeptideMH')\n",
    "        print('Done sorting by PeptideMH --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'GlycanComposition_ByonicStyle')\n",
    "        print('Done sorting by GlycanComposition_ByonicStyle --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'Peptide')\n",
    "        print('Done sorting by Peptide --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'ProSites')\n",
    "        print('Done sorting by ProSites')\n",
    "\n",
    "        # convert '-1' back to int -1 for correct glycansource analysis\n",
    "        id_df['GlycanComposition_ByonicStyle'] = [int(i) if i == '-1' else i for i in id_df['GlycanComposition_ByonicStyle']]\n",
    "        id_df = id_df[col_order]\n",
    "        threshold_masks_colorind(id_df)\n",
    "        print('\\n----- Exporting \"_UniquePep\" file... This may take some time, please wait. -----\\n')\n",
    "        id_df.style.apply(bg_color, axis=None).to_excel(f'{date}_{filename}_UniquePep.xlsx', index = False)  \n",
    "        print('\\n----- \"_UniquePep\" file exported. -----\\n')\n",
    "    elif byonicfile == '' and byosfile != '' and pglycofile == '': # only byos \n",
    "        print('----- Only Byos file is detected. Please at least submit either Byonic or pGlyco file for further processing. -----\\n')\n",
    "    elif byonicfile == '' and byosfile != '' and pglycofile == '': # byos + pglyco \n",
    "        print('----- Byos & pGlyco files are detected. Please submit Byonic file for further processing. -----\\n')\n",
    "    elif byonicfile != '' and byosfile != '' and pglycofile == '': # byonic + byos \n",
    "        print('----- Start combining Byonic & Byos. -----\\n')\n",
    "        # combined data based on 'Scan'\n",
    "        byonic_scanasid = byonic_df.copy()\n",
    "        new_byonic_col = [n + '[Byonic]' if n != 'Scan' else n for n in byonic_scanasid.columns]\n",
    "        byonic_scanasid.columns = new_byonic_col\n",
    "        byos_scanasid = byos_df.copy()\n",
    "        new_byos_col = [n + '[Byos]' if n != 'Scan Number(s)\\r\\n(Posit)' else n for n in byos_scanasid.columns]\n",
    "        byos_scanasid.columns = new_byos_col\n",
    "        byonic_scanasid = byonic_scanasid.set_index('Scan')\n",
    "        byos_scanasid = byos_scanasid.set_index('Scan Number(s)\\r\\n(Posit)')\n",
    "        # align scan & concat (all align on row to make row number all the same)\n",
    "        a1, a2 = byonic_scanasid.align(byos_scanasid, join = 'outer', axis = 0) # row: a1 = a2\n",
    "        all_combined_df = pd.concat([a1,a2], axis = 1)\n",
    "        all_combined_df.index.name = 'Scan'\n",
    "        all_combined_df.reset_index(level=0, inplace=True)\n",
    "        # change all nan to blank -1\n",
    "        all_combined_df = all_combined_df.fillna(-1)\n",
    "        ## result post-processing \n",
    "        print('\\nCombined data shape:\\nrow --> %s, column --> %s'%(all_combined_df.shape[0], all_combined_df.shape[1]))\n",
    "        ## style apply for excel export\n",
    "        # color the rows below the threshold (threshold [byonic: score > 200 & pep2d < 0.001; pglyco: PepScore>5 & GlyScore>4])\n",
    "        # color code => #ffedcc -> light orange for byonic; #add8e6 -> light blue for pglyco; #FFB6C1 -> light pink for byos w/ dif calm ^ seq from byonic; #FF1493 -> deep pink for byos w/ dif calm & seq from byonic; #FFFF00 -> yellow for byos & byonic all the same\n",
    "        threshold_masks_colorind(all_combined_df)\n",
    "        # analyze PSM (need to pass threshold)\n",
    "        byonic_colored_id = list(set(lightgreen_ind + normalgreen_ind)) # byonic pass threshold\n",
    "        byonic_belowthreshold_id = [i for i in all_combined_df.index.tolist() if i not in byonic_colored_id]\n",
    "        # using groupby size function to count psm & add psm columns (new criterion: RT/scantime dif < 3 min (180s). is regarded as the same, >= 3 min. should be seen as dif)\n",
    "        # byonic & byos\n",
    "        all_combined_df = all_combined_df.astype({'N-site(SequonBased)[Byonic]': 'str'}) # convert list & tuple to str for later groupby function\n",
    "        all_combined_df['to_subtract[Byonic]'] = all_combined_df.loc[all_combined_df.groupby(['N-site(SequonBased)[Byonic]', 'Calc.\\r\\nm/z[Byonic]','Glycans[Byonic]', 'PureSequence[Byonic]'])['Score[Byonic]'].idxmax(), 'Scan\\r\\nTime[Byonic]'] # get the rt of highest score as ref for rt_dif < 3 min.\n",
    "        all_combined_df['to_subtract_fillna[Byonic]'] = all_combined_df.groupby(['N-site(SequonBased)[Byonic]', 'Calc.\\r\\nm/z[Byonic]','Glycans[Byonic]', 'PureSequence[Byonic]'])['to_subtract[Byonic]'].transform(lambda x: x.fillna(x.mean())) # fillna w/ rt of highest score\n",
    "        all_combined_df['rt_dif[Byonic]'] = (all_combined_df['Scan\\r\\nTime[Byonic]'] - all_combined_df['to_subtract_fillna[Byonic]']).abs() # get absolute dif\n",
    "        all_combined_df['rt_dif_reset[Byonic]'] = [0 if dif < byonic_rt else dif for dif in all_combined_df['rt_dif[Byonic]']] # if rt_dif < 3, then reset the dif to 0 -> seen as the same\n",
    "        byonic_psm = all_combined_df.groupby(['N-site(SequonBased)[Byonic]', 'Calc.\\r\\nm/z[Byonic]','Glycans[Byonic]', 'PureSequence[Byonic]', 'rt_dif_reset[Byonic]'])['N-site(SequonBased)[Byonic]'].transform('size')\n",
    "        all_combined_df.insert(all_combined_df.columns.get_loc('N-site(SequonBased)[Byonic]') + 1 , 'PSM[Byonic]', byonic_psm , True)\n",
    "        all_combined_df.loc[(all_combined_df['N-site(SequonBased)[Byonic]'] == 'N/A'), 'PSM[Byonic]'] = 'N/A' # if n-site is 'N/A', do not count psm\n",
    "        all_combined_df.loc[byonic_belowthreshold_id, 'PSM[Byonic]'] = 'N/A' # do not count psm for rows below threshold\n",
    "        all_combined_df.loc[(all_combined_df['N-site(SequonBased)[Byonic]'] == '-1'), 'PSM[Byonic]'] = -1 # if site is '-1', then psm set to -1\n",
    "        all_forsimple_df = all_combined_df.copy() # to retain rt_dif_reset for simple df groupy and get unique row\n",
    "        all_combined_df = all_combined_df.drop(['to_subtract[Byonic]', 'to_subtract_fillna[Byonic]', 'rt_dif[Byonic]', 'rt_dif_reset[Byonic]'], axis = 1) # drop the intermediate cols\n",
    "\n",
    "        print('\\n----- Exporting \"_All\" file... This may take some time, please wait. -----\\n')\n",
    "        all_combined_df.style.apply(bg_color, axis=None).to_excel(f'{date}_{filename}_All.xlsx', index = False)  \n",
    "        print('\\n----- \"_All\" file exported. -----\\n')\n",
    "        \n",
    "        if 'Pair[Byonic]' in all_combined_df.columns.tolist():\n",
    "            # ONLY FOR HCD/ETD FILES: prepare '_Pair' file (as long as byonic passes threshold & have pair)\n",
    "            all_combined_df = all_combined_df.astype({'Pair[Byonic]': 'str'})\n",
    "            pair_df = all_combined_df.loc[byonic_colored_id]\n",
    "            pair_df = pair_df[pair_df['Pair[Byonic]'].str.contains('pair')]\n",
    "            pair_df = pair_df[pair_df.duplicated(subset=['Pair[Byonic]'], keep=False)] # only paired data included in _Pair\n",
    "            threshold_masks_colorind(pair_df)\n",
    "            print('\\n----- Exporting \"_Pair\" file... This may take some time, please wait. -----\\n')\n",
    "            pair_df.style.apply(bg_color, axis=None).to_excel(f'{date}_{filename}_Pair.xlsx', index = False)  \n",
    "            print('\\n----- \"_Pair\" file exported. -----\\n')\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        print('----- Start preparing simplified version. -----\\n')\n",
    "        # extract rows included in colored indices list separately\n",
    "        byonicbyos_col_range = ['Scan'] + [col for col in all_forsimple_df.columns.tolist() if '[Byonic]' in col or '[Byos]' in col]\n",
    "        simple_byonicbyos = all_forsimple_df.loc[byonic_colored_id, byonicbyos_col_range] # extract colored (pass threshold) rows\n",
    "        simple_byonicbyos = simple_byonicbyos[(simple_byonicbyos['N-site(SequonBased)[Byonic]'] != 'N/A')&(simple_byonicbyos['N-site(SequonBased)[Byonic]'] != '-1')] # for simplified, n-site must exist\n",
    "        \n",
    "        # get unique calc.m/z by groupby & idxmax function to find highest score within each gp and preserve (remember to split the simple_df into byonicbyos & pglyco parts to avoid dropping non-target rows)\n",
    "        simple_byonicbyos = simple_byonicbyos.groupby(['N-site(SequonBased)[Byonic]', 'Calc.\\r\\nm/z[Byonic]','Glycans[Byonic]', 'PureSequence[Byonic]', 'rt_dif_reset[Byonic]'], as_index=False).apply(lambda x: x.loc[x['Score[Byonic]'].idxmax()]).reset_index(drop=True)\n",
    "        \n",
    "        # make sure scan is the 1st col\n",
    "        simple_byonicbyos = simple_byonicbyos.set_index('Scan')\n",
    "        simple_byonicbyos.reset_index(level=0, inplace=True)\n",
    "        # change variable name\n",
    "        id_df = simple_byonicbyos\n",
    "        # extract nglycan numbers in Mods & use it to calculate byonic pep mass \n",
    "        mods_nglycan_sum = [sum([ast.literal_eval(v) for v in lst]) if type(lst) == list else -1 for lst in id_df['Mods\\r\\n(variable)[Byonic]'].str.findall(r'Glycan / (\\d+.\\d+)').tolist()]\n",
    "        id_df['glycan_mods_sum[Byonic]'] = mods_nglycan_sum\n",
    "        id_df['PepMS[Byonic]'] = id_df['Calc.\\r\\nMH[Byonic]'] - id_df['glycan_mods_sum[Byonic]']\n",
    "        id_df.loc[(id_df['glycan_mods_sum[Byonic]'] == -1), 'PepMS[Byonic]'] = -1\n",
    "        move_df(id_df, 'PepMS[Byonic]', 'Fragment\\r\\nType[Byonic]')\n",
    "        # ast.literaleval byonicbyos n-site & sorting: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic clam/z -> pglcyo calm/z\n",
    "        id_df['N-site(SequonBased)[Byonic]'] = [ast.literal_eval(i) if type(i) == str and '(' not in i else i for i in id_df['N-site(SequonBased)[Byonic]'].tolist()] # convert str back to int & tuple\n",
    "                \n",
    "        # drop intermediate cols\n",
    "        id_df = id_df.drop(['to_subtract[Byonic]', 'to_subtract_fillna[Byonic]', 'rt_dif[Byonic]', 'rt_dif_reset[Byonic]', 'glycan_mods_sum[Byonic]'], axis = 1) # drop the intermediate cols\n",
    "        \n",
    "        col_order = id_df.columns.tolist()\n",
    "        # sorting order: byonic site -> pglyco site -> byonic peptide mass -> pglyco peptide mass -> byonic glycans -> pglyco glycans in byonic style -> byonic calm/z -> pglcyo calm/z => all of this can be acheive with sort_values to multi cols.\n",
    "\n",
    "        id_df = sort_intstr_col(id_df, 'z[Byonic]')\n",
    "        print('Done sorting by z[Byonic] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'Calc.\\r\\nMH[Byonic]')\n",
    "        print('Done sorting by Calc.MH[Byonic] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'PepMS[Byonic]')\n",
    "        print('Done sorting by PepMS[Byonic] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'Glycans[Byonic]')\n",
    "        print('Done sorting by Glycans[Byonic] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'PureSequence[Byonic]')\n",
    "        print('Done sorting by PureSequence[Byonic] --> ', end = '')\n",
    "        id_df = sort_intstr_col(id_df, 'N-site(SequonBased)[Byonic]')\n",
    "        print('Done sorting by N-site(SequonBased)[Byonic]')\n",
    "\n",
    "        # convert '-1' back to int -1 for correct glycansource analysis\n",
    "        id_df['Glycans[Byonic]'] = [int(i) if i == '-1' else i for i in id_df['Glycans[Byonic]']]\n",
    "        \n",
    "        id_df = id_df[col_order]\n",
    "        threshold_masks_colorind(id_df)\n",
    "        print('\\n----- Exporting \"_UniquePep\" file... This may take some time, please wait. -----\\n')\n",
    "        id_df.style.apply(bg_color, axis=None).to_excel(f'{date}_{filename}_UniquePep.xlsx', index = False)  \n",
    "        print('\\n----- \"_UniquePep\" file exported. -----\\n')\n",
    "        print('----- Start preparing quantification file. -----\\n')\n",
    "\n",
    "        # quantification only apply to single sites (quant_df offers important info. for later multiIndex df construction)\n",
    "        quant = id_df[id_df['N-site(SequonBased)[Byonic]'].apply(lambda x: isinstance(x, int))]\n",
    "        drop_ind = quant.loc[(quant['Fragment\\r\\nType[Byonic]'] == 'ethcd') & ((quant['Score[Byonic]'] <= 200)|(quant['PEP\\r\\n2D[Byonic]'].abs() >= 0.001)) & ((quant['Pair[Byonic]'] == -1)|(quant['Pair[Byonic]'] == 'N/A'))].index.tolist()\n",
    "        ind = [i for i in quant.index.tolist() if i not in drop_ind]\n",
    "        quant = quant.loc[ind] # hcd all in, if byonic etd pass score & pep2d all in, otherwise in with pair\n",
    "        # normalize by sum of xicauc/ int/ mono/ iso respectively\n",
    "        total_xicauc = quant.loc[quant['XIC\\r\\nAUC[Byos]'] != -1, 'XIC\\r\\nAUC[Byos]'].sum()\n",
    "        print('total_xicauc:%s'%total_xicauc)\n",
    "        total_int = quant.loc[quant['Apex Int.\\r\\n(Posit)[Byos]'] != -1, 'Apex Int.\\r\\n(Posit)[Byos]'].sum()\n",
    "        print('total_int:%s'%total_int)\n",
    "        total_mono = quant.loc[quant['MonoArea[pGlyco]'] != -1, 'MonoArea[pGlyco]'].sum()\n",
    "        print('total_mono:%s'%total_mono)\n",
    "        total_iso = quant.loc[quant['IsotopeArea[pGlyco]'] != -1, 'IsotopeArea[pGlyco]'].sum()\n",
    "        print('total_iso:%s'%total_iso)\n",
    "        # avoid adding values from below-threshold rows: if deepgreen -> change value to -1, if deepblue -> change value to -1.(-1 to make lambda function easier to write)\n",
    "        threshold_masks_colorind(quant)\n",
    "        quant.loc[deepgreen_ind, ['MonoArea[pGlyco]', 'IsotopeArea[pGlyco]']] = -1\n",
    "        quant.loc[deepblue_ind, ['XIC\\r\\nAUC[Byos]', 'Apex Int.\\r\\n(Posit)[Byos]']] = -1\n",
    "        # convert all the 'N/A' in byonic glycans to 'Unoccupied'\n",
    "        quant.loc[(quant['Glycans[Byonic]'] == 'N/A'), ['Glycans[Byonic]']] = 'Unoccupied'\n",
    "        # using groupby transform sum function to add 8 cols (byos xicauc/byos area int/pglycomono/pglycoisotope) recording summed values & normalized values (same site & same glycan & seq can be dif)\n",
    "        quant['e_sum_XIC\\r\\nAUC[Byos]'] = quant.groupby(['N-site(SequonBased)[Byonic]', 'Glycans[Byonic]'])['XIC\\r\\nAUC[Byos]'].transform(lambda x: x[x != -1].sum())\n",
    "        quant['f_sum_Apex Int.\\r\\n(Posit)[Byos]'] = quant.groupby(['N-site(SequonBased)[Byonic]', 'Glycans[Byonic]'])['Apex Int.\\r\\n(Posit)[Byos]'].transform(lambda x: x[x != -1].sum())\n",
    "        quant['g_sum_MonoArea[pGlyco]'] = quant.groupby(['ProSites[pGlyco]', 'GlycanComposition_ByonicStyle[pGlyco]'])['MonoArea[pGlyco]'].transform(lambda x: x[x != -1].sum())\n",
    "        quant['h_sum_IsotopeArea[pGlyco]'] = quant.groupby(['ProSites[pGlyco]', 'GlycanComposition_ByonicStyle[pGlyco]'])['IsotopeArea[pGlyco]'].transform(lambda x: x[x != -1].sum())\n",
    "        quant['a_norm_XIC\\r\\nAUC[Byos]'] = quant.groupby(['N-site(SequonBased)[Byonic]', 'Glycans[Byonic]'])['XIC\\r\\nAUC[Byos]'].transform(lambda x: x[x != -1].sum()/total_xicauc)\n",
    "        quant['b_norm_Apex Int.\\r\\n(Posit)[Byos]'] = quant.groupby(['N-site(SequonBased)[Byonic]', 'Glycans[Byonic]'])['Apex Int.\\r\\n(Posit)[Byos]'].transform(lambda x: x[x != -1].sum()/total_int)\n",
    "        quant['c_norm_MonoArea[pGlyco]'] = quant.groupby(['ProSites[pGlyco]', 'GlycanComposition_ByonicStyle[pGlyco]'])['MonoArea[pGlyco]'].transform(lambda x: x[x != -1].sum()/total_mono)\n",
    "        quant['d_norm_IsotopeArea[pGlyco]'] = quant.groupby(['ProSites[pGlyco]', 'GlycanComposition_ByonicStyle[pGlyco]'])['IsotopeArea[pGlyco]'].transform(lambda x: x[x != -1].sum()/total_iso)\n",
    "        # since it's possible to have real 0 from calculation, change the real absent data back to -1 in sum_ & norm_\n",
    "        quant.loc[quant['MonoArea[pGlyco]'] == -1, ['g_sum_MonoArea[pGlyco]', 'h_sum_IsotopeArea[pGlyco]', 'c_norm_MonoArea[pGlyco]', 'd_norm_IsotopeArea[pGlyco]']] = -1\n",
    "        quant.loc[quant['XIC\\r\\nAUC[Byos]'] == -1, ['e_sum_XIC\\r\\nAUC[Byos]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]', 'a_norm_XIC\\r\\nAUC[Byos]', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']] = -1 \n",
    "        # extract the needed cols only & split byonicbyos/pglyco, drop all -1 rows, glycans as index to outer union concat data again\n",
    "        quant_bb = quant[['Scan', 'N-site(SequonBased)[Byonic]', 'Glycans[Byonic]', 'MS2 Search\\r\\nAlias name[Byos]', 'XIC\\r\\nAUC[Byos]', 'Apex Int.\\r\\n(Posit)[Byos]', 'e_sum_XIC\\r\\nAUC[Byos]', 'f_sum_Apex Int.\\r\\n(Posit)[Byos]', 'a_norm_XIC\\r\\nAUC[Byos]', 'b_norm_Apex Int.\\r\\n(Posit)[Byos]']]\n",
    "        quant_bb = quant_bb.rename(columns={'Scan': 'Scan[Byonic]'})\n",
    "        print('quant_bb len: %s'%len(quant_bb))\n",
    "        quant_p = quant[['Scan', 'ProSites[pGlyco]', 'GlycanComposition_ByonicStyle[pGlyco]', 'MonoArea[pGlyco]', 'IsotopeArea[pGlyco]', 'g_sum_MonoArea[pGlyco]', 'h_sum_IsotopeArea[pGlyco]', 'c_norm_MonoArea[pGlyco]', 'd_norm_IsotopeArea[pGlyco]']]\n",
    "        quant_p = quant_p.rename(columns={'Scan': 'Scan[pGlyco]'})\n",
    "        print('quant_p len: %s'%len(quant_p))\n",
    "        quant_bb = quant_bb.loc[quant_bb['N-site(SequonBased)[Byonic]'] != -1]\n",
    "        print('cleaned up quant_bb len: %s'%len(quant_bb))\n",
    "        quant_p = quant_p.loc[quant_p['ProSites[pGlyco]'] != -1]\n",
    "        print('cleaned up quant_p len: %s'%len(quant_p))\n",
    "        quant_bb = quant_bb.set_index('Glycans[Byonic]')\n",
    "        quant_p = quant_p.set_index('GlycanComposition_ByonicStyle[pGlyco]')\n",
    "        a1, a2 = quant_bb.align(quant_p, join = 'outer', axis = 0) \n",
    "        quant_glycanid = pd.concat([a1,a2], axis = 1)\n",
    "        quant_glycanid.index.name = 'Glycans ↓'\n",
    "        quant_glycanid.reset_index(level=0, inplace=True)\n",
    "        # add N(x) col\n",
    "        nx = ['Unoccupied' if lst == [] else 'N(%s)'%(lst[0]) for lst in quant_glycanid['Glycans ↓'].str.findall(r'HexNAc\\((\\d+)\\)').tolist()]\n",
    "        quant_glycanid.insert(0 , 'N(x) ↓', nx , True)\n",
    "        move_df(quant_glycanid, 'ProSites[pGlyco]', 'N-site(SequonBased)[Byonic]')\n",
    "        move_df(quant_glycanid, 'Scan[Byonic]', 'N-site(SequonBased)[Byonic]')\n",
    "        move_df(quant_glycanid, 'Scan[pGlyco]', 'ProSites[pGlyco]')\n",
    "        # change all nan to blank -1\n",
    "        quant_glycanid = quant_glycanid.fillna(-1)\n",
    "        # quant_glycanid.to_excel('quant_glycanid.xlsx', index = False)\n",
    "        print('----- Start summary table construction. -----\\n')\n",
    "        # start grouping: N(X) -> byonic glycans -> byonic sites -> .agg({all 8 cols, apply .mean() & .mean()/total XXX})\n",
    "        quant = quant_glycanid.groupby(['N(x) ↓', 'Glycans ↓', 'N-site(SequonBased)[Byonic]', 'ProSites[pGlyco]']).agg({'e_sum_XIC\\r\\nAUC[Byos]': lambda x: x.mean(), 'f_sum_Apex Int.\\r\\n(Posit)[Byos]': lambda x: x.mean() \\\n",
    "                                                                                              , 'g_sum_MonoArea[pGlyco]': lambda x: x.mean(), 'h_sum_IsotopeArea[pGlyco]': lambda x: x.mean() \\\n",
    "                                                                                              , 'a_norm_XIC\\r\\nAUC[Byos]': lambda x: x.mean(), 'b_norm_Apex Int.\\r\\n(Posit)[Byos]': lambda x: x.mean() \\\n",
    "                                                                                              , 'c_norm_MonoArea[pGlyco]': lambda x: x.mean(), 'd_norm_IsotopeArea[pGlyco]': lambda x: x.mean()})\n",
    "                              \n",
    "        # fix the str '10' sorted before '2' problem\n",
    "        nx = list(set(nx))\n",
    "        nx  = [int(re.findall(r'[0-9]+', i)[0]) if type(i) == str and i != 'Unoccupied' else i for i in nx]\n",
    "        nx.sort(key=lambda v: (isinstance(v, str), v))\n",
    "        new_nx = ['N(%s)'%(str(i)) if type(i) == int and i != -1 else i for i in nx]\n",
    "        quant = quant.reindex(new_nx, level = 0)\n",
    "        # unstack ms2 alias name, byonic n-sites, pglyco n-sites\n",
    "        quant = quant.unstack(level=-1)\n",
    "        quant = quant.unstack(level=-1)\n",
    "        # multiIndex col swaplevel\n",
    "        quant.columns = quant.columns.swaplevel(0, 2)\n",
    "        quant.columns = quant.columns.swaplevel(0, 1)\n",
    "        # sort is necessary for the right table structure (but since it will sort every level, so we need to manually adjust level3 back to the original order)\n",
    "        quant.sort_index(axis=1, level=[0, 1, 2], inplace=True)\n",
    "        quant.columns = quant.columns.set_names(['ProSites[pGlyco] →', 'N-site(SequonBased)[Byonic] →', 'Quant. →'])\n",
    "        # delete a-h in Quant. (the alphabet is just for sorting)\n",
    "        quant.columns.set_levels(['norm_XIC\\r\\nAUC[Byos]', 'norm_Apex Int.\\r\\n(Posit)[Byos]', 'norm_MonoArea[pGlyco]', 'norm_IsotopeArea[pGlyco]', 'sum_XIC\\r\\nAUC[Byos]', 'sum_Apex Int.\\r\\n(Posit)[Byos]', 'sum_MonoArea[pGlyco]', 'sum_IsotopeArea[pGlyco]'], level = 2, inplace=True)\n",
    "\n",
    "        print('\\n----- Exporting \"_Quant\" file... This may take some time, please wait. -----\\n')\n",
    "        # quant.style.background_gradient(cmap ='Reds').to_excel(f'{date}_{filename}_All.xlsx')  \n",
    "        print('\\n----- \"_Quant\" file exported. -----\\n')\n",
    "    # EXECUTION TIME\n",
    "    print(\"\\nAll tasks completed.\\nExecution time: %.2f seconds\"%(time.time() - start_time))\n",
    "    \n",
    "# RUN PROCESSING\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eb98b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
